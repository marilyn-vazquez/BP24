{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Original data set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/elleemortensen/Documents/GitHub/BP24/Ellee/Sanity Checks/Demos/gaussmall_orig.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# New data set\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/elleemortensen/Documents/GitHub/BP24/Ellee/Experiments/gaussian_new.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Original data set\n",
    "data1 = pd.read_csv(\"/Users/elleemortensen/Documents/GitHub/BP24/Ellee/Sanity Checks/Demos/gaussmall_orig.csv\")\n",
    "\n",
    "# New data set\n",
    "data2 = pd.read_csv(\"/Users/elleemortensen/Documents/GitHub/BP24/Ellee/Experiments/gaussian_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Print shapes for debugging\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of data1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata1\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of data2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata2\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data1' is not defined"
     ]
    }
   ],
   "source": [
    "# Print shapes for debugging\n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea6a10-aae1-4a13-a214-e033f0638380",
   "metadata": {},
   "source": [
    "# Concat Synthetic + Augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86eef45b-8cda-4d44-8ff9-5d6689c1ba6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the last 9 columns to categorical\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m data1\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     data1[column] \u001b[38;5;241m=\u001b[39m data1[column]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Verify the changes\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data1' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert the last 9 columns to categorical\n",
    "for column in data1.columns[-9]:\n",
    "    data1[column] = data1[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(data1.dtypes)\n",
    "\n",
    "# Convert the last 9 columns to categorical\n",
    "for column in data1.columns[-9]:\n",
    "    data1[column] = data1[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(data1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51473b1c-3bd5-4e99-9544-0eb557739829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat (adding rows)\n",
    "augmented_df = pd.concat([data1, data2], axis=0)\n",
    "augmented_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2489f-88d4-44ab-bdef-17c367df9c35",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into X and y\n",
    "X = data1.iloc[:, :-1]  # All columns except the last one\n",
    "y = data1.iloc[:, -1]   # Only the last column\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30441ffc-4e6b-44be-94fb-4366c680c6ec",
   "metadata": {},
   "source": [
    "# Correlation between columns test (Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7781a524-15f7-4da5-95ab-24800c49ed8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numerical_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------------Correlation Matrix------------------------- \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, matrix)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#Calls the function so the matrix prints out    \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m num_corr(numerical_df)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Print the dataframe to verify\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(correlation_matrix)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numerical_df' is not defined"
     ]
    }
   ],
   "source": [
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n",
    "\n",
    "# Print the dataframe to verify\n",
    "print(correlation_matrix)\n",
    "\n",
    "np.savetxt('correlation_matrix.csv', correlation_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Differences in Matrices (Frobenius Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the dataframes to numpy arrays\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m matrix1 \u001b[38;5;241m=\u001b[39m data1\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      3\u001b[0m matrix2 \u001b[38;5;241m=\u001b[39m augmented_df\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Compute the Frobenius norm of the difference between the matrices. \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#frobenius_norm = np.linalg.norm(matrix1 - matrix2, ord='fro')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#axis= 1 goes across columns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#axis = 0 goes across rows\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data1' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert the dataframes to numpy arrays\n",
    "matrix1 = data1.to_numpy()\n",
    "matrix2 = augmented_df.to_numpy()\n",
    "\n",
    "# Compute the Frobenius norm of the difference between the matrices. \n",
    "#frobenius_norm = np.linalg.norm(matrix1 - matrix2, ord='fro')\n",
    "#axis= 1 goes across columns\n",
    "#axis = 0 goes across rows\n",
    "\n",
    "\n",
    "print(f\"Frobenius norm difference: {frobenius_norm: .3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893a07c-00f8-4041-ae4b-77e155738f6f",
   "metadata": {},
   "source": [
    "# Differences in Arrays (L2 Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e65e78-7871-4fc8-a693-b5c2ad10229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm difference:  5.20\n"
     ]
    }
   ],
   "source": [
    "# Compute the L2 norm (Euclidean norm) of the difference between the arrays\n",
    "L2_norm = np.linalg.norm(array1 - array2, ord=2)\n",
    "\n",
    "print(f\"L2 norm difference: {L2_norm: .3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996e1a0-7162-478b-87bc-f7ac46404aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
