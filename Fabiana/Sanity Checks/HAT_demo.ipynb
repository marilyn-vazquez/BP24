{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da77f20e-a3f5-48da-8aec-4960d9f07f79",
   "metadata": {},
   "source": [
    "# HAT\n",
    "- Histogram Augmentation Technique (HAT) is used widely to augment and classify any tabular data\n",
    "- HAT is designed such that the generated data retains the distribution of the original tabular data histogram\n",
    "- HAT analyses the data distribution of a particular feature and based on the feature type (i.e. continuous or discrete) it generates new samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a737b0-03df-46c9-84fa-51d0da483b24",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cd4bc04-cb71-4cce-8d99-e5c6e58713ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.DataFrame.iteritems = pd.DataFrame.items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d89b50-13e2-4a37-b0b5-cd58dec13f7e",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c855b190-2706-44ca-831f-c015ec85ab40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      float64\n",
      "1      float64\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "5      float64\n",
      "6      float64\n",
      "7      float64\n",
      "8      float64\n",
      "9      float64\n",
      "10     float64\n",
      "11     float64\n",
      "12     float64\n",
      "13     float64\n",
      "14     float64\n",
      "15     float64\n",
      "16    category\n",
      "17    category\n",
      "18    category\n",
      "19    category\n",
      "20    category\n",
      "21    category\n",
      "22    category\n",
      "23    category\n",
      "24    category\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2.475630</td>\n",
       "      <td>4.509819</td>\n",
       "      <td>2.698743</td>\n",
       "      <td>0.735190</td>\n",
       "      <td>0.298927</td>\n",
       "      <td>0.733570</td>\n",
       "      <td>-0.401217</td>\n",
       "      <td>2.891989</td>\n",
       "      <td>0.398573</td>\n",
       "      <td>0.309395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430840</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.071487</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>0.513916</td>\n",
       "      <td>0.389062</td>\n",
       "      <td>1.745885</td>\n",
       "      <td>0.878669</td>\n",
       "      <td>1.122335</td>\n",
       "      <td>0.820908</td>\n",
       "      <td>0.205372</td>\n",
       "      <td>0.373203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2.968174</td>\n",
       "      <td>0.157638</td>\n",
       "      <td>0.687278</td>\n",
       "      <td>-0.417489</td>\n",
       "      <td>-1.123093</td>\n",
       "      <td>2.150422</td>\n",
       "      <td>1.684241</td>\n",
       "      <td>1.521522</td>\n",
       "      <td>0.400247</td>\n",
       "      <td>0.165305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2.371169</td>\n",
       "      <td>0.906434</td>\n",
       "      <td>2.989207</td>\n",
       "      <td>1.185898</td>\n",
       "      <td>1.895433</td>\n",
       "      <td>1.591490</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>2.669418</td>\n",
       "      <td>0.261084</td>\n",
       "      <td>0.194195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362731</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1.188074</td>\n",
       "      <td>-0.604477</td>\n",
       "      <td>1.692414</td>\n",
       "      <td>2.779292</td>\n",
       "      <td>5.630710</td>\n",
       "      <td>2.470652</td>\n",
       "      <td>2.391655</td>\n",
       "      <td>2.526611</td>\n",
       "      <td>0.435726</td>\n",
       "      <td>0.239847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-1.902237</td>\n",
       "      <td>4.093622</td>\n",
       "      <td>1.455013</td>\n",
       "      <td>0.745927</td>\n",
       "      <td>1.959397</td>\n",
       "      <td>2.148542</td>\n",
       "      <td>0.823208</td>\n",
       "      <td>0.640636</td>\n",
       "      <td>0.208701</td>\n",
       "      <td>0.211725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.041787</td>\n",
       "      <td>0.598329</td>\n",
       "      <td>0.457436</td>\n",
       "      <td>0.946191</td>\n",
       "      <td>0.489044</td>\n",
       "      <td>0.508848</td>\n",
       "      <td>0.633938</td>\n",
       "      <td>0.888166</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.241606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.217072</td>\n",
       "      <td>2.343969</td>\n",
       "      <td>2.855842</td>\n",
       "      <td>1.467715</td>\n",
       "      <td>3.655893</td>\n",
       "      <td>2.827516</td>\n",
       "      <td>1.309079</td>\n",
       "      <td>-0.802491</td>\n",
       "      <td>0.464559</td>\n",
       "      <td>0.449139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2.021847</td>\n",
       "      <td>0.696105</td>\n",
       "      <td>2.746981</td>\n",
       "      <td>3.661601</td>\n",
       "      <td>1.925047</td>\n",
       "      <td>0.421424</td>\n",
       "      <td>-0.254105</td>\n",
       "      <td>1.765419</td>\n",
       "      <td>0.353653</td>\n",
       "      <td>0.198970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.433892</td>\n",
       "      <td>0.356210</td>\n",
       "      <td>0.444889</td>\n",
       "      <td>0.364789</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>1.218331</td>\n",
       "      <td>0.297104</td>\n",
       "      <td>0.505349</td>\n",
       "      <td>0.254185</td>\n",
       "      <td>0.314854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "139  2.475630  4.509819  2.698743  0.735190  0.298927  0.733570 -0.401217   \n",
       "60   0.071487  0.021725  0.513916  0.389062  1.745885  0.878669  1.122335   \n",
       "204  2.968174  0.157638  0.687278 -0.417489 -1.123093  2.150422  1.684241   \n",
       "186  2.371169  0.906434  2.989207  1.185898  1.895433  1.591490  0.015655   \n",
       "207  1.188074 -0.604477  1.692414  2.779292  5.630710  2.470652  2.391655   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "106 -1.902237  4.093622  1.455013  0.745927  1.959397  2.148542  0.823208   \n",
       "14  -0.041787  0.598329  0.457436  0.946191  0.489044  0.508848  0.633938   \n",
       "92   0.217072  2.343969  2.855842  1.467715  3.655893  2.827516  1.309079   \n",
       "179  2.021847  0.696105  2.746981  3.661601  1.925047  0.421424 -0.254105   \n",
       "102  1.433892  0.356210  0.444889  0.364789  0.004819  1.218331  0.297104   \n",
       "\n",
       "           7         8         9   ...        15   16   17   18   19   20  \\\n",
       "139  2.891989  0.398573  0.309395  ...  0.430840  3.0  1.0  0.0  1.0  0.0   \n",
       "60   0.820908  0.205372  0.373203  ...  0.235020  2.0  0.0  0.0  2.0  2.0   \n",
       "204  1.521522  0.400247  0.165305  ...  0.363965  0.0  0.0  2.0  1.0  1.0   \n",
       "186  2.669418  0.261084  0.194195  ...  0.362731  2.0  0.0  1.0  0.0  1.0   \n",
       "207  2.526611  0.435726  0.239847  ...  0.202225  0.0  0.0  0.0  1.0  0.0   \n",
       "..        ...       ...       ...  ...       ...  ...  ...  ...  ...  ...   \n",
       "106  0.640636  0.208701  0.211725  ...  0.418545  0.0  1.0  1.0  1.0  2.0   \n",
       "14   0.888166  0.017482  0.241606  ...  0.149555  1.0  3.0  2.0  1.0  1.0   \n",
       "92  -0.802491  0.464559  0.449139  ...  0.448680  2.0  2.0  1.0  0.0  1.0   \n",
       "179  1.765419  0.353653  0.198970  ...  0.180303  1.0  0.0  1.0  1.0  0.0   \n",
       "102  0.505349  0.254185  0.314854  ...  0.116794  0.0  1.0  0.0  0.0  2.0   \n",
       "\n",
       "      21   22   23   24  \n",
       "139  1.0  2.0  0.0  1.0  \n",
       "60   0.0  2.0  1.0  0.0  \n",
       "204  1.0  2.0  0.0  1.0  \n",
       "186  3.0  0.0  1.0  1.0  \n",
       "207  1.0  0.0  2.0  1.0  \n",
       "..   ...  ...  ...  ...  \n",
       "106  2.0  0.0  0.0  1.0  \n",
       "14   0.0  0.0  0.0  0.0  \n",
       "92   0.0  0.0  0.0  1.0  \n",
       "179  0.0  0.0  1.0  1.0  \n",
       "102  1.0  0.0  1.0  0.0  \n",
       "\n",
       "[192 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "\n",
    "for column in data1.columns[-9:]:\n",
    "    data1[column] = data1[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(data1.dtypes)\n",
    "\n",
    "# data1\n",
    "X = data1.iloc[:, :-1]\n",
    "y = data1.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Combining X_train and y_train into one DataFrame\n",
    "train_combined = pd.concat([X_train, y_train], axis=1)\n",
    "train_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d254a0b4-3f95-4116-ad30-b9fce5455cfa",
   "metadata": {},
   "source": [
    "# HAT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "250e6e5f-494b-4a96-9910-98a9c27829f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define histogram function\n",
    "#data: This is the original dataset that you want to use for generating new data\n",
    "#no_new_data: This parameter indicates how much new data you want to generate\n",
    "#data_feat: This parameter specifies the type of data feature. It can be either 'c' for continuous data or 'd' for discrete data.\n",
    "#preserve: This parameter determines whether to preserve the original dataset or not while generating new data. If set to True, the original dataset will be included in the generated data; otherwise, it won't be included.\n",
    "def histogram_sampler(data, no_new_data, data_feat, preserve):\n",
    "\n",
    "    if (data_feat == 'c'):\n",
    "        start_time = time.time()\n",
    "        print(\"Existing data:\", len(data))\n",
    "        print(\"New data to be produced:\", no_new_data)\n",
    "\n",
    "#Function parameters\n",
    "#X_new = New data for each iteration\n",
    "#len_X_new = length of the newly generated data\n",
    "#iter_count = number of iterations\n",
    "#data_gen = Augmented data (original data + newly generated data)\n",
    "        \n",
    "        X_new = []\n",
    "        len_X_new = len(X_new)\n",
    "        iter_count = 0\n",
    "        data_gen = data\n",
    "\n",
    "\n",
    "         # Histogram calculation and sampling logic goes here...\n",
    "        # Adjust the condition for the while loop\n",
    "        while (len_X_new < 0.7 * no_new_data):\n",
    "            iter_count += 1\n",
    "            print(\"Number of iterations ---> niter_count=\", iter_count)\n",
    "\n",
    "            \n",
    "#Histogram: Generating the histogram , choosing the mid-value of the bins, and normalizing frequency\n",
    "#fd- Freedman–Diaconis rule is employed to choose the bin size, as it depends on the spread of the data, without any presumption\n",
    "            if (iter_count == 1):\n",
    "                Y,X_interval=np.histogram(data_gen,bins='doane')\n",
    "                n_bins = len(Y)\n",
    "            else:\n",
    "                Y,X_interval=np.histogram(data_gen,bins=n_bins)\n",
    "\n",
    "            \n",
    "            X = ((X_interval[0:-1] + X_interval[1:])/2) \n",
    "            Y = Y/max(Y)\n",
    "\n",
    "            bin_val = list(np.round(X,8))\n",
    "            weight = list(Y)\n",
    "            hist = dict(zip(bin_val,weight))\n",
    "\n",
    "            for xi in bin_val[0:-1]:\n",
    "\n",
    "#Values: choosing the values for undergoing validity check\n",
    "\n",
    "                bin_width = ((max(bin_val) - min(bin_val)) / int(len(bin_val)-1))\n",
    "                xm = xi + (bin_width/2)\n",
    "                x1 = xi\n",
    "                y1 = hist[xi]\n",
    "\n",
    "                res = None\n",
    "                temp = iter(hist)\n",
    "                for key in temp:\n",
    "                    if(key == xi):\n",
    "                        res = next(temp,None)\n",
    "\n",
    "                y2 = hist[res]\n",
    "                ym = ((y1+y2)/2)\n",
    "#Validity check: checking if the specified value can be considered\n",
    "#if(no_new_data <= len(data)):\n",
    "#ym = ym*(np.random.rand()<=ym)\n",
    "#y1 = y1*(np.random.rand()<=y1)\n",
    "    \n",
    "                #else:\n",
    "                ym = ym*(abs(np.random.normal(0,0.5))<=ym)\n",
    "                y1 = y1*(abs(np.random.normal(0,0.5))<=y1)\n",
    "\n",
    "#Appending: appending the valid values\n",
    "                \n",
    "\n",
    "                if (ym!=0):\n",
    "                    X_new.append(np.round(xm,8))\n",
    "                    #X_new.append(np.round(xm+0.1*xm,8))\n",
    "                    #X_new.append(np.round(xm-0.1*xm,8))\n",
    "                if (y1!=0):\n",
    "                    X_new.append(np.round(x1,8))\n",
    "                    #X_new.append(np.round(x1+0.1*xm,8))\n",
    "                    #X_new.append(np.round(x1-0.1*xm,8))\n",
    "#Stopping: bins * 2, length check\n",
    "\n",
    "            data_gen = data_gen + X_new\n",
    "            n_bins = n_bins*2     \n",
    "            len_X_new+= len(X_new)\n",
    "            print(len_X_new)\n",
    "            X_new = []\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "        print(len(data_gen)-len(data),no_new_data)\n",
    "\n",
    "        if(len(data_gen)-len(data) >= no_new_data):\n",
    "            data_gen = data_gen[:len(data)] + list(np.random.choice(data_gen[len(data):], no_new_data, replace = False))\n",
    "            print('\\nNew data generated:', len(data_gen[len(data):]), '\\nNew data:', len(data_gen), '\\n')\n",
    "            #sns.distplot(data_gen)\n",
    "            if(preserve == False):\n",
    "                data_gen = data_gen[len(data):]\n",
    "            return data_gen\n",
    "\n",
    "        else:\n",
    "            print('to discrete...', no_new_data - (len(data_gen)-len(data)))\n",
    "            samples = histogram_sampler(data_gen, no_new_data - (len(data_gen)-len(data)), 'd', preserve = True)\n",
    "            if(preserve == False):\n",
    "                samples = samples[len(data):]\n",
    "            return samples\n",
    "            \n",
    "    elif(data_feat == 'd'):\n",
    "        X_new=[]\n",
    "        data_gen=[]\n",
    "        disc_data= list(set(data))\n",
    "\n",
    "        for i in disc_data: \n",
    "            x=data.count(i)\n",
    "            X_new.append(round(x*(no_new_data) / len(data)))\n",
    "        #print(x_new,sum(x_new))\n",
    "\n",
    "        for j in range(0,len(X_new)):\n",
    "            for i in range(X_new[j]):\n",
    "                data_gen.append(disc_data[j])\n",
    "\n",
    "        if(len(data_gen)==0):\n",
    "            data_gen = data + data_gen\n",
    "\n",
    "        print(no_new_data, sum(X_new))            \n",
    "        if(no_new_data > sum(X_new)):\n",
    "            data_gen = data + data_gen\n",
    "            data_gen = list(data_gen + list(np.random.choice(data_gen,int(no_new_data-sum(X_new)),replace = False)))    \n",
    "\n",
    "        data_gen = list(np.random.choice(data_gen,int(no_new_data),replace = False))   \n",
    "        \n",
    "        if(preserve == True):\n",
    "            data_gen = data + data_gen\n",
    "    \n",
    "        #sns.distplot(data_gen)     \n",
    "        print('\\nNew data generated:', len(data_gen[len(data):]), '\\nNew data:', len(data_gen), '\\n') \n",
    "        return data_gen\n",
    "        \n",
    "    else:\n",
    "        print('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2700468-ca31-4fff-8539-d6139ba6e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_class : This parameter represents the DataFrame containing the data.\n",
    "#diff :This parameter specifies the difference or ratio between the number of samples in the smallest and largest classes after splitting\n",
    "#label_name: It's the column in your DataFrame that you want to use for splitting the data.\n",
    "#cd: It can take values 'c' for continuous classes or 'd' for discrete classes.\n",
    "#label_column: It helps the function identify which column contains the labels or classes.\n",
    "#preserve: If set to `True`, the original dataset will be included in the split data; otherwise, it won't be included.\n",
    "def label_split(df_class, diff, label_name , cd, label_column, preserve):\n",
    "    cdi = 0\n",
    "    columns_data ={}\n",
    "    \n",
    "    df_ = pd.DataFrame(columns=[])\n",
    "    del df_class[label_column]\n",
    "    \n",
    "    for (columnName, columnData) in df_class.iteritems(): \n",
    "        print(columnName)\n",
    "        feat_type = cd[cdi]\n",
    "        df_[columnName] = histogram_sampler(list(columnData.values), diff, feat_type, preserve)\n",
    "        cdi+=1\n",
    "    \n",
    "    df_[label_column] = label_name\n",
    "    print(df_)\n",
    "\n",
    "    return df_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a38fa058-c7a2-4c45-9a9f-51ef5676efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance(data, label_column, cd, augment = False, preserve = True):\n",
    "    split_list=[]\n",
    "    #label_column = 'species'\n",
    "    for label, df_label in data.groupby(label_column):\n",
    "        split_list.append(df_label)\n",
    "\n",
    "    maxLength = max(len(x) for x in split_list)\n",
    "\n",
    "    if(augment == False):\n",
    "        augmented_list=[]\n",
    "        for i in range(0,len(split_list)):\n",
    "\n",
    "            label_name = list(set(split_list[i][label_column]))[0]\n",
    "            diff = maxLength - len(split_list[i])\n",
    "            augmented_list.append(label_split(split_list[i], diff, label_name, cd, label_column, preserve))\n",
    "        finaldf = pd.DataFrame(columns=[])\n",
    "\n",
    "    elif(type(augment) == dict):\n",
    "        augmented_list=[]\n",
    "        for i in range(0,len(split_list)):\n",
    "\n",
    "            label_name = list(set(split_list[i][label_column]))[0]\n",
    "            diff = augment[label_name]\n",
    "            augmented_list.append(label_split(split_list[i], diff, label_name, cd, label_column, preserve))\n",
    "        finaldf = pd.DataFrame(columns=[])\n",
    "\n",
    "    elif(type(augment) == int):\n",
    "\n",
    "        label_count = dict(Counter(list(df[label_column])))\n",
    "        count_key = list(label_count.keys())\n",
    "        count_val = list(label_count.values())\n",
    "\n",
    "        for i in range(0,len(count_val)):\n",
    "            count_val[i] = round(count_val[i] * augment  /sum(list(label_count.values())))\n",
    "\n",
    "\n",
    "        while(sum(count_val) != augment):\n",
    "            if(sum(count_val) > augment):\n",
    "                rand_indx = int(np.random.rand() * len(count_val))\n",
    "                if(count_val[rand_indx] > 0):\n",
    "                    count_val[rand_indx]-= 1\n",
    "\n",
    "            else:\n",
    "                rand_indx = int(np.random.rand() * len(count_val))\n",
    "                count_val[rand_indx]+= 1\n",
    "\n",
    "        new_count = dict(zip(count_key, count_val))\n",
    "\n",
    "        augmented_list=[]\n",
    "        for i in range(0,len(split_list)):\n",
    "\n",
    "            label_name = list(set(split_list[i][label_column]))[0]\n",
    "            diff = new_count[label_name]\n",
    "            augmented_list.append(label_split(split_list[i], diff, label_name, cd, label_column, preserve))\n",
    "        finaldf = pd.DataFrame(columns=[])\n",
    "\n",
    "\n",
    "        #finaldf = class_balance(data, label_column, cd, augment = new_count, preserve = preserve)\n",
    "\n",
    "\n",
    "    for i in range(0,len(split_list)):\n",
    "        finaldf = pd.concat([finaldf,augmented_list[i]],axis=0)\n",
    "\n",
    "    return finaldf\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01651932-1b29-4f4e-82b4-f28c6e506afb",
   "metadata": {},
   "source": [
    "# This is where you begin coding!\n",
    "- Below: Only change --> for i in range(0, 24):\n",
    "- 24 is the number of columns in your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83d942-b529-46ea-81a0-a9e4bb490b09",
   "metadata": {},
   "source": [
    "# Run HAT Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27561d2e-4779-4e0d-8e58-e0f6bdf06d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of new rows to augment:  240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "14\n",
      "--- 0.0036280155181884766 seconds ---\n",
      "14 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "1\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "10\n",
      "--- 0.0008018016815185547 seconds ---\n",
      "10 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "2\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "9\n",
      "--- 0.0006361007690429688 seconds ---\n",
      "9 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "3\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "8\n",
      "--- 0.001238107681274414 seconds ---\n",
      "8 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "4\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "11\n",
      "--- 0.0010156631469726562 seconds ---\n",
      "11 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "5\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "8\n",
      "--- 0.0008032321929931641 seconds ---\n",
      "8 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "6\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "9\n",
      "--- 0.0018768310546875 seconds ---\n",
      "9 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "7\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "10\n",
      "--- 0.0008180141448974609 seconds ---\n",
      "10 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "8\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "14\n",
      "--- 0.0005841255187988281 seconds ---\n",
      "14 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "9\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "13\n",
      "--- 0.0005099773406982422 seconds ---\n",
      "13 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "10\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "12\n",
      "--- 0.0005309581756591797 seconds ---\n",
      "12 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "11\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "8\n",
      "--- 0.00045990943908691406 seconds ---\n",
      "8 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "12\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "12\n",
      "--- 0.0005488395690917969 seconds ---\n",
      "12 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "13\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "9\n",
      "--- 0.0010399818420410156 seconds ---\n",
      "9 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "14\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "14\n",
      "--- 0.0005581378936767578 seconds ---\n",
      "14 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "15\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "13\n",
      "--- 0.00047898292541503906 seconds ---\n",
      "13 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "16\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "7\n",
      "--- 0.0005099773406982422 seconds ---\n",
      "7 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "17\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "8\n",
      "--- 0.0005090236663818359 seconds ---\n",
      "8 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "18\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "4\n",
      "--- 0.0005509853363037109 seconds ---\n",
      "Number of iterations ---> niter_count= 2\n",
      "9\n",
      "--- 0.0009098052978515625 seconds ---\n",
      "9 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "19\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "5\n",
      "--- 0.0004239082336425781 seconds ---\n",
      "5 6\n",
      "to discrete... 1\n",
      "1 0\n",
      "\n",
      "New data generated: 1 \n",
      "New data: 99 \n",
      "\n",
      "20\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "4\n",
      "--- 0.0004372596740722656 seconds ---\n",
      "Number of iterations ---> niter_count= 2\n",
      "11\n",
      "--- 0.000904083251953125 seconds ---\n",
      "11 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "21\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "3\n",
      "--- 0.0003898143768310547 seconds ---\n",
      "Number of iterations ---> niter_count= 2\n",
      "11\n",
      "--- 0.000762939453125 seconds ---\n",
      "11 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "22\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "6\n",
      "--- 0.0004038810729980469 seconds ---\n",
      "6 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "23\n",
      "Existing data: 93\n",
      "New data to be produced: 6\n",
      "Number of iterations ---> niter_count= 1\n",
      "4\n",
      "--- 0.0004038810729980469 seconds ---\n",
      "Number of iterations ---> niter_count= 2\n",
      "9\n",
      "--- 0.0007228851318359375 seconds ---\n",
      "9 6\n",
      "\n",
      "New data generated: 6 \n",
      "New data: 99 \n",
      "\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0   0.071487  0.021725  0.513916  0.389062  1.745885  0.878669  1.122335   \n",
      "1   0.000351  0.550407  0.331484  1.044437  0.390396  0.407602  0.646286   \n",
      "2   1.087347  0.457737 -0.091736  1.002913  0.847598 -0.085731  1.251487   \n",
      "3   0.287127  0.600268  0.968859  1.248610  1.110305  0.695419  1.202400   \n",
      "4  -0.022901  0.047964  0.782207  0.734502 -0.298396  1.115937  0.387924   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "94  1.497023  1.137204  1.064443  1.093759 -0.149971  0.680711  0.415377   \n",
      "95  0.819064 -0.449087  0.159112  0.026437  0.177971 -0.101377  1.046178   \n",
      "96 -0.401263  0.344058  0.272278  1.246234  0.341942  0.941407  0.920018   \n",
      "97  0.276696  0.185429  0.385444  0.483861  1.653710  0.550363  0.793857   \n",
      "98  1.361431  0.819945  0.045945  0.178912  1.325768  0.811059  0.163057   \n",
      "\n",
      "          7         8         9   ...        15        16        17   18  \\\n",
      "0   0.820908  0.205372  0.373203  ...  0.235020  2.000000  0.000000  0.0   \n",
      "1   0.963913  0.166634  0.346868  ...  0.364053  1.000000  2.000000  0.0   \n",
      "2   0.803963  0.304347  0.168672  ...  0.181225  0.000000  1.000000  4.0   \n",
      "3   0.124289  0.307961  0.080798  ...  0.083708  1.000000  1.000000  0.0   \n",
      "4   0.088086  0.145183  0.086185  ...  0.322146  0.000000  1.000000  2.0   \n",
      "..       ...       ...       ...  ...       ...       ...       ...  ...   \n",
      "94 -0.201188  0.077422  0.080989  ...  0.114448  0.727273  0.818182  1.0   \n",
      "95  1.413318  0.102153  0.201873  ...  0.243574  1.090909  0.272727  0.4   \n",
      "96  0.875149  0.176346  0.105166  ...  0.071406  0.181818  1.090909  0.1   \n",
      "97  1.054539  0.275269  0.032635  ...  0.049885  3.090909  3.000000  2.2   \n",
      "98  0.516370  0.349462  0.274404  ...  0.222053  0.363636  4.909091  2.0   \n",
      "\n",
      "          19        20   21    22   23   24  \n",
      "0   2.000000  2.000000  0.0  2.00  1.0  0.0  \n",
      "1   2.000000  2.000000  1.0  1.00  2.0  0.0  \n",
      "2   1.000000  1.000000  3.0  0.00  1.0  0.0  \n",
      "3   0.000000  0.000000  0.0  0.00  0.0  0.0  \n",
      "4   0.000000  0.000000  0.0  0.00  0.0  0.0  \n",
      "..       ...       ...  ...   ...  ...  ...  \n",
      "94  0.227273  1.090909  2.0  0.15  1.0  0.0  \n",
      "95  0.909091  0.090909  3.0  1.20  0.2  0.0  \n",
      "96  1.363636  2.000000  0.4  2.70  0.1  0.0  \n",
      "97  2.272727  1.090909  1.1  0.90  1.0  0.0  \n",
      "98  0.000000  0.181818  1.0  1.80  1.1  0.0  \n",
      "\n",
      "[99 rows x 25 columns]\n",
      "0\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "1\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "2\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "3\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "4\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "5\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "6\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "7\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "8\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "9\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "10\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "11\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "12\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "13\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "14\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "15\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "16\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "17\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "18\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "19\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "20\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "21\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "22\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "23\n",
      "Existing data: 99\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 99 \n",
      "\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0   2.475630  4.509819  2.698743  0.735190  0.298927  0.733570 -0.401217   \n",
      "1   2.968174  0.157638  0.687278 -0.417489 -1.123093  2.150422  1.684241   \n",
      "2   2.371169  0.906434  2.989207  1.185898  1.895433  1.591490  0.015655   \n",
      "3   1.188074 -0.604477  1.692414  2.779292  5.630710  2.470652  2.391655   \n",
      "4   2.638445  2.729833 -3.903223  1.067383 -0.638392  0.543326  0.773438   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "94  0.051633  2.130751  2.717839  2.167154  2.640775 -0.713211  2.541866   \n",
      "95  2.568245  1.561148 -0.175027  1.517797  2.557624  2.001565 -0.454653   \n",
      "96 -1.902237  4.093622  1.455013  0.745927  1.959397  2.148542  0.823208   \n",
      "97  0.217072  2.343969  2.855842  1.467715  3.655893  2.827516  1.309079   \n",
      "98  2.021847  0.696105  2.746981  3.661601  1.925047  0.421424 -0.254105   \n",
      "\n",
      "          7         8         9   ...        15   16   17   18   19   20   21  \\\n",
      "0   2.891989  0.398573  0.309395  ...  0.430840  3.0  1.0  0.0  1.0  0.0  1.0   \n",
      "1   1.521522  0.400247  0.165305  ...  0.363965  0.0  0.0  2.0  1.0  1.0  1.0   \n",
      "2   2.669418  0.261084  0.194195  ...  0.362731  2.0  0.0  1.0  0.0  1.0  3.0   \n",
      "3   2.526611  0.435726  0.239847  ...  0.202225  0.0  0.0  0.0  1.0  0.0  1.0   \n",
      "4   3.515232  0.312116  0.375936  ...  0.429645  1.0  0.0  1.0  1.0  2.0  2.0   \n",
      "..       ...       ...       ...  ...       ...  ...  ...  ...  ...  ...  ...   \n",
      "94  1.355541  0.488824  0.325901  ...  0.296256  3.0  2.0  0.0  1.0  1.0  2.0   \n",
      "95  1.901542  0.302504  0.494011  ...  0.253270  0.0  1.0  0.0  0.0  1.0  1.0   \n",
      "96  0.640636  0.208701  0.211725  ...  0.418545  0.0  1.0  1.0  1.0  2.0  2.0   \n",
      "97 -0.802491  0.464559  0.449139  ...  0.448680  2.0  2.0  1.0  0.0  1.0  0.0   \n",
      "98  1.765419  0.353653  0.198970  ...  0.180303  1.0  0.0  1.0  1.0  0.0  0.0   \n",
      "\n",
      "     22   23   24  \n",
      "0   2.0  0.0  1.0  \n",
      "1   2.0  0.0  1.0  \n",
      "2   0.0  1.0  1.0  \n",
      "3   0.0  2.0  1.0  \n",
      "4   0.0  2.0  1.0  \n",
      "..  ...  ...  ...  \n",
      "94  2.0  0.0  1.0  \n",
      "95  1.0  1.0  1.0  \n",
      "96  0.0  0.0  1.0  \n",
      "97  0.0  0.0  1.0  \n",
      "98  0.0  1.0  1.0  \n",
      "\n",
      "[99 rows x 25 columns]\n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>> 4.592084169387817 seconds \n",
      "----------------------------- Augmented DataFrame -------------------------\n",
      "\n",
      "           0         1         2         3         4         5         6   \\\n",
      "0    2.475630  4.509819  2.698743  0.735190  0.298927  0.733570 -0.401217   \n",
      "1    0.071487  0.021725  0.513916  0.389062  1.745885  0.878669  1.122335   \n",
      "2    2.968174  0.157638  0.687278 -0.417489 -1.123093  2.150422  1.684241   \n",
      "3    2.371169  0.906434  2.989207  1.185898  1.895433  1.591490  0.015655   \n",
      "4    1.188074 -0.604477  1.692414  2.779292  5.630710  2.470652  2.391655   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "427  0.616210  0.717889 -0.032384  0.366636 -0.226484  0.336005  0.919921   \n",
      "428 -1.075887  2.381960  1.451937  4.390355  0.481035 -1.014018  3.025875   \n",
      "429 -0.022901  0.047964  0.782207  0.734502 -0.298396  1.115937  0.387924   \n",
      "430  0.000351  0.550407  0.331484  1.044437  0.390396  0.407602  0.646286   \n",
      "431  0.051633  2.130751  2.717839  2.167154  2.640775 -0.713211  2.541866   \n",
      "\n",
      "           7         8         9   ...        15   16   17   18   19   20  \\\n",
      "0    2.891989  0.398573  0.309395  ...  0.430840  3.0  1.0  0.0  1.0  0.0   \n",
      "1    0.820908  0.205372  0.373203  ...  0.235020  2.0  0.0  0.0  2.0  2.0   \n",
      "2    1.521522  0.400247  0.165305  ...  0.363965  0.0  0.0  2.0  1.0  1.0   \n",
      "3    2.669418  0.261084  0.194195  ...  0.362731  2.0  0.0  1.0  0.0  1.0   \n",
      "4    2.526611  0.435726  0.239847  ...  0.202225  0.0  0.0  0.0  1.0  0.0   \n",
      "..        ...       ...       ...  ...       ...  ...  ...  ...  ...  ...   \n",
      "427  0.302044  0.319013  0.098104  ...  0.065751  0.0  1.0  0.0  2.0  1.0   \n",
      "428 -0.665778  0.409486  0.340132  ...  0.313879  1.0  1.0  2.0  0.0  2.0   \n",
      "429  0.088086  0.145183  0.086185  ...  0.322146  0.0  1.0  2.0  0.0  0.0   \n",
      "430  0.963913  0.166634  0.346868  ...  0.364053  1.0  2.0  0.0  2.0  2.0   \n",
      "431  1.355541  0.488824  0.325901  ...  0.296256  3.0  2.0  0.0  1.0  1.0   \n",
      "\n",
      "      21   22   23   24  \n",
      "0    1.0  2.0  0.0  1.0  \n",
      "1    0.0  2.0  1.0  0.0  \n",
      "2    1.0  2.0  0.0  1.0  \n",
      "3    3.0  0.0  1.0  1.0  \n",
      "4    1.0  0.0  2.0  1.0  \n",
      "..   ...  ...  ...  ...  \n",
      "427  1.0  2.0  1.0  0.0  \n",
      "428  0.0  1.0  1.0  1.0  \n",
      "429  0.0  0.0  0.0  0.0  \n",
      "430  1.0  1.0  2.0  0.0  \n",
      "431  2.0  2.0  0.0  1.0  \n",
      "\n",
      "[432 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gq/wfvm6zt96_vgyjdb9mtbd22w0000gn/T/ipykernel_55441/4247497729.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for label, df_label in data.groupby(label_column):\n"
     ]
    }
   ],
   "source": [
    "# Start Timing the Execution: (do not change this)\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a List cd with Specific Values and prints it\n",
    "cd = []\n",
    "for i in range(0, 24):  # you need to input your number of columns\n",
    "    cd.append('c')\n",
    "print(cd)\n",
    "\n",
    "# Assuming train_combined is your dataframe\n",
    "label_column_index = 24  # Index of the label column\n",
    "label_column_name = train_combined.columns[label_column_index]\n",
    "\n",
    "# Function to augment the data\n",
    "def augment_data(a_df, label_column, cd, num_new_rows):\n",
    "    # Assuming class_balance is your augmentation method\n",
    "    augmented_data = class_balance(a_df, label_column=label_column, cd=cd, augment=False, preserve=True)\n",
    "    additional_rows = augmented_data.sample(n=num_new_rows, replace=True)\n",
    "    augmented_data = pd.concat([a_df, additional_rows], ignore_index=True)\n",
    "    return augmented_data\n",
    "\n",
    "# Get user input for the number of new rows to augment\n",
    "num_new_rows = int(input(\"Enter the number of new rows to augment: \"))\n",
    "\n",
    "# Augment the dataframe with the specified number of new rows\n",
    "a_df = augment_data(train_combined, label_column=label_column_name, cd=cd, num_new_rows=num_new_rows)\n",
    "\n",
    "# Print the Time Taken for Execution\n",
    "print(\"\\n\\n\\n>>>>>>>>> %s seconds \" % (time.time() - start_time))\n",
    "\n",
    "# Print new augmented dataframe\n",
    "print(\"----------------------------- Augmented DataFrame -------------------------\\n\")\n",
    "print(a_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
