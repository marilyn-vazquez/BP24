{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47297b3e-727e-44ba-8672-92785b6dbb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe function Measure_Patterns has 3 parameters: X_train, y_train, optional\\noptional will check if the columns selected is categorical (integers and strings) or numerical (float)\\nif optional is not provided, then the program will assume that the column has integers values, therefore it will be considered categorical\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pdb\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "\"\"\"\n",
    "The function Measure_Patterns has 3 parameters: X_train, y_train, optional\n",
    "optional will check if the columns selected is categorical (integers and strings) or numerical (float)\n",
    "if optional is not provided, then the program will assume that the column has integers values, therefore it will be considered categorical\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc0ac151-8344-469b-a68d-475bb8eba5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "data = np.loadtxt(\"/Users/fabianafazio/Documents/GitHub/BP24/Fabiana/Data/uniform_large_d_1.tex\")\n",
    "#data = np.loadtxt(\"uniform_small_d_1.tex\")\n",
    "#df = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Fabiana/Data/lung_cancer_data.csv\")\n",
    "#df.head()\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "# Converting to Pandas DataFrame\n",
    "df = pd.DataFrame(array)\n",
    "# Displaying the table\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "683d662f-5d3c-46c6-9956-27634c142183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 25 columns from numerical floats -> categorical integers\n",
    "for i in range(25):\n",
    "    \n",
    "    df.iloc[:,i] = df.iloc[:,i].round() # Rounding\n",
    "    df.iloc[:,i] = df.iloc[:,i].astype(int) # Integer\n",
    "    df.iloc[:,i] = df.iloc[:,i].astype('category') # Categories\n",
    "    \n",
    "# Turn label into categorical label\n",
    "df.iloc[:,150] = df.iloc[:,150].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a80b3ea9-9543-419f-a322-bbc6ad318545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,1:150], df.iloc[:,-1], test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "82df840a-2614-46a7-957c-2ba5ed2da8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Measure_Patterns begins here!\n",
    "def Measure_Patterns(X_train, y_train, optional=None):\n",
    "    \n",
    "    # Initialize empty dataframes for numerical and categorical data\n",
    "    numerical_df = pd.DataFrame()\n",
    "    categorical_df = pd.DataFrame()\n",
    "    \n",
    "    # Check if the data type is provided for columns\n",
    "    if optional is None:\n",
    "        print(\"Optional parameter not provided. Assuming integers values are categorical\")\n",
    "    \n",
    "        # Splitting X_train into numerical subset \n",
    "        print(\"\\nNumerical DataFrame:\")\n",
    "        numerical_df = X_train.select_dtypes(include = ['int', 'int64', 'float', 'float64'])\n",
    "        print(numerical_df)\n",
    "\n",
    "        # Splitting X_train into categorical subset \n",
    "        print(\"Categorical DataFrame:\")\n",
    "        categorical_df = X_train.select_dtypes(include=['object', 'category'])\n",
    "        print(categorical_df)\n",
    "    \n",
    "    else:\n",
    "        # Create empty numerical & categorical data frames\n",
    "        numerical = []\n",
    "        numerical_colnames = []\n",
    "        categorical = []\n",
    "        categorical_colnames = []\n",
    "        \n",
    "        # Check that length of optional = # of columns in X_train\n",
    "        # Optional is the column type for X_train, so the lengths should be equal\n",
    "        if len(optional) == len(X_train.columns):\n",
    "            # For all the values in optional\n",
    "            for i in range(len(optional)):\n",
    "                if optional[i] == True:\n",
    "                    numerical.append(X_train.iloc[:,i])\n",
    "                    # TO DO: Save SPECIFIC column name in each loop, order matters\n",
    "                    # numerical_colnames.append()\n",
    "                else: \n",
    "                    categorical.append(X_train.iloc[:,i])\n",
    "                    # TO DO: Save SPECIFIC column name in each loop, order matters\n",
    "                    # categorical_colnames.append()\n",
    "            # Turn transposed arrays into dataframes\n",
    "            numerical_df = pd.DataFrame(np.transpose(numerical))\n",
    "            categorical_df = pd.DataFrame(np.transpose(categorical))\n",
    "            # TO DO: Re-attach the column names to numerical_df & categorical_df \n",
    "            \n",
    "            print(\"Numerical DF:\")\n",
    "            print(numerical_df)\n",
    "            print(\"Categorical Df\")\n",
    "            print(categorical_df)\n",
    "            \n",
    "        else:\n",
    "            print(\"The length of X_train and optional are different.\")\n",
    "\n",
    "    return numerical_df, categorical_df\n",
    "\n",
    "# Get numerical and categorical dataframes\n",
    "#numerical_df, categorical_df = Measure_Patterns(X_train, y_train)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "635ff6f6-65f4-4284-ab9b-3e572552862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Correlation Matrix------------------------- \n",
      "           25        26        27        28        29        30        31   \\\n",
      "25   1.000000  0.358685  0.339666  0.420727  0.325975  0.321370  0.312616   \n",
      "26   0.358685  1.000000  0.357068  0.351886  0.329074  0.287777  0.380258   \n",
      "27   0.339666  0.357068  1.000000  0.367739  0.389061  0.341500  0.396636   \n",
      "28   0.420727  0.351886  0.367739  1.000000  0.335209  0.362763  0.407312   \n",
      "29   0.325975  0.329074  0.389061  0.335209  1.000000  0.360621  0.343141   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "145  0.299274  0.287986  0.303644  0.309662  0.296231  0.337183  0.378580   \n",
      "146  0.329233  0.318679  0.372271  0.342548  0.358008  0.388022  0.348550   \n",
      "147  0.261596  0.304371  0.366230  0.362147  0.330776  0.275535  0.350481   \n",
      "148  0.311470  0.325705  0.249223  0.303436  0.347029  0.317083  0.335171   \n",
      "149  0.331838  0.376243  0.372860  0.329591  0.386683  0.325197  0.342970   \n",
      "\n",
      "          32        33        34   ...       140       141       142  \\\n",
      "25   0.358120  0.340237  0.355736  ...  0.388343  0.343965  0.353968   \n",
      "26   0.364896  0.313088  0.313652  ...  0.330200  0.307858  0.372170   \n",
      "27   0.317724  0.353367  0.391373  ...  0.388568  0.318648  0.311079   \n",
      "28   0.343381  0.324576  0.325974  ...  0.318035  0.318733  0.355605   \n",
      "29   0.288978  0.368976  0.355106  ...  0.275384  0.294827  0.293040   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "145  0.298865  0.340888  0.316708  ...  0.324805  0.255120  0.290438   \n",
      "146  0.329221  0.317480  0.363988  ...  0.300605  0.350588  0.311782   \n",
      "147  0.289346  0.389360  0.366852  ...  0.315736  0.290044  0.367292   \n",
      "148  0.392179  0.276141  0.327268  ...  0.318717  0.280078  0.355233   \n",
      "149  0.385078  0.365040  0.350028  ...  0.368805  0.390631  0.335357   \n",
      "\n",
      "          143       144       145       146       147       148       149  \n",
      "25   0.297635  0.309828  0.299274  0.329233  0.261596  0.311470  0.331838  \n",
      "26   0.270419  0.255457  0.287986  0.318679  0.304371  0.325705  0.376243  \n",
      "27   0.416223  0.254246  0.303644  0.372271  0.366230  0.249223  0.372860  \n",
      "28   0.318610  0.278100  0.309662  0.342548  0.362147  0.303436  0.329591  \n",
      "29   0.337193  0.306814  0.296231  0.358008  0.330776  0.347029  0.386683  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "145  0.271765  0.254472  1.000000  0.356620  0.328866  0.241951  0.357109  \n",
      "146  0.376935  0.298234  0.356620  1.000000  0.385769  0.298358  0.371384  \n",
      "147  0.371114  0.275243  0.328866  0.385769  1.000000  0.285769  0.336253  \n",
      "148  0.364042  0.287514  0.241951  0.298358  0.285769  1.000000  0.347269  \n",
      "149  0.330357  0.215141  0.357109  0.371384  0.336253  0.347269  1.000000  \n",
      "\n",
      "[125 rows x 125 columns]\n"
     ]
    }
   ],
   "source": [
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "num_corr(numerical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "81f9bbe3-b16b-4ab8-8ca3-bf15a134187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------Chi-Squared for Features v. Features-----------------------\n",
      "Chi-Squared Values:\n",
      "                0          1          2          3          4          5  \\\n",
      "0        0.000000  15.224160  25.490076  34.849944  22.262568  12.436666   \n",
      "1       15.224160   0.000000  16.636916  26.793910   5.609747  24.156967   \n",
      "2       25.490076  16.636916   0.000000  24.384730   9.469731  17.746646   \n",
      "3       34.849944  26.793910  24.384730   0.000000  13.046184   9.840086   \n",
      "4       22.262568   5.609747   9.469731  13.046184   0.000000  11.386875   \n",
      "5       12.436666  24.156967  17.746646   9.840086  11.386875   0.000000   \n",
      "6       17.914775   6.716693  28.809709  14.819042   4.781560   4.801779   \n",
      "7       17.086793  14.952261   5.102826  20.019675  12.520304  10.815238   \n",
      "8       19.341124  13.601784  15.378196  27.070757  20.132751  20.061328   \n",
      "9       29.477945  17.980589   9.469731  38.982638  14.831678  14.819042   \n",
      "10      12.681208  12.955651  25.488970   0.855007   4.619875  25.962871   \n",
      "11      19.463548  26.197858  10.541525  22.415896   5.430327  27.121486   \n",
      "12      39.548809   4.993627  13.544493  10.307350  19.611190   8.908307   \n",
      "13      31.861771  14.087381  36.727747  16.704421   9.840086  25.218662   \n",
      "14      29.617421  22.079719  26.325766  25.973357  17.325216  15.263989   \n",
      "15      31.861771  24.156967  14.068204  20.813767  18.702662  27.643362   \n",
      "16       2.725645   2.038960  17.528885   9.867411  11.405517  18.534776   \n",
      "17      10.905941   9.521907   9.597494   7.016907   8.351966  11.420061   \n",
      "18      24.555344  14.230903  20.006750  14.831678   2.128026  16.704421   \n",
      "19      36.961314  11.881026  15.584665  15.587414  15.587414  19.825289   \n",
      "20      23.997165  10.553086  25.461742  27.563167  22.886282   3.909992   \n",
      "21      14.770016   8.442801  12.991488   5.119327  11.924025  11.906770   \n",
      "22      25.170709   5.767652   8.441123  21.149295   9.791694   5.856401   \n",
      "23      23.068081   7.206451  14.909422  26.328139   2.352213   5.128676   \n",
      "24      18.521776  27.104487  31.937744  39.599133  11.937032  13.556160   \n",
      "label  112.752781  76.935839  93.634102  84.404438  58.614193  73.605378   \n",
      "\n",
      "               6          7          8          9  ...         16         17  \\\n",
      "0      17.914775  17.086793  19.341124  29.477945  ...   2.725645  10.905941   \n",
      "1       6.716693  14.952261  13.601784  17.980589  ...   2.038960   9.521907   \n",
      "2      28.809709   5.102826  15.378196   9.469731  ...  17.528885   9.597494   \n",
      "3      14.819042  20.019675  27.070757  38.982638  ...   9.867411   7.016907   \n",
      "4       4.781560  12.520304  20.132751  14.831678  ...  11.405517   8.351966   \n",
      "5       4.801779  10.815238  20.061328  14.819042  ...  18.534776  11.420061   \n",
      "6       0.000000  17.791348  10.850898   8.406160  ...  20.607061  25.549761   \n",
      "7      17.791348   0.000000  30.862820   4.556123  ...   7.910565  12.653863   \n",
      "8      10.850898  30.862820   0.000000  24.644164  ...  14.185281  22.438655   \n",
      "9       8.406160   4.556123  24.644164   0.000000  ...  22.972631   7.016907   \n",
      "10      9.920286   6.975695  18.286311   4.619875  ...   4.859732   8.194622   \n",
      "11     20.174905  28.660210  10.329469  16.106351  ...   8.012937  14.223569   \n",
      "12     15.619565   4.993627   5.787628   8.802596  ...  10.519481  11.838295   \n",
      "13     18.612218  17.791348  26.935454  18.702662  ...  22.789137  13.094912   \n",
      "14      3.312894   8.247643   9.890110  25.973357  ...  13.367729   0.799215   \n",
      "15     30.179337  21.927138  16.040189  16.704421  ...  29.994103  23.187556   \n",
      "16     20.607061   7.910565  14.185281  22.972631  ...   0.000000  25.519891   \n",
      "17     25.549761  12.653863  22.438655   7.016907  ...  25.519891   0.000000   \n",
      "18     20.813767   6.772867  12.477019   5.835810  ...   7.125267  14.854132   \n",
      "19      8.934752   6.179771   8.361520  21.949390  ...  26.975286  11.816494   \n",
      "20     29.685828   5.460809  17.904405  11.462646  ...   2.275372   7.303495   \n",
      "21      6.274624   7.143746  11.377001  23.831466  ...   8.877686   7.491786   \n",
      "22      7.092721  16.634300   7.896701  23.462214  ...  23.638416  11.263952   \n",
      "23     19.429296   6.002149  13.051592   7.468343  ...  13.659859   6.169625   \n",
      "24     19.239701  18.327492  18.638549  19.368174  ...   8.843555  13.708026   \n",
      "label  69.925699  59.315198  90.107143  72.777296  ...  78.242909  75.777076   \n",
      "\n",
      "              18         19         20         21         22         23  \\\n",
      "0      24.555344  36.961314  23.997165  14.770016  25.170709  23.068081   \n",
      "1      14.230903  11.881026  10.553086   8.442801   5.767652   7.206451   \n",
      "2      20.006750  15.584665  25.461742  12.991488   8.441123  14.909422   \n",
      "3      14.831678  15.587414  27.563167   5.119327  21.149295  26.328139   \n",
      "4       2.128026  15.587414  22.886282  11.924025   9.791694   2.352213   \n",
      "5      16.704421  19.825289   3.909992  11.906770   5.856401   5.128676   \n",
      "6      20.813767   8.934752  29.685828   6.274624   7.092721  19.429296   \n",
      "7       6.772867   6.179771   5.460809   7.143746  16.634300   6.002149   \n",
      "8      12.477019   8.361520  17.904405  11.377001   7.896701  13.051592   \n",
      "9       5.835810  21.949390  11.462646  23.831466  23.462214   7.468343   \n",
      "10      9.791694   7.006708   3.181179   7.488113  12.771101   2.206830   \n",
      "11     14.234384   9.701409  20.183409  13.067825  14.230428  11.360606   \n",
      "12     11.930775   5.044320  24.406603  30.072192   8.514330   5.336059   \n",
      "13     27.824260   8.934752   9.824485  23.708789  16.995114  26.237657   \n",
      "14      5.263622  18.780622   6.175785   9.375286  16.036582  22.248044   \n",
      "15     25.374566  22.056820   9.824485  21.462302  16.995114  19.429296   \n",
      "16      7.125267  26.975286   2.275372   8.877686  23.638416  13.659859   \n",
      "17     14.854132  11.816494   7.303495   7.491786  11.263952   6.169625   \n",
      "18      0.000000   1.552570  13.095021  15.439620  11.384638  15.460318   \n",
      "19      1.552570   0.000000  14.298435   5.425363  17.272402   7.804379   \n",
      "20     13.095021  14.298435   0.000000   6.359539   8.860267  19.403423   \n",
      "21     15.439620   5.425363   6.359539   0.000000  10.394200   3.470604   \n",
      "22     11.384638  17.272402   8.860267  10.394200   0.000000  11.901750   \n",
      "23     15.460318   7.804379  19.403423   3.470604  11.901750   0.000000   \n",
      "24     26.115928   9.524031  23.158078   9.347123  10.526115  18.046546   \n",
      "label  72.777296  72.839623  69.059848  64.883438  70.532915  67.616300   \n",
      "\n",
      "              24       label  \n",
      "0      18.521776  112.752781  \n",
      "1      27.104487   76.935839  \n",
      "2      31.937744   93.634102  \n",
      "3      39.599133   84.404438  \n",
      "4      11.937032   58.614193  \n",
      "5      13.556160   73.605378  \n",
      "6      19.239701   69.925699  \n",
      "7      18.327492   59.315198  \n",
      "8      18.638549   90.107143  \n",
      "9      19.368174   72.777296  \n",
      "10     13.902726   52.978056  \n",
      "11     27.909743   73.498233  \n",
      "12     12.664486   66.083829  \n",
      "13     15.340400   93.419035  \n",
      "14     10.742832   78.507123  \n",
      "15      8.865089   93.419035  \n",
      "16      8.843555   78.242909  \n",
      "17     13.708026   75.777076  \n",
      "18     26.115928   72.777296  \n",
      "19      9.524031   72.839623  \n",
      "20     23.158078   69.059848  \n",
      "21      9.347123   64.883438  \n",
      "22     10.526115   70.532915  \n",
      "23     18.046546   67.616300  \n",
      "24      0.000000   76.683029  \n",
      "label  76.683029    0.000000  \n",
      "\n",
      "[26 rows x 26 columns]\n",
      "\n",
      "P-Values:\n",
      "                  0             1             2             3             4  \\\n",
      "0      0.000000e+00  9.547413e-05  4.446644e-07  3.561197e-09  2.377972e-06   \n",
      "1      9.547413e-05  0.000000e+00  4.526144e-05  2.263495e-07  1.786084e-02   \n",
      "2      4.446644e-07  4.526144e-05  0.000000e+00  7.889154e-07  2.088900e-03   \n",
      "3      3.561197e-09  2.263495e-07  7.889154e-07  0.000000e+00  3.039030e-04   \n",
      "4      2.377972e-06  1.786084e-02  2.088900e-03  3.039030e-04  0.000000e+00   \n",
      "5      4.209867e-04  8.879436e-07  2.523620e-05  1.707496e-03  7.396487e-04   \n",
      "6      2.310207e-05  9.551458e-03  7.984983e-08  1.183346e-04  2.876604e-02   \n",
      "7      3.570977e-05  1.102658e-04  2.388690e-02  7.664942e-06  4.025534e-04   \n",
      "8      1.093263e-05  2.259707e-04  8.799790e-05  1.961427e-07  7.224888e-06   \n",
      "9      5.655665e-08  2.231691e-05  2.088900e-03  4.275915e-10  1.175444e-04   \n",
      "10     3.693488e-04  3.189572e-04  4.449192e-07  3.551396e-01  3.160353e-02   \n",
      "11     1.025380e-05  3.081642e-07  1.167221e-03  2.195494e-06  1.978997e-02   \n",
      "12     3.199616e-10  2.544082e-02  2.329739e-04  1.325014e-03  9.491171e-06   \n",
      "13     1.655434e-08  1.745106e-04  1.358323e-09  4.367910e-05  1.707496e-03   \n",
      "14     5.262979e-08  2.615586e-06  2.884152e-07  3.461618e-07  3.149794e-05   \n",
      "15     1.655434e-08  8.879436e-07  1.762990e-04  5.061780e-06  1.527690e-05   \n",
      "16     9.874822e-02  1.533144e-01  2.829759e-05  1.682321e-03  7.322631e-04   \n",
      "17     9.585636e-04  2.030335e-03  1.948431e-03  8.074357e-03  3.852702e-03   \n",
      "18     7.220581e-07  1.616932e-04  7.716929e-06  1.175444e-04  1.446269e-01   \n",
      "19     1.204965e-09  5.670869e-04  7.889184e-05  7.877721e-05  7.877721e-05   \n",
      "20     9.647765e-07  1.159942e-03  4.512430e-07  1.520468e-07  1.718742e-06   \n",
      "21     1.214514e-04  3.664913e-03  3.129102e-04  2.366079e-02  5.541463e-04   \n",
      "22     5.247314e-07  1.632383e-02  3.668297e-03  4.248575e-06  1.753019e-03   \n",
      "23     1.563651e-06  7.264199e-03  1.127982e-04  2.880610e-07  1.251053e-01   \n",
      "24     1.679741e-05  1.927500e-07  1.591936e-08  3.118217e-10  5.502908e-04   \n",
      "label  2.444282e-26  1.766031e-18  3.795908e-22  4.032416e-20  1.918277e-14   \n",
      "\n",
      "                  5             6             7             8             9  \\\n",
      "0      4.209867e-04  2.310207e-05  3.570977e-05  1.093263e-05  5.655665e-08   \n",
      "1      8.879436e-07  9.551458e-03  1.102658e-04  2.259707e-04  2.231691e-05   \n",
      "2      2.523620e-05  7.984983e-08  2.388690e-02  8.799790e-05  2.088900e-03   \n",
      "3      1.707496e-03  1.183346e-04  7.664942e-06  1.961427e-07  4.275915e-10   \n",
      "4      7.396487e-04  2.876604e-02  4.025534e-04  7.224888e-06  1.175444e-04   \n",
      "5      0.000000e+00  2.843037e-02  1.006681e-03  7.499797e-06  1.183346e-04   \n",
      "6      2.843037e-02  0.000000e+00  2.465016e-05  9.874787e-04  3.739518e-03   \n",
      "7      1.006681e-03  2.465016e-05  0.000000e+00  2.769266e-08  3.280125e-02   \n",
      "8      7.499797e-06  9.874787e-04  2.769266e-08  0.000000e+00  6.895326e-07   \n",
      "9      1.183346e-04  3.739518e-03  3.280125e-02  6.895326e-07  0.000000e+00   \n",
      "10     3.480471e-07  1.634670e-03  8.262413e-03  1.900680e-05  3.160353e-02   \n",
      "11     1.910625e-07  7.067405e-06  8.625801e-08  1.309229e-03  5.988287e-05   \n",
      "12     2.838764e-03  7.744907e-05  2.544082e-02  1.613936e-02  3.008023e-03   \n",
      "13     5.118451e-07  1.601906e-05  2.465016e-05  2.103644e-07  1.527690e-05   \n",
      "14     9.348182e-05  6.873834e-02  4.080496e-03  1.661694e-03  3.461618e-07   \n",
      "15     1.458718e-07  3.938836e-08  2.832006e-06  6.201211e-05  4.367910e-05   \n",
      "16     1.668324e-05  5.638775e-06  4.914691e-03  1.656613e-04  1.643242e-06   \n",
      "17     7.265532e-04  4.311194e-07  3.747905e-04  2.169632e-06  8.074357e-03   \n",
      "18     4.367910e-05  5.061780e-06  9.255406e-03  4.119891e-04  1.570318e-02   \n",
      "19     8.485257e-06  2.797955e-03  1.292190e-02  3.832499e-03  2.799359e-06   \n",
      "20     4.799982e-02  5.080490e-08  1.944765e-02  2.322828e-05  7.100912e-04   \n",
      "21     5.593029e-04  1.224791e-02  7.522586e-03  7.435906e-04  1.051494e-06   \n",
      "22     1.552050e-02  7.739763e-03  4.532391e-05  4.952504e-03  1.273914e-06   \n",
      "23     2.353367e-02  1.043934e-05  1.428847e-02  3.030268e-04  6.279333e-03   \n",
      "24     2.315303e-04  1.152906e-05  1.860035e-05  1.579933e-05  1.077885e-05   \n",
      "label  9.540439e-18  6.158091e-17  1.343350e-14  2.256057e-21  1.451369e-17   \n",
      "\n",
      "       ...            16            17            18            19  \\\n",
      "0      ...  9.874822e-02  9.585636e-04  7.220581e-07  1.204965e-09   \n",
      "1      ...  1.533144e-01  2.030335e-03  1.616932e-04  5.670869e-04   \n",
      "2      ...  2.829759e-05  1.948431e-03  7.716929e-06  7.889184e-05   \n",
      "3      ...  1.682321e-03  8.074357e-03  1.175444e-04  7.877721e-05   \n",
      "4      ...  7.322631e-04  3.852702e-03  1.446269e-01  7.877721e-05   \n",
      "5      ...  1.668324e-05  7.265532e-04  4.367910e-05  8.485257e-06   \n",
      "6      ...  5.638775e-06  4.311194e-07  5.061780e-06  2.797955e-03   \n",
      "7      ...  4.914691e-03  3.747905e-04  9.255406e-03  1.292190e-02   \n",
      "8      ...  1.656613e-04  2.169632e-06  4.119891e-04  3.832499e-03   \n",
      "9      ...  1.643242e-06  8.074357e-03  1.570318e-02  2.799359e-06   \n",
      "10     ...  2.749060e-02  4.201474e-03  1.753019e-03  8.120487e-03   \n",
      "11     ...  4.644435e-03  1.623247e-04  1.613945e-04  1.841268e-03   \n",
      "12     ...  1.181227e-03  5.802493e-04  5.521421e-04  2.470680e-02   \n",
      "13     ...  1.807847e-06  2.960988e-04  1.328498e-07  2.797955e-03   \n",
      "14     ...  2.559912e-04  3.713281e-01  2.177566e-02  1.466496e-05   \n",
      "15     ...  4.333622e-08  1.469452e-06  4.721018e-07  2.646975e-06   \n",
      "16     ...  0.000000e+00  4.378457e-07  7.600508e-03  2.060736e-07   \n",
      "17     ...  4.378457e-07  0.000000e+00  1.161533e-04  5.870830e-04   \n",
      "18     ...  7.600508e-03  1.161533e-04  0.000000e+00  2.127564e-01   \n",
      "19     ...  2.060736e-07  5.870830e-04  2.127564e-01  0.000000e+00   \n",
      "20     ...  1.314436e-01  6.882063e-03  2.960817e-04  1.559945e-04   \n",
      "21     ...  2.886771e-03  6.198105e-03  8.518352e-05  1.984631e-02   \n",
      "22     ...  1.162436e-06  7.902680e-04  7.405398e-04  3.238566e-05   \n",
      "23     ...  2.190880e-04  1.299622e-02  8.425571e-05  5.211976e-03   \n",
      "24     ...  2.941257e-03  2.135400e-04  3.215208e-07  2.027986e-03   \n",
      "label  ...  9.111759e-19  3.175665e-18  1.451369e-17  1.406251e-17   \n",
      "\n",
      "                 20            21            22            23            24  \\\n",
      "0      9.647765e-07  1.214514e-04  5.247314e-07  1.563651e-06  1.679741e-05   \n",
      "1      1.159942e-03  3.664913e-03  1.632383e-02  7.264199e-03  1.927500e-07   \n",
      "2      4.512430e-07  3.129102e-04  3.668297e-03  1.127982e-04  1.591936e-08   \n",
      "3      1.520468e-07  2.366079e-02  4.248575e-06  2.880610e-07  3.118217e-10   \n",
      "4      1.718742e-06  5.541463e-04  1.753019e-03  1.251053e-01  5.502908e-04   \n",
      "5      4.799982e-02  5.593029e-04  1.552050e-02  2.353367e-02  2.315303e-04   \n",
      "6      5.080490e-08  1.224791e-02  7.739763e-03  1.043934e-05  1.152906e-05   \n",
      "7      1.944765e-02  7.522586e-03  4.532391e-05  1.428847e-02  1.860035e-05   \n",
      "8      2.322828e-05  7.435906e-04  4.952504e-03  3.030268e-04  1.579933e-05   \n",
      "9      7.100912e-04  1.051494e-06  1.273914e-06  6.279333e-03  1.077885e-05   \n",
      "10     7.449096e-02  6.210759e-03  3.520156e-04  1.374007e-01  1.925190e-04   \n",
      "11     7.036056e-06  3.004118e-04  1.617341e-04  7.501834e-04  1.271081e-07   \n",
      "12     7.800089e-07  4.162575e-08  3.523605e-03  2.088865e-02  3.726670e-04   \n",
      "13     1.722039e-03  1.120696e-06  3.747614e-05  3.018781e-07  8.977596e-05   \n",
      "14     1.295104e-02  2.199304e-03  6.213037e-05  2.396027e-06  1.046840e-03   \n",
      "15     1.722039e-03  3.608534e-06  3.747614e-05  1.043934e-05  2.906761e-03   \n",
      "16     1.314436e-01  2.886771e-03  1.162436e-06  2.190880e-04  2.941257e-03   \n",
      "17     6.882063e-03  6.198105e-03  7.902680e-04  1.299622e-02  2.135400e-04   \n",
      "18     2.960817e-04  8.518352e-05  7.405398e-04  8.425571e-05  3.215208e-07   \n",
      "19     1.559945e-04  1.984631e-02  3.238566e-05  5.211976e-03  2.027986e-03   \n",
      "20     0.000000e+00  1.167519e-02  2.914449e-03  1.058172e-05  1.492151e-06   \n",
      "21     1.167519e-02  0.000000e+00  1.264117e-03  6.246849e-02  2.233358e-03   \n",
      "22     2.914449e-03  1.264117e-03  0.000000e+00  5.608123e-04  1.176994e-03   \n",
      "23     1.058172e-05  6.246849e-02  5.608123e-04  0.000000e+00  2.155693e-05   \n",
      "24     1.492151e-06  2.233358e-03  1.176994e-03  2.155693e-05  0.000000e+00   \n",
      "label  9.552035e-17  7.946213e-16  4.526507e-17  1.986187e-16  2.007208e-18   \n",
      "\n",
      "              label  \n",
      "0      2.444282e-26  \n",
      "1      1.766031e-18  \n",
      "2      3.795908e-22  \n",
      "3      4.032416e-20  \n",
      "4      1.918277e-14  \n",
      "5      9.540439e-18  \n",
      "6      6.158091e-17  \n",
      "7      1.343350e-14  \n",
      "8      2.256057e-21  \n",
      "9      1.451369e-17  \n",
      "10     3.372956e-13  \n",
      "11     1.007263e-17  \n",
      "12     4.321467e-16  \n",
      "13     4.231614e-22  \n",
      "14     7.971032e-19  \n",
      "15     4.231614e-22  \n",
      "16     9.111759e-19  \n",
      "17     3.175665e-18  \n",
      "18     1.451369e-17  \n",
      "19     1.406251e-17  \n",
      "20     9.552035e-17  \n",
      "21     7.946213e-16  \n",
      "22     4.526507e-17  \n",
      "23     1.986187e-16  \n",
      "24     2.007208e-18  \n",
      "label  0.000000e+00  \n",
      "\n",
      "[26 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "    \n",
    "chi_squared_fvf(categorical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "daf01a4b-be58-4adc-8150-409d15586536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------Chi-Square (F vs label column)------------------------\n",
      "Label: label\n",
      " Feature  Chi Squared Statistic  P-Value\n",
      "       0                  319.0 0.473672\n",
      "       1                  319.0 0.473672\n",
      "       2                  319.0 0.473672\n",
      "       3                  319.0 0.473672\n",
      "       4                  319.0 0.473672\n",
      "       5                  319.0 0.473672\n",
      "       6                  319.0 0.473672\n",
      "       7                  319.0 0.473672\n",
      "       8                  319.0 0.473672\n",
      "       9                  319.0 0.473672\n",
      "      10                  319.0 0.473672\n",
      "      11                  319.0 0.473672\n",
      "      12                  319.0 0.473672\n",
      "      13                  319.0 0.473672\n",
      "      14                  319.0 0.473672\n",
      "      15                  319.0 0.473672\n",
      "      16                  319.0 0.473672\n",
      "      17                  319.0 0.473672\n",
      "      18                  319.0 0.473672\n",
      "      19                  319.0 0.473672\n",
      "      20                  319.0 0.473672\n",
      "      21                  319.0 0.473672\n",
      "      22                  319.0 0.473672\n",
      "      23                  319.0 0.473672\n",
      "      24                  319.0 0.473672\n"
     ]
    }
   ],
   "source": [
    "##################### Chi-Square (F vs label column) Code ####################################\n",
    "    \n",
    "print(\"\\n------------------------Chi-Square (F vs label column)------------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train & the label in y_train\n",
    "def chi_squared_fvl(X_train_categorical, y_train):\n",
    "        \n",
    "    # Combining CATEGORICAL X_train and y_train\n",
    "    df = X_train_categorical\n",
    "    df['label'] = y_train\n",
    "\n",
    "    # Number of features, excluding label\n",
    "    var_count = len(df.columns)-1\n",
    "\n",
    "    # Creates an empty array to print values in a table\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, var_count):\n",
    "\n",
    "        # Create contigency table of all features v. label\n",
    "        crosstab = pd.crosstab(df.iloc[:, i], df.iloc[:,-1])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(crosstab)[0]\n",
    "        p = stats.chi2_contingency(crosstab)[1]\n",
    "            \n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            \"Feature\": df.columns[i],\n",
    "            \"Chi Squared Statistic\": chi2,\n",
    "            \"P-Value\": p})\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(\"Label:\", df.columns.values[-1])\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "chi_squared_fvl(categorical_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f846b9ff-17ad-43f3-8004-fd790ae6f558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ ANOVA (Feature vs Feature) -----------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_col \u001b[38;5;129;01min\u001b[39;00m numerical_df:\n\u001b[1;32m     10\u001b[0m     groups \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m X_train[cat_col]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m     12\u001b[0m         groups\u001b[38;5;241m.\u001b[39mappend(X_train[num_col][X_train[cat_col] \u001b[38;5;241m==\u001b[39m category])\n\u001b[1;32m     13\u001b[0m     f_statistic, p_value \u001b[38;5;241m=\u001b[39m f_oneway(\u001b[38;5;241m*\u001b[39mgroups)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "############################# ANOVA (Feature vs Feature) #########################################\n",
    "\n",
    "print(\"\\n------------------ ANOVA (Feature vs Feature) -----------------------\")\n",
    "# Initialize an empty DataFrame to store ANOVA results\n",
    "anova_results = pd.DataFrame(index=categorical_df.columns, columns=numerical_df.columns)\n",
    "\n",
    "# Perform ANOVA for each combination of categorical and numerical columns\n",
    "for cat_col in categorical_df:\n",
    "    for num_col in numerical_df:\n",
    "        groups = []\n",
    "        for category in X_train[cat_col].unique():\n",
    "            groups.append(X_train[num_col][X_train[cat_col] == category])\n",
    "        f_statistic, p_value = f_oneway(*groups)\n",
    "        anova_results.loc[cat_col, num_col] = f_statistic, p_value\n",
    "\n",
    "# Create a formatted DataFrame for ANOVA results with labeled interpretation\n",
    "formatted_results = pd.DataFrame(index=categorical_df.columns, columns=numerical_df.columns)\n",
    "for num_col in numerical_df:\n",
    "    for cat_col in categorical_df:\n",
    "        f_statistic, p_value = anova_results.loc[cat_col, num_col]\n",
    "        if p_value < 0.05:\n",
    "            significance = \"Significant\"\n",
    "        else:\n",
    "            significance = \"Not Significant\"\n",
    "        formatted_results.loc[cat_col, num_col] = f\"F = {f_statistic:.2f}, p = {p_value:.4f} ({significance})\"\n",
    "\n",
    "# Display formatted ANOVA results as a table\n",
    "print(formatted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b33d6-fa2d-4b3a-9c3f-c60adeb395c8",
   "metadata": {},
   "source": [
    "# ANOVA FEATURE VS LABEL (PENDING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2aa2b78a-aaff-40bd-bee3-3c75df34dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ ANOVA (Feature vs Label) -----------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gq/wfvm6zt96_vgyjdb9mtbd22w0000gn/T/ipykernel_14817/1933457199.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Perform ANOVA for each feature column against the target column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_col\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_column\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# Skip the target column itself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mf_statistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_oneway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0manova_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"F = {f_statistic:.2f}, p = {p_value:.4f}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "############################# ANOVA (Feature vs Label) #############################\n",
    "print(\"\\n------------------ ANOVA (Feature vs Label) -----------------------\")\n",
    "# Concatenate X_train and y_train into a single DataFrame for ANOVA comparison\n",
    "data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Automatically detect all columns as features (numerical and categorical)\n",
    "all_columns = data.columns\n",
    "\n",
    "# Identify the last column as the target column\n",
    "target_column = all_columns[-1]\n",
    "\n",
    "# Initialize an empty DataFrame to store ANOVA results\n",
    "anova_results = pd.DataFrame(index=[target_column], columns=all_columns)\n",
    "\n",
    "# Perform ANOVA for each feature column against the target column\n",
    "for feature_col in all_columns:\n",
    "    if feature_col == target_column:\n",
    "        continue  # Skip the target column itself\n",
    "    groups = [data[feature_col][data[target_column] == value] for value in data[target_column].unique()]\n",
    "    f_statistic, p_value = f_oneway(*groups)\n",
    "    anova_results.loc[target_column, feature_col] = f\"F = {f_statistic:.2f}, p = {p_value:.4f}\"\n",
    "\n",
    "# Print ANOVA results for each feature with significance indication\n",
    "print(\"ANOVA Results:\")\n",
    "for feature_col in anova_results.columns[:-1]:  # Exclude the last column (target column)\n",
    "    result = anova_results.loc[target_column, feature_col]\n",
    "    f_statistic, p_value = result.split(', ')\n",
    "    f_statistic = float(f_statistic.split(' = ')[1])\n",
    "    p_value = float(p_value.split(' = ')[1])\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        significance = \"Significant\"\n",
    "    else:\n",
    "        significance = \"Not Significant\"\n",
    "    \n",
    "    print(f\"{feature_col}: {result} ({significance})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d36b6-ba30-4221-863a-ef9d6805c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Histogram/Graphing ###############################\n",
    "\n",
    "print(\"------------------------Histogram/Graphing-----------------------------\")\n",
    "\n",
    "\n",
    "###### These are just here for now so the histogram and bar graph functions work\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = [\"float64\"])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float64'])\n",
    "        \n",
    "\n",
    "# Ensure data is 2D\n",
    "if numerical_df.ndim == 1:\n",
    "    numerical_df = numerical_df.reshape(-1, 1)  # Reshape 1D array to 2D array with one column\n",
    "\n",
    "# Number of features (columns) in the dataset\n",
    "numerical_num_features = numerical_df.shape[1]\n",
    "\n",
    "\n",
    "# Loop through each numerical feature\n",
    "for feature_idx in range(numerical_num_features):\n",
    "    # Extract the current feature data (column)\n",
    "    feature_df = numerical_df.iloc[:, feature_idx]\n",
    "\n",
    "    # Compute histogram with 10 bins\n",
    "    hist, bin_edges = np.histogram(feature_df, bins=10)\n",
    "\n",
    "    # Print feature number\n",
    "    print(f\"Feature {feature_idx + 1}:\")\n",
    "    \n",
    "    # Print bin edges\n",
    "    print(\"Bin Edges:\", bin_edges)\n",
    "\n",
    "    # Store bin heights in a list\n",
    "    bin_heights = []\n",
    "    bin_heights.extend(hist)\n",
    "    print(\"Array with bin heights:\", bin_heights)\n",
    "\n",
    "    # Store bin probabilities in a list and normalize\n",
    "    bin_probs = []\n",
    "    bin_probs.extend(hist)\n",
    "    bin_probs = np.array(bin_probs) / sum(bin_heights)\n",
    "    print(\"Array with bin probabilities:\", bin_probs)\n",
    "\n",
    "    # Loop through each bin to print range and probabilities\n",
    "    for i in range(len(hist)):\n",
    "        bin_range = f\"{bin_edges[i]:.2f} to {bin_edges[i+1]:.2f}\"  # Bin range\n",
    "        bin_probability = hist[i] / sum(hist)  # Bin probability\n",
    "        print(f\"Bin {i + 1} ({bin_range}): Height = {hist[i]}, Probability = {bin_probability:.2f}\")\n",
    "\n",
    "    # Separator between features for clarity\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Calculate and store probabilities for each categorical column\n",
    "print(\"Proportions for Label for Categorical Columns:\")\n",
    "\n",
    "for column in categorical_df.columns:\n",
    "    value_counts = categorical_df[column].value_counts(normalize=True).sort_index()\n",
    "    # print(f\"Probabilities for Categorical Column {column}:\")\n",
    "    print(value_counts)\n",
    "    print()  # Add an empty line for separation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fdbad-47f3-4fd8-8b9a-f8810771c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ KL Divergence ####################################\n",
    "\n",
    "optional_test = []\n",
    "\n",
    "for i in range(151):\n",
    "    optional_test.append(bool(random.getrandbits(1)))\n",
    "\n",
    "# Call the measure_patterns function\n",
    "Measure_Patterns(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311c09e-3c45-4309-b2a7-4f5646164748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
