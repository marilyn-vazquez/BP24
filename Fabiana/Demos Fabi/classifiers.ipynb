{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975e2c1f-5e05-4835-801d-4263aae6f310",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39179e0a-ebed-4582-907a-5fe57bff1559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.604431</td>\n",
       "      <td>0.724054</td>\n",
       "      <td>1.295053</td>\n",
       "      <td>0.495865</td>\n",
       "      <td>0.607451</td>\n",
       "      <td>0.547615</td>\n",
       "      <td>0.564150</td>\n",
       "      <td>0.468880</td>\n",
       "      <td>0.420394</td>\n",
       "      <td>0.910129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660629</td>\n",
       "      <td>1.325968</td>\n",
       "      <td>1.282151</td>\n",
       "      <td>0.600550</td>\n",
       "      <td>0.592177</td>\n",
       "      <td>0.776711</td>\n",
       "      <td>1.085891</td>\n",
       "      <td>1.153748</td>\n",
       "      <td>1.352572</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.180423</td>\n",
       "      <td>1.391002</td>\n",
       "      <td>1.184481</td>\n",
       "      <td>0.583052</td>\n",
       "      <td>1.210490</td>\n",
       "      <td>0.923676</td>\n",
       "      <td>1.185203</td>\n",
       "      <td>1.369972</td>\n",
       "      <td>1.201448</td>\n",
       "      <td>0.614857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892705</td>\n",
       "      <td>0.848612</td>\n",
       "      <td>1.298801</td>\n",
       "      <td>1.250497</td>\n",
       "      <td>0.547771</td>\n",
       "      <td>1.215082</td>\n",
       "      <td>0.940952</td>\n",
       "      <td>1.109552</td>\n",
       "      <td>1.181372</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.067779</td>\n",
       "      <td>0.718696</td>\n",
       "      <td>0.798901</td>\n",
       "      <td>1.369462</td>\n",
       "      <td>0.470935</td>\n",
       "      <td>0.566282</td>\n",
       "      <td>1.398846</td>\n",
       "      <td>1.015372</td>\n",
       "      <td>0.801271</td>\n",
       "      <td>1.330270</td>\n",
       "      <td>...</td>\n",
       "      <td>1.339399</td>\n",
       "      <td>0.417466</td>\n",
       "      <td>0.496915</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.875185</td>\n",
       "      <td>1.293924</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>0.742218</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.368247</td>\n",
       "      <td>0.730771</td>\n",
       "      <td>0.134119</td>\n",
       "      <td>0.984532</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.470181</td>\n",
       "      <td>0.025061</td>\n",
       "      <td>0.648142</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>0.973801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086188</td>\n",
       "      <td>0.394613</td>\n",
       "      <td>0.252668</td>\n",
       "      <td>0.808593</td>\n",
       "      <td>0.587922</td>\n",
       "      <td>0.827502</td>\n",
       "      <td>0.862651</td>\n",
       "      <td>0.684517</td>\n",
       "      <td>0.149873</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.919760</td>\n",
       "      <td>0.577797</td>\n",
       "      <td>0.441661</td>\n",
       "      <td>0.862139</td>\n",
       "      <td>0.263016</td>\n",
       "      <td>0.393494</td>\n",
       "      <td>0.635624</td>\n",
       "      <td>0.657747</td>\n",
       "      <td>0.781920</td>\n",
       "      <td>0.566910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816635</td>\n",
       "      <td>0.319880</td>\n",
       "      <td>0.770176</td>\n",
       "      <td>0.919029</td>\n",
       "      <td>0.265299</td>\n",
       "      <td>0.983398</td>\n",
       "      <td>0.956898</td>\n",
       "      <td>0.175083</td>\n",
       "      <td>0.170124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.604431  0.724054  1.295053  0.495865  0.607451  0.547615  0.564150   \n",
       "1  1.180423  1.391002  1.184481  0.583052  1.210490  0.923676  1.185203   \n",
       "2  1.067779  0.718696  0.798901  1.369462  0.470935  0.566282  1.398846   \n",
       "3  0.368247  0.730771  0.134119  0.984532  0.397524  0.470181  0.025061   \n",
       "4  0.919760  0.577797  0.441661  0.862139  0.263016  0.393494  0.635624   \n",
       "\n",
       "        7         8         9    ...       141       142       143       144  \\\n",
       "0  0.468880  0.420394  0.910129  ...  0.660629  1.325968  1.282151  0.600550   \n",
       "1  1.369972  1.201448  0.614857  ...  0.892705  0.848612  1.298801  1.250497   \n",
       "2  1.015372  0.801271  1.330270  ...  1.339399  0.417466  0.496915  0.661756   \n",
       "3  0.648142  0.016333  0.973801  ...  0.086188  0.394613  0.252668  0.808593   \n",
       "4  0.657747  0.781920  0.566910  ...  0.816635  0.319880  0.770176  0.919029   \n",
       "\n",
       "        145       146       147       148       149  150  \n",
       "0  0.592177  0.776711  1.085891  1.153748  1.352572  1.0  \n",
       "1  0.547771  1.215082  0.940952  1.109552  1.181372  1.0  \n",
       "2  0.875185  1.293924  0.750581  0.742218  0.993983  1.0  \n",
       "3  0.587922  0.827502  0.862651  0.684517  0.149873  0.0  \n",
       "4  0.265299  0.983398  0.956898  0.175083  0.170124  0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#load dataset\n",
    "#data = np.loadtxt(\"uniform_small_d_1.tex\")\n",
    "data = np.loadtxt(\"uniform_large_d_1.tex\")\n",
    "#data = np.loadtxt(\"gaussian_small_d_1.tex\")\n",
    "#data = np.loadtxt(\"gaussian_large_d_1.tex\")\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df = pd.DataFrame(array)\n",
    "\n",
    "# Look at data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47374f2a-42f2-4690-9035-3d6086010171",
   "metadata": {},
   "source": [
    "# Convert dataset to 'categorical' and 'numerical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42db5971-5001-4ee9-8742-201d0d6b700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 25 columns from numerical floats -> categorical integers\n",
    "for i in range(25):\n",
    "    \n",
    "    df.iloc[:,i] = df.iloc[:,i].round() # Rounding\n",
    "    df.iloc[:,i] = df.iloc[:,i].astype(int) # Integer\n",
    "    df.iloc[:,i] = df.iloc[:,i].astype('category') # Categories\n",
    "    \n",
    "# Turn label into categorical label\n",
    "df.iloc[:,150] = df.iloc[:,150].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee4c61bf-8320-4d97-badf-75d933daa5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660629</td>\n",
       "      <td>1.325968</td>\n",
       "      <td>1.282151</td>\n",
       "      <td>0.600550</td>\n",
       "      <td>0.592177</td>\n",
       "      <td>0.776711</td>\n",
       "      <td>1.085891</td>\n",
       "      <td>1.153748</td>\n",
       "      <td>1.352572</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892705</td>\n",
       "      <td>0.848612</td>\n",
       "      <td>1.298801</td>\n",
       "      <td>1.250497</td>\n",
       "      <td>0.547771</td>\n",
       "      <td>1.215082</td>\n",
       "      <td>0.940952</td>\n",
       "      <td>1.109552</td>\n",
       "      <td>1.181372</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.339399</td>\n",
       "      <td>0.417466</td>\n",
       "      <td>0.496915</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.875185</td>\n",
       "      <td>1.293924</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>0.742218</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086188</td>\n",
       "      <td>0.394613</td>\n",
       "      <td>0.252668</td>\n",
       "      <td>0.808593</td>\n",
       "      <td>0.587922</td>\n",
       "      <td>0.827502</td>\n",
       "      <td>0.862651</td>\n",
       "      <td>0.684517</td>\n",
       "      <td>0.149873</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816635</td>\n",
       "      <td>0.319880</td>\n",
       "      <td>0.770176</td>\n",
       "      <td>0.919029</td>\n",
       "      <td>0.265299</td>\n",
       "      <td>0.983398</td>\n",
       "      <td>0.956898</td>\n",
       "      <td>0.175083</td>\n",
       "      <td>0.170124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...       141       142  \\\n",
       "0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0  ...  0.660629  1.325968   \n",
       "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  0.892705  0.848612   \n",
       "2  1.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  ...  1.339399  0.417466   \n",
       "3  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  0.086188  0.394613   \n",
       "4  1.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  ...  0.816635  0.319880   \n",
       "\n",
       "        143       144       145       146       147       148       149  150  \n",
       "0  1.282151  0.600550  0.592177  0.776711  1.085891  1.153748  1.352572  1.0  \n",
       "1  1.298801  1.250497  0.547771  1.215082  0.940952  1.109552  1.181372  1.0  \n",
       "2  0.496915  0.661756  0.875185  1.293924  0.750581  0.742218  0.993983  1.0  \n",
       "3  0.252668  0.808593  0.587922  0.827502  0.862651  0.684517  0.149873  0.0  \n",
       "4  0.770176  0.919029  0.265299  0.983398  0.956898  0.175083  0.170124  0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cd94e-5734-4ad0-84a4-26261dcc3970",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1bb13f3-63e8-4849-aaca-82a08a8ce06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:150], df.iloc[:,-1], test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983d27b7-a27a-45a2-b7da-812d4645eb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159    0.0\n",
       "198    1.0\n",
       "259    1.0\n",
       "301    1.0\n",
       "220    0.0\n",
       "      ... \n",
       "86     0.0\n",
       "151    1.0\n",
       "13     1.0\n",
       "267    0.0\n",
       "156    0.0\n",
       "Name: 150, Length: 400, dtype: category\n",
       "Categories (2, float64): [0.0, 1.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c8cb0-be5d-46d3-bdd1-b589aea83e3f",
   "metadata": {},
   "source": [
    "# XG-BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b556a05d-cddb-48dc-9228-890e7857dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "# First, put this prompt: \"conda install -c conda-forge py-xgboost\" in anaconda to download xgboost package\n",
    "# install xgboost in jupyter\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8486047d-e245-44b0-b266-223cf1d04aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
      " 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1\n",
      " 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1]\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# import the classifier from the xgboost package\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# read data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# create model instance\n",
    "# n_estimators: number of trees(estimators) the model uses --> the more used, the more accurate the model is\n",
    "# max_depth: maximum depth of tree --> higher number makes model more complex, but too high can cause overfitting\n",
    "# learning_rate: quantifies each tree's contribution to total prediction --> lower number takes longer, but can lead to better generalization\n",
    "# objective: binary:logistic outputs probabilities. if classification is wanted, use binary:hinge\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic', enable_categorical=True)\n",
    "\n",
    "# fit model with the training data\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for the test dataset\n",
    "preds = bst.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(preds)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd9727-fa96-4eed-84fd-ab332fee941d",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9815a9c1-2ef9-468e-a32b-15eee40f443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "#Create a svm Classifier\n",
    "# kernel: options for kernel include linear, poly, rbf, sigmoid\n",
    "    # linear: use this when data can be split by a linear function\n",
    "    # poly (polynomial): use this when data can be split by a polynomial function\n",
    "    # rbf (radial basis function): use this when there are clusters of one class inside another\n",
    "    # sigmoid: use this when the split between classes is curved and irregular\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(y_pred)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbb0a4-af3e-4f69-84aa-258df7d433b1",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a30467-013d-4449-beeb-9d53774928c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#import knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#create a knn classifier\n",
    "#n_neighbors: predicting the label of the data point by looking at the 3 closest data points and getting them to \"vote\"\n",
    "#algorithm: we may need to look at this if it misbehaves\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#train the model using the training sets\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "#predict the response for the test dataset\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "#print predictions\n",
    "print(y_pred)\n",
    "\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a38be0-c339-4bc9-ba85-450adfd743f3",
   "metadata": {},
   "source": [
    "# FIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0eb0c28-3b5a-4cea-a2b9-eb11d65d1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Authors: Balachander S, Prahalad Srinivas C G, Yogesh Chandra Singh Samant, B Varshin Hariharan\n",
    "'''\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#import scikit learn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc=0.01,classifier='DesicionTree',bias=[],control=None,n_jobs=None,random_state=None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f81e26-2ab8-432b-8a76-bb023a2c9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "[0, 2, 120, 137, 85, 100, 13, 15, 34, 73, 39, 106, 8, 65, 90, 91, 55, 97, 61, 149, 126, 99, 49, 47, 76, 42, 102, 67, 14, 124, 127, 60, 138, 25, 28, 3, 114, 29, 1, 112, 125, 16, 88, 98, 146, 33, 117, 105, 72, 140, 143, 122, 24, 83, 115, 95, 107, 59, 52, 80, 36, 63, 64, 111, 37, 44, 101, 27, 103, 121, 130, 20, 129, 135, 69, 5, 62, 139, 147, 31, 113, 68, 142, 17, 48, 104, 92, 79, 94, 109, 9, 18, 89, 11, 82, 118, 54, 35, 141, 6, 75, 116, 119, 74, 40, 53, 41, 70, 93, 77, 32, 148, 26, 71, 132, 133, 51, 23, 43, 86, 19, 87, 45, 21, 56, 84, 145, 22, 57, 78, 46, 7, 66, 50, 30, 110, 81, 12, 96, 134, 136, 128, 4, 58, 38, 144, 108, 131, 123, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(DecisionTreeClassifier(max_depth=3), 35.3826714801444, 0),\n",
       " (DecisionTreeClassifier(max_depth=3), 31.582089552238806, 2),\n",
       " (DecisionTreeClassifier(max_depth=3), 30.64785141254948, 120),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.7060595004451, 137),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.361849176904997, 85),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.176838266946696, 100),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.136690647482013, 13),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.136690647482013, 15),\n",
       " (DecisionTreeClassifier(max_depth=3), 28.4108943265348, 34),\n",
       " (DecisionTreeClassifier(max_depth=3), 28.345919382078073, 73),\n",
       " (DecisionTreeClassifier(max_depth=3), 28.257501104288405, 39),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.70165781193473, 106),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.65714285714286, 8),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.351735160862674, 65),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.11795596995177, 90),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.095244307812784, 91),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.03372399774386, 55),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.90734722680694, 97),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.801080346879342, 61),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.752005567908995, 149),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.5301362782941, 126),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.521582323354384, 99),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.26724970591146, 49),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.20224979923976, 47),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.20108925249272, 76),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.16639351640911, 42),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.161951515795938, 102),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.145554728654506, 67),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.133333333333333, 14),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.125065617574435, 124),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.109239817876535, 127),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.98127801218135, 60),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.893434456691093, 138),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.73589818979655, 25),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.716135866874236, 28),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.71174377224199, 3),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.690568860296203, 114),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.455843865897688, 29),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.420664206642066, 1),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.413143085195728, 112),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.297859817159424, 125),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.05090909090909, 16),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.932032039043648, 88),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.865339945661958, 98),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.853199716582637, 146),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.836643533492037, 33),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.771208536813045, 117),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.58085952176841, 105),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.53021549959054, 72),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.497406947177105, 140),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.459300880519606, 143),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.385136511820072, 122),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.36231884057971, 24),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.347732033915275, 83),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.318395752966936, 115),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.287402293702, 95),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.242758172197455, 107),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.006430255688603, 59),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.941007871743714, 52),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.898888453831702, 80),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.891750748788922, 36),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.80672386911857, 63),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.806668404527393, 64),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.797152873426477, 111),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.769712130982633, 37),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.697008894927823, 44),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.66066965581271, 101),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.599569548927086, 27),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.554499132678608, 103),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.523257016010177, 121),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.43272764621396, 130),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.200743494423794, 20),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.142609761639925, 129),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.066021513919253, 135),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.03785702081052, 69),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.02158273381295, 5),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.993180685184605, 62),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.969056727588736, 139),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.947704971966882, 147),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.75756760478628, 31),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.739809330365183, 113),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.65583437131976, 68),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.536652761664037, 142),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.535211267605632, 17),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.52204690774029, 48),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.508182318723907, 104),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.354425615491973, 92),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.342206231405438, 79),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.264717591665622, 94),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.221464329253394, 109),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.209964412811388, 9),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.209964412811388, 18),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.142558189656604, 89),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.053003533568905, 11),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.044533732221232, 82),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.017056563696478, 118),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.94903310930454, 54),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.930966604409868, 35),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.92352613971728, 141),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.884892086330936, 6),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.854632672653132, 75),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.78811873323197, 116),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.72304713267495, 119),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.54636482235538, 74),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.535499004032694, 40),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.500345464775897, 53),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.42064265949685, 41),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.37098844217879, 70),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.22537222660368, 93),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.195604981057386, 77),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.124337337115733, 32),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.07850785298416, 148),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.71484860422597, 26),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.652578017610914, 71),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.5596336260828, 132),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.514213749340463, 133),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.48958472915465, 51),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.4822695035461, 23),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.458395414740107, 43),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.44400909427341, 86),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.374570446735394, 19),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.3511766181633, 87),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.34621933703229, 45),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.161290322580644, 21),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.123707869459665, 56),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.108676702247966, 84),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.997522946044725, 145),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.917241379310344, 22),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.85117368840305, 57),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.815610525074803, 78),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.728321971786833, 46),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.66420664206642, 7),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.5686980869652, 66),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.4570267417468, 50),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.277449699482613, 30),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.086009152579997, 110),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.044664031471108, 81),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.01388888888889, 12),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.998363297367618, 96),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.80120086080076, 134),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.43059475873974, 136),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.271066799140876, 128),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.939501779359432, 4),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.766386216041763, 58),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.67541648572722, 38),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.497488114109178, 144),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.479292636210666, 108),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.83365567738565, 131),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.237949425183977, 123),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.020689655172413, 10)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model using the training sets\n",
    "clf1=FeatureClassifier(0,classifier='DecisionTree',control=3)\n",
    "# clf1.fit(X_train,y_train.reshape(-1,1))\n",
    "clf1.fit(np.array(X_train), np.array(y_train)[:,np.newaxis].astype(int))\n",
    "\n",
    "#predict the response for the test dataset\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(np.array(y_test).astype(int),clf1.predict(np.array(X_test))))\n",
    "\n",
    "print(clf1.indexLs)\n",
    "clf1.featureClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798dc440-8385-445d-a850-c15708bf30fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
