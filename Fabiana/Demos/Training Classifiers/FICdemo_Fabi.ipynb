{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adc2afd-c1c3-4074-9ab1-1820c797c3b2",
   "metadata": {},
   "source": [
    "# FIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a65ec5d6-3ebe-45d9-a36e-a9a58a17f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Authors: Balachander S, Prahalad Srinivas C G, Yogesh Chandra Singh Samant, B Varshin Hariharan\n",
    "'''\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#import scikit learn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc=0.01,classifier='DesicionTree',bias=[],control=None,n_jobs=None,random_state=None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e6619e2-1fcc-48a3-964d-8bce726ab58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is what I implemented --Fabi\n",
    "#load dataset\n",
    "data = np.loadtxt(\"uniform_large_d_1.tex\")\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df_table = pd.DataFrame(array)\n",
    "\n",
    "# Displaying the table\n",
    "#print(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95577d76-1181-45e2-85b8-30dfe82bb815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660629</td>\n",
       "      <td>1.325968</td>\n",
       "      <td>1.282151</td>\n",
       "      <td>0.600550</td>\n",
       "      <td>0.592177</td>\n",
       "      <td>0.776711</td>\n",
       "      <td>1.085891</td>\n",
       "      <td>1.153748</td>\n",
       "      <td>1.352572</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892705</td>\n",
       "      <td>0.848612</td>\n",
       "      <td>1.298801</td>\n",
       "      <td>1.250497</td>\n",
       "      <td>0.547771</td>\n",
       "      <td>1.215082</td>\n",
       "      <td>0.940952</td>\n",
       "      <td>1.109552</td>\n",
       "      <td>1.181372</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.339399</td>\n",
       "      <td>0.417466</td>\n",
       "      <td>0.496915</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.875185</td>\n",
       "      <td>1.293924</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>0.742218</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086188</td>\n",
       "      <td>0.394613</td>\n",
       "      <td>0.252668</td>\n",
       "      <td>0.808593</td>\n",
       "      <td>0.587922</td>\n",
       "      <td>0.827502</td>\n",
       "      <td>0.862651</td>\n",
       "      <td>0.684517</td>\n",
       "      <td>0.149873</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816635</td>\n",
       "      <td>0.319880</td>\n",
       "      <td>0.770176</td>\n",
       "      <td>0.919029</td>\n",
       "      <td>0.265299</td>\n",
       "      <td>0.983398</td>\n",
       "      <td>0.956898</td>\n",
       "      <td>0.175083</td>\n",
       "      <td>0.170124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...       141       142  \\\n",
       "0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0  ...  0.660629  1.325968   \n",
       "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  0.892705  0.848612   \n",
       "2  1.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  ...  1.339399  0.417466   \n",
       "3  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  0.086188  0.394613   \n",
       "4  1.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  ...  0.816635  0.319880   \n",
       "\n",
       "        143       144       145       146       147       148       149  150  \n",
       "0  1.282151  0.600550  0.592177  0.776711  1.085891  1.153748  1.352572  1.0  \n",
       "1  1.298801  1.250497  0.547771  1.215082  0.940952  1.109552  1.181372  1.0  \n",
       "2  0.496915  0.661756  0.875185  1.293924  0.750581  0.742218  0.993983  1.0  \n",
       "3  0.252668  0.808593  0.587922  0.827502  0.862651  0.684517  0.149873  0.0  \n",
       "4  0.770176  0.919029  0.265299  0.983398  0.956898  0.175083  0.170124  0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the dataset, change 25 columns to 'categorical'\n",
    "#Loop, converts floats to ints and then those ints to category\n",
    "for i in range(26):\n",
    "    df_table.iloc[:,i] = df_table.iloc[:,i].round()\n",
    "    df_table.iloc[:,i] = df_table.iloc[:,i].astype(int)\n",
    "    df_table.iloc[:,i] = df_table.iloc[:,i].astype(\"category\")\n",
    "\n",
    "df_table.iloc[:, 150] = df_table.iloc[:, 150].astype(\"category\")\n",
    "\n",
    "df_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cc7b1b1-2c0b-4ea1-9254-ff2ee40eeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training set and test set\n",
    "#test_size: in this case it is 70% training and 30% testing\n",
    "#random_state: sets a seed for a random number generator that splits the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_table.iloc[:,0:150], df_table.iloc[:,-1], test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97ef39bd-a115-4856-a4ea-25b12d82aab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "[0, 2, 120, 25, 137, 85, 100, 13, 15, 34, 73, 39, 106, 8, 65, 90, 91, 55, 97, 61, 149, 126, 99, 49, 47, 76, 42, 102, 67, 14, 124, 127, 60, 138, 28, 3, 114, 29, 1, 112, 125, 16, 88, 98, 146, 33, 117, 105, 72, 140, 143, 122, 24, 83, 115, 95, 107, 59, 52, 80, 36, 63, 64, 111, 37, 44, 101, 27, 103, 121, 130, 20, 129, 135, 69, 5, 62, 139, 147, 31, 113, 68, 142, 17, 48, 104, 92, 79, 94, 109, 9, 18, 89, 11, 82, 118, 54, 35, 141, 6, 75, 116, 119, 74, 40, 53, 41, 70, 93, 77, 32, 148, 26, 71, 132, 133, 51, 23, 43, 86, 19, 87, 45, 21, 56, 84, 145, 22, 57, 78, 46, 7, 66, 50, 30, 110, 81, 12, 96, 134, 136, 128, 4, 58, 38, 144, 108, 131, 123, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(DecisionTreeClassifier(max_depth=3), 35.3826714801444, 0),\n",
       " (DecisionTreeClassifier(max_depth=3), 31.582089552238806, 2),\n",
       " (DecisionTreeClassifier(max_depth=3), 30.64785141254948, 120),\n",
       " (DecisionTreeClassifier(max_depth=3), 30.488188976377952, 25),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.7060595004451, 137),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.361849176904997, 85),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.176838266946696, 100),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.136690647482013, 13),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.136690647482013, 15),\n",
       " (DecisionTreeClassifier(max_depth=3), 28.4108943265348, 34),\n",
       " (DecisionTreeClassifier(max_depth=3), 28.345919382078073, 73),\n",
       " (DecisionTreeClassifier(max_depth=3), 28.257501104288405, 39),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.70165781193473, 106),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.65714285714286, 8),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.351735160862674, 65),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.11795596995177, 90),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.095244307812784, 91),\n",
       " (DecisionTreeClassifier(max_depth=3), 27.03372399774386, 55),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.90734722680694, 97),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.801080346879342, 61),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.752005567908995, 149),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.5301362782941, 126),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.521582323354384, 99),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.26724970591146, 49),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.20224979923976, 47),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.20108925249272, 76),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.16639351640911, 42),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.161951515795938, 102),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.145554728654506, 67),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.133333333333333, 14),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.125065617574435, 124),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.109239817876535, 127),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.98127801218135, 60),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.893434456691093, 138),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.716135866874236, 28),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.71174377224199, 3),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.690568860296203, 114),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.455843865897688, 29),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.420664206642066, 1),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.413143085195728, 112),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.297859817159424, 125),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.05090909090909, 16),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.932032039043648, 88),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.865339945661958, 98),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.853199716582637, 146),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.836643533492037, 33),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.771208536813045, 117),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.58085952176841, 105),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.53021549959054, 72),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.497406947177105, 140),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.459300880519606, 143),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.385136511820072, 122),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.36231884057971, 24),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.347732033915275, 83),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.318395752966936, 115),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.287402293702, 95),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.242758172197455, 107),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.006430255688603, 59),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.941007871743714, 52),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.898888453831702, 80),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.891750748788922, 36),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.80672386911857, 63),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.806668404527393, 64),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.797152873426477, 111),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.769712130982633, 37),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.697008894927823, 44),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.66066965581271, 101),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.599569548927086, 27),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.554499132678608, 103),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.523257016010177, 121),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.43272764621396, 130),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.200743494423794, 20),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.142609761639925, 129),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.066021513919253, 135),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.03785702081052, 69),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.02158273381295, 5),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.993180685184605, 62),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.969056727588736, 139),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.947704971966882, 147),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.75756760478628, 31),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.739809330365183, 113),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.65583437131976, 68),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.536652761664037, 142),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.535211267605632, 17),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.52204690774029, 48),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.508182318723907, 104),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.354425615491973, 92),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.342206231405438, 79),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.264717591665622, 94),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.221464329253394, 109),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.209964412811388, 9),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.209964412811388, 18),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.142558189656604, 89),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.053003533568905, 11),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.044533732221232, 82),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.017056563696478, 118),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.94903310930454, 54),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.930966604409868, 35),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.92352613971728, 141),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.884892086330936, 6),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.854632672653132, 75),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.78811873323197, 116),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.72304713267495, 119),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.54636482235538, 74),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.535499004032694, 40),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.500345464775897, 53),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.42064265949685, 41),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.37098844217879, 70),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.22537222660368, 93),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.195604981057386, 77),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.124337337115733, 32),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.07850785298416, 148),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.71484860422597, 26),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.652578017610914, 71),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.5596336260828, 132),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.514213749340463, 133),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.48958472915465, 51),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.4822695035461, 23),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.458395414740107, 43),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.44400909427341, 86),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.374570446735394, 19),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.3511766181633, 87),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.34621933703229, 45),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.161290322580644, 21),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.123707869459665, 56),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.108676702247966, 84),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.997522946044725, 145),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.917241379310344, 22),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.85117368840305, 57),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.815610525074803, 78),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.728321971786833, 46),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.66420664206642, 7),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.5686980869652, 66),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.4570267417468, 50),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.277449699482613, 30),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.086009152579997, 110),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.044664031471108, 81),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.01388888888889, 12),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.998363297367618, 96),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.80120086080076, 134),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.43059475873974, 136),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.271066799140876, 128),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.939501779359432, 4),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.766386216041763, 58),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.67541648572722, 38),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.497488114109178, 144),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.479292636210666, 108),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.83365567738565, 131),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.237949425183977, 123),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.020689655172413, 10)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model using the training sets\n",
    "clf1=FeatureClassifier(0,classifier='DecisionTree',control=3)\n",
    "# clf1.fit(X_train,y_train.reshape(-1,1))\n",
    "clf1.fit(np.array(X_train), np.array(y_train)[:,np.newaxis].astype(int))\n",
    "\n",
    "#predict the response for the test dataset\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(np.array(y_test).astype(int),clf1.predict(np.array(X_test))))\n",
    "\n",
    "print(clf1.indexLs)\n",
    "clf1.featureClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353075b2-a152-4ecf-904e-e7de3e3991b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
