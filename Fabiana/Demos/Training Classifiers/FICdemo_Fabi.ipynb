{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a65ec5d6-3ebe-45d9-a36e-a9a58a17f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Authors: Balachander S, Prahalad Srinivas C G, Yogesh Chandra Singh Samant, B Varshin Hariharan\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#import scikit learn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc=0.01,classifier='DesicionTree',bias=[],control=None,n_jobs=None,random_state=None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e6619e2-1fcc-48a3-964d-8bce726ab58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6    \\\n",
      "0    2.014037  2.842330  2.093059  2.314322  2.550290  2.556514  2.063987   \n",
      "1    2.655125  2.439494  2.387897  2.414520  2.677007  2.066587  2.221681   \n",
      "2    2.397686  2.129261  2.228847  2.574741  2.672454  2.330393  2.379493   \n",
      "3    0.021023  0.884131  0.570157  0.950007  0.570792  0.741419  0.251829   \n",
      "4    0.087550  0.596086  0.355909  0.447322  0.680048  0.198563  0.192330   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "495  0.611156  0.236036  0.896368  0.773777  0.538057  0.402998  0.090796   \n",
      "496  2.761173  2.080949  2.939479  2.325925  2.977614  2.109083  2.517269   \n",
      "497  0.401104  0.340544  0.555580  0.230778  0.600226  0.992868  0.274078   \n",
      "498  0.248207  0.096274  0.516660  0.946114  0.271408  0.845261  0.546188   \n",
      "499  2.647101  2.363681  2.077603  2.632778  2.676110  2.920187  2.866320   \n",
      "\n",
      "          7         8         9    ...       141       142       143  \\\n",
      "0    2.626166  2.169865  2.729640  ...  2.646452  2.997843  2.546260   \n",
      "1    2.714329  2.637106  2.846487  ...  2.024768  2.424598  2.349128   \n",
      "2    2.028757  2.071634  2.981206  ...  2.625961  2.962051  2.420763   \n",
      "3    0.757477  0.494526  0.316475  ...  0.864361  0.083862  0.616211   \n",
      "4    0.583206  0.219153  0.186750  ...  0.455617  0.516570  0.956458   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "495  0.482314  0.720830  0.180064  ...  0.171930  0.575546  0.945014   \n",
      "496  2.544312  2.654161  2.652206  ...  2.151422  2.056074  2.046506   \n",
      "497  0.244900  0.721668  0.165614  ...  0.372709  0.878008  0.004829   \n",
      "498  0.421216  0.754997  0.122243  ...  0.701308  0.291159  0.210397   \n",
      "499  2.482348  2.262446  2.408884  ...  2.727562  2.806661  2.950930   \n",
      "\n",
      "          144       145       146       147       148       149  150  \n",
      "0    2.423437  2.825879  2.566278  2.403595  2.396183  2.684211  1.0  \n",
      "1    2.325874  2.524994  2.862275  2.060383  2.505475  2.334364  1.0  \n",
      "2    2.411974  2.361735  2.667143  2.073825  2.388143  2.831569  1.0  \n",
      "3    0.898456  0.117597  0.664931  0.813385  0.573604  0.117329  0.0  \n",
      "4    0.972840  0.550108  0.503513  0.337278  0.735706  0.284006  0.0  \n",
      "..        ...       ...       ...       ...       ...       ...  ...  \n",
      "495  0.081361  0.288813  0.572817  0.976307  0.629648  0.328398  0.0  \n",
      "496  2.201667  2.586060  2.426173  2.814096  2.713502  2.494102  1.0  \n",
      "497  0.395672  0.574108  0.120476  0.566036  0.027377  0.236266  0.0  \n",
      "498  0.689696  0.531994  0.544423  0.311161  0.296630  0.472500  0.0  \n",
      "499  2.100634  2.557499  2.814815  2.111127  2.403118  2.725393  1.0  \n",
      "\n",
      "[500 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "#This is what I implemented --Fabi\n",
    "#load dataset\n",
    "data = np.loadtxt(\"uniform_large_d_1.tex\")\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df_table = pd.DataFrame(array)\n",
    "\n",
    "# Displaying the table\n",
    "print(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcbe69f4-e85e-43aa-bb40-3dbe6a7e6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#import and read data\n",
    "#from sklearn.datasets import load_iris\n",
    "#iris = datasets.load_iris()\n",
    "\n",
    "#split dataset into training set and test set\n",
    "#test_size: in this case it is 70% training and 30% testing\n",
    "#random_state: sets a seed for a random number generator that splits the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_table.iloc[:,1:150], df_table.iloc[:,-1], test_size=0.2, random_state=52)\n",
    "\n",
    "\n",
    "# Save the data (example: saving as CSV files)\n",
    "#X_test.to_csv('X_test.csv', index=False)\n",
    "#y_test.to_csv('y_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97ef39bd-a115-4856-a4ea-25b12d82aab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "[84, 80, 10, 14, 2, 42, 54, 146, 136, 82, 28, 58, 123, 87, 92, 107, 140, 41, 72, 132, 51, 111, 148, 135, 27, 26, 47, 94, 108, 90, 109, 115, 55, 9, 0, 116, 137, 142, 19, 12, 128, 43, 104, 89, 110, 22, 112, 118, 6, 131, 74, 60, 88, 102, 15, 37, 130, 79, 124, 48, 114, 120, 117, 70, 17, 129, 18, 101, 103, 31, 119, 78, 44, 3, 93, 53, 138, 76, 67, 33, 125, 35, 61, 65, 106, 5, 97, 100, 20, 64, 36, 8, 143, 40, 49, 66, 71, 99, 121, 29, 105, 39, 59, 45, 77, 23, 95, 7, 50, 144, 134, 63, 122, 52, 145, 91, 147, 68, 75, 86, 85, 133, 141, 56, 32, 1, 38, 96, 4, 24, 57, 34, 62, 30, 25, 21, 16, 11, 69, 139, 83, 126, 127, 98, 73, 113, 81, 13, 46]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(DecisionTreeClassifier(max_depth=3), 291.0553717510584, 84),\n",
       " (DecisionTreeClassifier(max_depth=3), 282.4690133841282, 80),\n",
       " (DecisionTreeClassifier(max_depth=3), 282.28267184781237, 10),\n",
       " (DecisionTreeClassifier(max_depth=3), 280.3898606667616, 14),\n",
       " (DecisionTreeClassifier(max_depth=3), 278.773539630527, 2),\n",
       " (DecisionTreeClassifier(max_depth=3), 276.9569014542024, 42),\n",
       " (DecisionTreeClassifier(max_depth=3), 276.7148441422138, 54),\n",
       " (DecisionTreeClassifier(max_depth=3), 275.88500606823686, 146),\n",
       " (DecisionTreeClassifier(max_depth=3), 275.84830358956737, 136),\n",
       " (DecisionTreeClassifier(max_depth=3), 275.2023106378025, 82),\n",
       " (DecisionTreeClassifier(max_depth=3), 275.2018896623747, 28),\n",
       " (DecisionTreeClassifier(max_depth=3), 274.99522313121605, 58),\n",
       " (DecisionTreeClassifier(max_depth=3), 274.9165068096032, 123),\n",
       " (DecisionTreeClassifier(max_depth=3), 274.28604610699693, 87),\n",
       " (DecisionTreeClassifier(max_depth=3), 274.1001039958229, 92),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.7967150138474, 107),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.73564078397294, 140),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.6936357201083, 41),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.45285346294133, 72),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.2767697988181, 132),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.10450203235735, 51),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.0165154160592, 111),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.90724174065724, 148),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.8876522996543, 135),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.69348553563566, 27),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.2727205546793, 26),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.2523238706369, 47),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.23392708460966, 94),\n",
       " (DecisionTreeClassifier(max_depth=3), 271.6834941197262, 108),\n",
       " (DecisionTreeClassifier(max_depth=3), 271.51360683920313, 90),\n",
       " (DecisionTreeClassifier(max_depth=3), 271.260647048606, 109),\n",
       " (DecisionTreeClassifier(max_depth=3), 271.2462300920515, 115),\n",
       " (DecisionTreeClassifier(max_depth=3), 270.9479656088365, 55),\n",
       " (DecisionTreeClassifier(max_depth=3), 270.61587221444955, 9),\n",
       " (DecisionTreeClassifier(max_depth=3), 270.1120719974777, 0),\n",
       " (DecisionTreeClassifier(max_depth=3), 270.05949208397305, 116),\n",
       " (DecisionTreeClassifier(max_depth=3), 269.01357189020524, 137),\n",
       " (DecisionTreeClassifier(max_depth=3), 268.7778058719289, 142),\n",
       " (DecisionTreeClassifier(max_depth=3), 268.5582717055333, 19),\n",
       " (DecisionTreeClassifier(max_depth=3), 268.487418553578, 12),\n",
       " (DecisionTreeClassifier(max_depth=3), 268.1448125512942, 128),\n",
       " (DecisionTreeClassifier(max_depth=3), 268.0469593246471, 43),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.9919002278996, 104),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.97024315616073, 89),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.87128806330435, 110),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.7294357598605, 22),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.7283319382964, 112),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.7179762248853, 118),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.69269895629316, 6),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.48798698563303, 131),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.4495448115531, 74),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.93315091152715, 60),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.924858597581, 88),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.91072507068475, 102),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.6982329176794, 15),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.6761742833421, 37),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.66172247261215, 130),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.5816475739631, 79),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.37400440079006, 124),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.37385418557665, 48),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.08100294833287, 114),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.90539239180345, 120),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.8479962241885, 117),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.79295455910614, 70),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.63151520930046, 17),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.60140634734546, 129),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.3804391659425, 18),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.2660928068999, 101),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.2660216558709, 103),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.11612622916334, 31),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.1033144793722, 119),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.00277086950246, 78),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.9815191845991, 44),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.7577378970375, 3),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.6611508265155, 93),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.6278979633389, 53),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.54384685889255, 138),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.31572202730064, 76),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.17219603072454, 67),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.1633117092927, 33),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.11008911289656, 125),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.90072053280494, 35),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.83773537941374, 61),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.81731916032845, 65),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.8073452012618, 106),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.51423207333494, 5),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.23543959657934, 97),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.0792092787534, 100),\n",
       " (DecisionTreeClassifier(max_depth=3), 262.9612257326956, 20),\n",
       " (DecisionTreeClassifier(max_depth=3), 262.5222436626507, 64),\n",
       " (DecisionTreeClassifier(max_depth=3), 262.47691794984974, 36),\n",
       " (DecisionTreeClassifier(max_depth=3), 262.1963105644555, 8),\n",
       " (DecisionTreeClassifier(max_depth=3), 262.18988611368127, 143),\n",
       " (DecisionTreeClassifier(max_depth=3), 261.87111593787415, 40),\n",
       " (DecisionTreeClassifier(max_depth=3), 261.4944855179307, 49),\n",
       " (DecisionTreeClassifier(max_depth=3), 261.2593410839755, 66),\n",
       " (DecisionTreeClassifier(max_depth=3), 260.8430146299695, 71),\n",
       " (DecisionTreeClassifier(max_depth=3), 260.78577592181125, 99),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.8905801619035, 121),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.723278957709, 29),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.6112846979314, 105),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.51017364785105, 39),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.41626620216164, 59),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.24137868095585, 45),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.233734811741, 77),\n",
       " (DecisionTreeClassifier(max_depth=3), 258.8502670758984, 23),\n",
       " (DecisionTreeClassifier(max_depth=3), 258.3168020467703, 95),\n",
       " (DecisionTreeClassifier(max_depth=3), 258.26641123774283, 7),\n",
       " (DecisionTreeClassifier(max_depth=3), 258.224653923375, 50),\n",
       " (DecisionTreeClassifier(max_depth=3), 258.17976398012553, 144),\n",
       " (DecisionTreeClassifier(max_depth=3), 257.890587489014, 134),\n",
       " (DecisionTreeClassifier(max_depth=3), 257.88733415400657, 63),\n",
       " (DecisionTreeClassifier(max_depth=3), 257.7739366281654, 122),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.8496255783774, 52),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.64144470045653, 145),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.46897083696217, 91),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.3971181741143, 147),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.18754923989843, 68),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.13854608153895, 75),\n",
       " (DecisionTreeClassifier(max_depth=3), 255.75376185912694, 86),\n",
       " (DecisionTreeClassifier(max_depth=3), 255.37703702805965, 85),\n",
       " (DecisionTreeClassifier(max_depth=3), 255.33293572615125, 133),\n",
       " (DecisionTreeClassifier(max_depth=3), 255.33109498615113, 141),\n",
       " (DecisionTreeClassifier(max_depth=3), 254.39937745159568, 56),\n",
       " (DecisionTreeClassifier(max_depth=3), 254.37805945468676, 32),\n",
       " (DecisionTreeClassifier(max_depth=3), 254.2731085821032, 1),\n",
       " (DecisionTreeClassifier(max_depth=3), 254.1624157593368, 38),\n",
       " (DecisionTreeClassifier(max_depth=3), 254.16055246222018, 96),\n",
       " (DecisionTreeClassifier(max_depth=3), 253.9870420797596, 4),\n",
       " (DecisionTreeClassifier(max_depth=3), 253.9343719862539, 24),\n",
       " (DecisionTreeClassifier(max_depth=3), 253.80516169372254, 57),\n",
       " (DecisionTreeClassifier(max_depth=3), 253.5335226921278, 34),\n",
       " (DecisionTreeClassifier(max_depth=3), 252.95636889027912, 62),\n",
       " (DecisionTreeClassifier(max_depth=3), 252.72945869602097, 30),\n",
       " (DecisionTreeClassifier(max_depth=3), 252.40318173805292, 25),\n",
       " (DecisionTreeClassifier(max_depth=3), 252.37083940724028, 21),\n",
       " (DecisionTreeClassifier(max_depth=3), 251.4128266498056, 16),\n",
       " (DecisionTreeClassifier(max_depth=3), 250.97016537503822, 11),\n",
       " (DecisionTreeClassifier(max_depth=3), 250.5182690114924, 69),\n",
       " (DecisionTreeClassifier(max_depth=3), 250.34334757675774, 139),\n",
       " (DecisionTreeClassifier(max_depth=3), 250.1659538975594, 83),\n",
       " (DecisionTreeClassifier(max_depth=3), 249.7194314936458, 126),\n",
       " (DecisionTreeClassifier(max_depth=3), 249.60096294488807, 127),\n",
       " (DecisionTreeClassifier(max_depth=3), 248.9634444265997, 98),\n",
       " (DecisionTreeClassifier(max_depth=3), 248.961233179732, 73),\n",
       " (DecisionTreeClassifier(max_depth=3), 248.21258051718905, 113),\n",
       " (DecisionTreeClassifier(max_depth=3), 247.78716519875266, 81),\n",
       " (DecisionTreeClassifier(max_depth=3), 245.1912057014966, 13),\n",
       " (DecisionTreeClassifier(max_depth=3), 240.16572146135377, 46)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model using the training sets\n",
    "clf1=FeatureClassifier(0,classifier='DecisionTree',control=3)\n",
    "# clf1.fit(X_train,y_train.reshape(-1,1))\n",
    "clf1.fit(np.array(X_train), np.array(y_train)[:,np.newaxis].astype(int))\n",
    "\n",
    "#predict the response for the test dataset\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(np.array(y_test).astype(int),clf1.predict(np.array(X_test))))\n",
    "\n",
    "print(clf1.indexLs)\n",
    "clf1.featureClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353075b2-a152-4ecf-904e-e7de3e3991b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
