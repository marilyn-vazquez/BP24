{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65ec5d6-3ebe-45d9-a36e-a9a58a17f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Authors: Balachander S, Prahalad Srinivas C G, Yogesh Chandra Singh Samant, B Varshin Hariharan\n",
    "'''\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#import scikit learn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc=0.01,classifier='DesicionTree',bias=[],control=None,n_jobs=None,random_state=None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6619e2-1fcc-48a3-964d-8bce726ab58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is what I implemented --Fabi\n",
    "#load dataset\n",
    "data = np.loadtxt(\"uniform_large_d_1.tex\")\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df_table = pd.DataFrame(array)\n",
    "\n",
    "# Displaying the table\n",
    "#print(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95577d76-1181-45e2-85b8-30dfe82bb815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.646452</td>\n",
       "      <td>2.997843</td>\n",
       "      <td>2.546260</td>\n",
       "      <td>2.423437</td>\n",
       "      <td>2.825879</td>\n",
       "      <td>2.566278</td>\n",
       "      <td>2.403595</td>\n",
       "      <td>2.396183</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.024768</td>\n",
       "      <td>2.424598</td>\n",
       "      <td>2.349128</td>\n",
       "      <td>2.325874</td>\n",
       "      <td>2.524994</td>\n",
       "      <td>2.862275</td>\n",
       "      <td>2.060383</td>\n",
       "      <td>2.505475</td>\n",
       "      <td>2.334364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.625961</td>\n",
       "      <td>2.962051</td>\n",
       "      <td>2.420763</td>\n",
       "      <td>2.411974</td>\n",
       "      <td>2.361735</td>\n",
       "      <td>2.667143</td>\n",
       "      <td>2.073825</td>\n",
       "      <td>2.388143</td>\n",
       "      <td>2.831569</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864361</td>\n",
       "      <td>0.083862</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.898456</td>\n",
       "      <td>0.117597</td>\n",
       "      <td>0.664931</td>\n",
       "      <td>0.813385</td>\n",
       "      <td>0.573604</td>\n",
       "      <td>0.117329</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455617</td>\n",
       "      <td>0.516570</td>\n",
       "      <td>0.956458</td>\n",
       "      <td>0.972840</td>\n",
       "      <td>0.550108</td>\n",
       "      <td>0.503513</td>\n",
       "      <td>0.337278</td>\n",
       "      <td>0.735706</td>\n",
       "      <td>0.284006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...       141       142  \\\n",
       "0  2.0  3.0  2.0  2.0  3.0  3.0  2.0  3.0  2.0  3.0  ...  2.646452  2.997843   \n",
       "1  3.0  2.0  2.0  2.0  3.0  2.0  2.0  3.0  3.0  3.0  ...  2.024768  2.424598   \n",
       "2  2.0  2.0  2.0  3.0  3.0  2.0  2.0  2.0  2.0  3.0  ...  2.625961  2.962051   \n",
       "3  0.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  ...  0.864361  0.083862   \n",
       "4  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.455617  0.516570   \n",
       "\n",
       "        143       144       145       146       147       148       149  150  \n",
       "0  2.546260  2.423437  2.825879  2.566278  2.403595  2.396183  2.684211  1.0  \n",
       "1  2.349128  2.325874  2.524994  2.862275  2.060383  2.505475  2.334364  1.0  \n",
       "2  2.420763  2.411974  2.361735  2.667143  2.073825  2.388143  2.831569  1.0  \n",
       "3  0.616211  0.898456  0.117597  0.664931  0.813385  0.573604  0.117329  0.0  \n",
       "4  0.956458  0.972840  0.550108  0.503513  0.337278  0.735706  0.284006  0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the dataset, change 25 columns to 'categorical'\n",
    "#Loop, converts floats to ints and then those ints to category\n",
    "for i in range(26):\n",
    "    df_table.iloc[:,i] = df_table.iloc[:,i].round()\n",
    "    df_table.iloc[:,i] = df_table.iloc[:,i].astype(int)\n",
    "    df_table.iloc[:,i] = df_table.iloc[:,i].astype(\"category\")\n",
    "\n",
    "df_table.iloc[:, 150] = df_table.iloc[:, 150].astype(\"category\")\n",
    "\n",
    "df_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cc7b1b1-2c0b-4ea1-9254-ff2ee40eeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training set and test set\n",
    "#test_size: in this case it is 70% training and 30% testing\n",
    "#random_state: sets a seed for a random number generator that splits the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_table.iloc[:,0:150], df_table.iloc[:,-1], test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97ef39bd-a115-4856-a4ea-25b12d82aab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "[11, 85, 15, 81, 3, 23, 13, 43, 55, 1, 147, 137, 83, 29, 59, 124, 88, 93, 108, 0, 141, 42, 73, 133, 52, 112, 149, 136, 28, 27, 48, 95, 109, 91, 110, 116, 56, 117, 20, 138, 143, 7, 129, 44, 105, 90, 111, 113, 119, 132, 75, 19, 61, 89, 103, 38, 131, 80, 125, 49, 115, 121, 6, 118, 71, 130, 102, 104, 32, 120, 79, 45, 16, 94, 54, 139, 77, 68, 34, 126, 25, 36, 62, 66, 107, 98, 101, 65, 37, 144, 41, 50, 4, 9, 21, 67, 72, 100, 122, 30, 106, 18, 40, 60, 46, 78, 10, 96, 51, 145, 135, 64, 123, 53, 146, 92, 148, 69, 76, 87, 86, 134, 142, 57, 33, 39, 97, 58, 24, 35, 63, 31, 26, 70, 140, 84, 127, 128, 99, 74, 2, 114, 82, 22, 12, 5, 8, 47, 17, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(DecisionTreeClassifier(max_depth=3), 294.14355321629307, 11),\n",
       " (DecisionTreeClassifier(max_depth=3), 291.0553717510584, 85),\n",
       " (DecisionTreeClassifier(max_depth=3), 286.7686810697876, 15),\n",
       " (DecisionTreeClassifier(max_depth=3), 282.4690133841282, 81),\n",
       " (DecisionTreeClassifier(max_depth=3), 281.41787370587656, 3),\n",
       " (DecisionTreeClassifier(max_depth=3), 280.3528898344379, 23),\n",
       " (DecisionTreeClassifier(max_depth=3), 277.53767152259604, 13),\n",
       " (DecisionTreeClassifier(max_depth=3), 276.9569014542024, 43),\n",
       " (DecisionTreeClassifier(max_depth=3), 276.7148441422138, 55),\n",
       " (DecisionTreeClassifier(max_depth=3), 276.58381881593834, 1),\n",
       " (DecisionTreeClassifier(max_depth=3), 275.88500606823686, 147),\n",
       " (DecisionTreeClassifier(max_depth=3), 275.84830358956737, 137),\n",
       " (DecisionTreeClassifier(max_depth=3), 275.2023106378025, 83),\n",
       " (DecisionTreeClassifier(max_depth=3), 275.2018896623747, 29),\n",
       " (DecisionTreeClassifier(max_depth=3), 274.99522313121605, 59),\n",
       " (DecisionTreeClassifier(max_depth=3), 274.9165068096032, 124),\n",
       " (DecisionTreeClassifier(max_depth=3), 274.28604610699693, 88),\n",
       " (DecisionTreeClassifier(max_depth=3), 274.1001039958229, 93),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.7967150138474, 108),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.7601074157003, 0),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.73564078397294, 141),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.6936357201083, 42),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.45285346294133, 73),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.2767697988181, 133),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.10450203235735, 52),\n",
       " (DecisionTreeClassifier(max_depth=3), 273.0165154160592, 112),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.90724174065724, 149),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.8876522996543, 136),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.69348553563566, 28),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.2727205546793, 27),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.2523238706369, 48),\n",
       " (DecisionTreeClassifier(max_depth=3), 272.23392708460966, 95),\n",
       " (DecisionTreeClassifier(max_depth=3), 271.6834941197262, 109),\n",
       " (DecisionTreeClassifier(max_depth=3), 271.51360683920313, 91),\n",
       " (DecisionTreeClassifier(max_depth=3), 271.260647048606, 110),\n",
       " (DecisionTreeClassifier(max_depth=3), 271.2462300920515, 116),\n",
       " (DecisionTreeClassifier(max_depth=3), 270.9479656088365, 56),\n",
       " (DecisionTreeClassifier(max_depth=3), 270.05949208397305, 117),\n",
       " (DecisionTreeClassifier(max_depth=3), 269.6476869909212, 20),\n",
       " (DecisionTreeClassifier(max_depth=3), 269.01357189020524, 138),\n",
       " (DecisionTreeClassifier(max_depth=3), 268.7778058719289, 143),\n",
       " (DecisionTreeClassifier(max_depth=3), 268.40486114727184, 7),\n",
       " (DecisionTreeClassifier(max_depth=3), 268.1448125512942, 129),\n",
       " (DecisionTreeClassifier(max_depth=3), 268.0469593246471, 44),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.9919002278996, 105),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.97024315616073, 90),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.87128806330435, 111),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.7283319382964, 113),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.7179762248853, 119),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.48798698563303, 132),\n",
       " (DecisionTreeClassifier(max_depth=3), 267.4495448115531, 75),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.93869814331856, 19),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.93315091152715, 61),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.924858597581, 89),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.91072507068475, 103),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.6761742833421, 38),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.66172247261215, 131),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.5816475739631, 80),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.37400440079006, 125),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.37385418557665, 49),\n",
       " (DecisionTreeClassifier(max_depth=3), 266.08100294833287, 115),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.90539239180345, 121),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.9027874119622, 6),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.8479962241885, 118),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.79295455910614, 71),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.60140634734546, 130),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.2660928068999, 102),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.2660216558709, 104),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.11612622916334, 32),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.1033144793722, 120),\n",
       " (DecisionTreeClassifier(max_depth=3), 265.00277086950246, 79),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.9815191845991, 45),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.74899644305265, 16),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.6611508265155, 94),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.6278979633389, 54),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.54384685889255, 139),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.31572202730064, 77),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.17219603072454, 68),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.1633117092927, 34),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.11008911289656, 126),\n",
       " (DecisionTreeClassifier(max_depth=3), 264.00162553568794, 25),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.90072053280494, 36),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.83773537941374, 62),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.81731916032845, 66),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.8073452012618, 107),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.23543959657934, 98),\n",
       " (DecisionTreeClassifier(max_depth=3), 263.0792092787534, 101),\n",
       " (DecisionTreeClassifier(max_depth=3), 262.5222436626507, 65),\n",
       " (DecisionTreeClassifier(max_depth=3), 262.47691794984974, 37),\n",
       " (DecisionTreeClassifier(max_depth=3), 262.18988611368127, 144),\n",
       " (DecisionTreeClassifier(max_depth=3), 261.87111593787415, 41),\n",
       " (DecisionTreeClassifier(max_depth=3), 261.4944855179307, 50),\n",
       " (DecisionTreeClassifier(max_depth=3), 261.34006734006726, 4),\n",
       " (DecisionTreeClassifier(max_depth=3), 261.3220075702151, 9),\n",
       " (DecisionTreeClassifier(max_depth=3), 261.2955970393788, 21),\n",
       " (DecisionTreeClassifier(max_depth=3), 261.2593410839755, 67),\n",
       " (DecisionTreeClassifier(max_depth=3), 260.8430146299695, 72),\n",
       " (DecisionTreeClassifier(max_depth=3), 260.78577592181125, 100),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.8905801619035, 122),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.723278957709, 30),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.6112846979314, 106),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.5741705318072, 18),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.51017364785105, 40),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.41626620216164, 60),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.24137868095585, 46),\n",
       " (DecisionTreeClassifier(max_depth=3), 259.233734811741, 78),\n",
       " (DecisionTreeClassifier(max_depth=3), 258.77391910045276, 10),\n",
       " (DecisionTreeClassifier(max_depth=3), 258.3168020467703, 96),\n",
       " (DecisionTreeClassifier(max_depth=3), 258.224653923375, 51),\n",
       " (DecisionTreeClassifier(max_depth=3), 258.17976398012553, 145),\n",
       " (DecisionTreeClassifier(max_depth=3), 257.890587489014, 135),\n",
       " (DecisionTreeClassifier(max_depth=3), 257.88733415400657, 64),\n",
       " (DecisionTreeClassifier(max_depth=3), 257.7739366281654, 123),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.8496255783774, 53),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.64144470045653, 146),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.46897083696217, 92),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.3971181741143, 148),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.18754923989843, 69),\n",
       " (DecisionTreeClassifier(max_depth=3), 256.13854608153895, 76),\n",
       " (DecisionTreeClassifier(max_depth=3), 255.75376185912694, 87),\n",
       " (DecisionTreeClassifier(max_depth=3), 255.37703702805965, 86),\n",
       " (DecisionTreeClassifier(max_depth=3), 255.33293572615125, 134),\n",
       " (DecisionTreeClassifier(max_depth=3), 255.33109498615113, 142),\n",
       " (DecisionTreeClassifier(max_depth=3), 254.39937745159568, 57),\n",
       " (DecisionTreeClassifier(max_depth=3), 254.37805945468676, 33),\n",
       " (DecisionTreeClassifier(max_depth=3), 254.1624157593368, 39),\n",
       " (DecisionTreeClassifier(max_depth=3), 254.16055246222018, 97),\n",
       " (DecisionTreeClassifier(max_depth=3), 253.80516169372254, 58),\n",
       " (DecisionTreeClassifier(max_depth=3), 253.57749108244158, 24),\n",
       " (DecisionTreeClassifier(max_depth=3), 253.5335226921278, 35),\n",
       " (DecisionTreeClassifier(max_depth=3), 252.95636889027912, 63),\n",
       " (DecisionTreeClassifier(max_depth=3), 252.72945869602097, 31),\n",
       " (DecisionTreeClassifier(max_depth=3), 252.40318173805292, 26),\n",
       " (DecisionTreeClassifier(max_depth=3), 250.5182690114924, 70),\n",
       " (DecisionTreeClassifier(max_depth=3), 250.34334757675774, 140),\n",
       " (DecisionTreeClassifier(max_depth=3), 250.1659538975594, 84),\n",
       " (DecisionTreeClassifier(max_depth=3), 249.7194314936458, 127),\n",
       " (DecisionTreeClassifier(max_depth=3), 249.60096294488807, 128),\n",
       " (DecisionTreeClassifier(max_depth=3), 248.9634444265997, 99),\n",
       " (DecisionTreeClassifier(max_depth=3), 248.961233179732, 74),\n",
       " (DecisionTreeClassifier(max_depth=3), 248.3704535470048, 2),\n",
       " (DecisionTreeClassifier(max_depth=3), 248.21258051718905, 114),\n",
       " (DecisionTreeClassifier(max_depth=3), 247.78716519875266, 82),\n",
       " (DecisionTreeClassifier(max_depth=3), 247.48280038796463, 22),\n",
       " (DecisionTreeClassifier(max_depth=3), 246.65566159264938, 12),\n",
       " (DecisionTreeClassifier(max_depth=3), 243.76820298852323, 5),\n",
       " (DecisionTreeClassifier(max_depth=3), 243.23098976564324, 8),\n",
       " (DecisionTreeClassifier(max_depth=3), 240.16572146135377, 47),\n",
       " (DecisionTreeClassifier(max_depth=3), 239.04642384768283, 17),\n",
       " (DecisionTreeClassifier(max_depth=3), 225.30974150899698, 14)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model using the training sets\n",
    "clf1=FeatureClassifier(0,classifier='DecisionTree',control=3)\n",
    "# clf1.fit(X_train,y_train.reshape(-1,1))\n",
    "clf1.fit(np.array(X_train), np.array(y_train)[:,np.newaxis].astype(int))\n",
    "\n",
    "#predict the response for the test dataset\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(np.array(y_test).astype(int),clf1.predict(np.array(X_test))))\n",
    "\n",
    "print(clf1.indexLs)\n",
    "clf1.featureClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353075b2-a152-4ecf-904e-e7de3e3991b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
