{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df271435-829a-4274-9c16-7b98e95d9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# import splitting function\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e92fdb28-cf44-443c-9343-b8564875677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6    \\\n",
      "0    2.014037  2.842330  2.093059  2.314322  2.550290  2.556514  2.063987   \n",
      "1    2.655125  2.439494  2.387897  2.414520  2.677007  2.066587  2.221681   \n",
      "2    2.397686  2.129261  2.228847  2.574741  2.672454  2.330393  2.379493   \n",
      "3    0.021023  0.884131  0.570157  0.950007  0.570792  0.741419  0.251829   \n",
      "4    0.087550  0.596086  0.355909  0.447322  0.680048  0.198563  0.192330   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "495  0.611156  0.236036  0.896368  0.773777  0.538057  0.402998  0.090796   \n",
      "496  2.761173  2.080949  2.939479  2.325925  2.977614  2.109083  2.517269   \n",
      "497  0.401104  0.340544  0.555580  0.230778  0.600226  0.992868  0.274078   \n",
      "498  0.248207  0.096274  0.516660  0.946114  0.271408  0.845261  0.546188   \n",
      "499  2.647101  2.363681  2.077603  2.632778  2.676110  2.920187  2.866320   \n",
      "\n",
      "          7         8         9    ...       141       142       143  \\\n",
      "0    2.626166  2.169865  2.729640  ...  2.646452  2.997843  2.546260   \n",
      "1    2.714329  2.637106  2.846487  ...  2.024768  2.424598  2.349128   \n",
      "2    2.028757  2.071634  2.981206  ...  2.625961  2.962051  2.420763   \n",
      "3    0.757477  0.494526  0.316475  ...  0.864361  0.083862  0.616211   \n",
      "4    0.583206  0.219153  0.186750  ...  0.455617  0.516570  0.956458   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "495  0.482314  0.720830  0.180064  ...  0.171930  0.575546  0.945014   \n",
      "496  2.544312  2.654161  2.652206  ...  2.151422  2.056074  2.046506   \n",
      "497  0.244900  0.721668  0.165614  ...  0.372709  0.878008  0.004829   \n",
      "498  0.421216  0.754997  0.122243  ...  0.701308  0.291159  0.210397   \n",
      "499  2.482348  2.262446  2.408884  ...  2.727562  2.806661  2.950930   \n",
      "\n",
      "          144       145       146       147       148       149  150  \n",
      "0    2.423437  2.825879  2.566278  2.403595  2.396183  2.684211  1.0  \n",
      "1    2.325874  2.524994  2.862275  2.060383  2.505475  2.334364  1.0  \n",
      "2    2.411974  2.361735  2.667143  2.073825  2.388143  2.831569  1.0  \n",
      "3    0.898456  0.117597  0.664931  0.813385  0.573604  0.117329  0.0  \n",
      "4    0.972840  0.550108  0.503513  0.337278  0.735706  0.284006  0.0  \n",
      "..        ...       ...       ...       ...       ...       ...  ...  \n",
      "495  0.081361  0.288813  0.572817  0.976307  0.629648  0.328398  0.0  \n",
      "496  2.201667  2.586060  2.426173  2.814096  2.713502  2.494102  1.0  \n",
      "497  0.395672  0.574108  0.120476  0.566036  0.027377  0.236266  0.0  \n",
      "498  0.689696  0.531994  0.544423  0.311161  0.296630  0.472500  0.0  \n",
      "499  2.100634  2.557499  2.814815  2.111127  2.403118  2.725393  1.0  \n",
      "\n",
      "[500 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "#This is what I implemented --Fabi\n",
    "#load dataset\n",
    "data = np.loadtxt(\"uniform_large_d_1.tex\")\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df_table = pd.DataFrame(array)\n",
    "\n",
    "# Displaying the table\n",
    "print(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98fcf056-1d08-41d9-a423-1ce0542c08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training set and test set\n",
    "#test_size: in this case it is 70% training and 30% testing\n",
    "#random_state: sets a seed for a random number generator that splits the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_table.iloc[:,1:150], df_table.iloc[:,-1], test_size=0.2, random_state=52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1df4b532-8184-434d-80f0-bf5137cd246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save training data\n",
    "X_test.to_csv('X_test_SVM.csv', index=False)\n",
    "y_test.to_csv('y_test_SVM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abab71d7-aaa1-4cd6-beb5-48434210b4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 1. 1. 0.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Create a svm Classifier\n",
    "# kernel: options for kernel include linear, poly, rbf, sigmoid\n",
    "    # linear: use this when data can be split by a linear function\n",
    "    # poly (polynomial): use this when data can be split by a polynomial function\n",
    "    # rbf (radial basis function): use this when there are clusters of one class inside another\n",
    "    # sigmoid: use this when the split between classes is curved and irregular\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(y_pred)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65254972-a7ec-4530-a6bd-1c383174626c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
