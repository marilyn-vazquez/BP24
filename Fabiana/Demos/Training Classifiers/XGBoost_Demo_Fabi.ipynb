{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ab12ef8-29cf-4cf0-9165-2a38f7278dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.4)\n",
      "Downloading xgboost-2.0.3-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "# First, put this prompt: \"conda install -c conda-forge py-xgboost\" in anaconda to download xgboost package\n",
    "# install xgboost in jupyter\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e2c2b1-797d-4f7e-ad25-0e3a0045bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the classifier from the xgboost package\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import splitting function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de08a20d-8e4d-4856-a73a-67ab2d4f0a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6    \\\n",
      "0    2.014037  2.842330  2.093059  2.314322  2.550290  2.556514  2.063987   \n",
      "1    2.655125  2.439494  2.387897  2.414520  2.677007  2.066587  2.221681   \n",
      "2    2.397686  2.129261  2.228847  2.574741  2.672454  2.330393  2.379493   \n",
      "3    0.021023  0.884131  0.570157  0.950007  0.570792  0.741419  0.251829   \n",
      "4    0.087550  0.596086  0.355909  0.447322  0.680048  0.198563  0.192330   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "495  0.611156  0.236036  0.896368  0.773777  0.538057  0.402998  0.090796   \n",
      "496  2.761173  2.080949  2.939479  2.325925  2.977614  2.109083  2.517269   \n",
      "497  0.401104  0.340544  0.555580  0.230778  0.600226  0.992868  0.274078   \n",
      "498  0.248207  0.096274  0.516660  0.946114  0.271408  0.845261  0.546188   \n",
      "499  2.647101  2.363681  2.077603  2.632778  2.676110  2.920187  2.866320   \n",
      "\n",
      "          7         8         9    ...       141       142       143  \\\n",
      "0    2.626166  2.169865  2.729640  ...  2.646452  2.997843  2.546260   \n",
      "1    2.714329  2.637106  2.846487  ...  2.024768  2.424598  2.349128   \n",
      "2    2.028757  2.071634  2.981206  ...  2.625961  2.962051  2.420763   \n",
      "3    0.757477  0.494526  0.316475  ...  0.864361  0.083862  0.616211   \n",
      "4    0.583206  0.219153  0.186750  ...  0.455617  0.516570  0.956458   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "495  0.482314  0.720830  0.180064  ...  0.171930  0.575546  0.945014   \n",
      "496  2.544312  2.654161  2.652206  ...  2.151422  2.056074  2.046506   \n",
      "497  0.244900  0.721668  0.165614  ...  0.372709  0.878008  0.004829   \n",
      "498  0.421216  0.754997  0.122243  ...  0.701308  0.291159  0.210397   \n",
      "499  2.482348  2.262446  2.408884  ...  2.727562  2.806661  2.950930   \n",
      "\n",
      "          144       145       146       147       148       149  150  \n",
      "0    2.423437  2.825879  2.566278  2.403595  2.396183  2.684211  1.0  \n",
      "1    2.325874  2.524994  2.862275  2.060383  2.505475  2.334364  1.0  \n",
      "2    2.411974  2.361735  2.667143  2.073825  2.388143  2.831569  1.0  \n",
      "3    0.898456  0.117597  0.664931  0.813385  0.573604  0.117329  0.0  \n",
      "4    0.972840  0.550108  0.503513  0.337278  0.735706  0.284006  0.0  \n",
      "..        ...       ...       ...       ...       ...       ...  ...  \n",
      "495  0.081361  0.288813  0.572817  0.976307  0.629648  0.328398  0.0  \n",
      "496  2.201667  2.586060  2.426173  2.814096  2.713502  2.494102  1.0  \n",
      "497  0.395672  0.574108  0.120476  0.566036  0.027377  0.236266  0.0  \n",
      "498  0.689696  0.531994  0.544423  0.311161  0.296630  0.472500  0.0  \n",
      "499  2.100634  2.557499  2.814815  2.111127  2.403118  2.725393  1.0  \n",
      "\n",
      "[500 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "#This is what I implemented --Fabi\n",
    "#load dataset\n",
    "data = np.loadtxt(\"uniform_large_d_1.tex\")\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df_table = pd.DataFrame(array)\n",
    "\n",
    "# Displaying the table\n",
    "print(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b55537c8-4ef2-4de6-a901-14354eb8cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training set and test set\n",
    "#test_size: in this case it is 70% training and 30% testing\n",
    "#random_state: sets a seed for a random number generator that splits the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_table.iloc[:,1:150], df_table.iloc[:,-1], test_size=0.2, random_state=52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc0a8290-0ede-4a03-9ab6-c36d540105b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save training data\n",
    "X_test.to_csv('X_test_XGB.csv', index=False)\n",
    "y_test.to_csv('y_test_XGB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8b27a57-31b4-4bdb-b8bf-2537fe28f4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0\n",
      " 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 1 0\n",
      " 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "# n_estimators: number of trees(estimators) the model uses --> the more used, the more accurate the model is\n",
    "# max_depth: maximum depth of tree --> higher number makes model more complex, but too high can cause overfitting\n",
    "# learning_rate: quantifies each tree's contribution to total prediction --> lower number takes longer, but can lead to better generalization\n",
    "# objective: binary:logistic outputs probabilities. if classification is wanted, use binary:hinge\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "\n",
    "# fit model with the training data\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for the test dataset\n",
    "preds = bst.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(preds)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e512e-24e0-4cd3-8901-033d3ecbb707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
