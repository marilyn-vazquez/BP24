{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47297b3e-727e-44ba-8672-92785b6dbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pdb\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\"\"\"\n",
    "The function Measure_Patterns has 3 parameters: X_train, y_train, optional\n",
    "optional will check if the columns selected is categorical (integers and strings) or numerical (float)\n",
    "if optional is not provided, then the program will assume that the column has integers values, therefore it will be considered categorical\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55a54f-b77a-42d1-b19e-eb73202c0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Data Creation/Gaussian - small distance/gaussian_small_d_1.tex\")\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "# Converting to Pandas DataFrame\n",
    "df_table = pd.DataFrame(array)\n",
    "# Displaying the table\n",
    "print(df_table)\n",
    "\n",
    "\n",
    "\n",
    "# From the dataset, change 25 columns to 'categorical'\n",
    "#Loop, converts floats to ints and then those ints to category\n",
    "for i in range(26):\n",
    "    df_table.iloc[:,i] = df_table.iloc[:,i].astype(int)\n",
    "    df_table.iloc[:,i] = df_table.iloc[:,i].astype(\"category\")\n",
    "df_table.iloc[:, 150] = df_table.iloc[:, 150].astype(\"category\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_table.iloc[:,0:150], df_table.iloc[:,-1], test_size=0.2, random_state=52)\n",
    "\n",
    "\n",
    "# Function Measure_Patterns begins here!\n",
    "def Measure_Patterns(X_train, y_train, optional=None):\n",
    "    \n",
    "    # Check if the data type is provided for columns\n",
    "    if optional is None:\n",
    "        print(\"Optional parameter not provided. Assuming integers values are categorical\")\n",
    "    \n",
    "        # Splitting X_train into numerical subset \n",
    "        print(\"\\nNumerical DataFrame:\")\n",
    "        numerical_df = X_train.select_dtypes(include = [\"float64\"])\n",
    "        print(numerical_df)\n",
    "\n",
    "        # Splitting X_train into categorical subset \n",
    "        print(\"Categorical DataFrame:\")\n",
    "        categorical_df = X_train.select_dtypes(exclude=['float64'])\n",
    "        print(categorical_df)\n",
    "    \n",
    "    else:\n",
    "        # Create empty numerical & categorical data frames\n",
    "        numerical = []\n",
    "        numerical_colnames = []\n",
    "        categorical = []\n",
    "        categorical_colnames = []\n",
    "        \n",
    "        # Check that length of optional = # of columns in X_train\n",
    "        # Optional is the column type for X_train, so the lengths should be equal\n",
    "        if len(optional) == len(X_train.columns):\n",
    "            # For all the values in optional\n",
    "            for i in range(len(optional)):\n",
    "                if optional[i] == True:\n",
    "                    numerical.append(X_train.iloc[:,i])\n",
    "                    # TO DO: Save SPECIFIC column name in each loop, order matters\n",
    "                    # numerical_colnames.append()\n",
    "                else: \n",
    "                    categorical.append(X_train.iloc[:,i])\n",
    "                    # TO DO: Save SPECIFIC column name in each loop, order matters\n",
    "                    # categorical_colnames.append()\n",
    "            # Turn transposed arrays into dataframes\n",
    "            numerical_df = pd.DataFrame(np.transpose(numerical))\n",
    "            categorical_df = pd.DataFrame(np.transpose(categorical))\n",
    "            # TO DO: Re-attach the column names to numerical_df & categorical_df \n",
    "            \n",
    "            print(\"Numerical DF:\")\n",
    "            print(numerical_df)\n",
    "            print(\"Categorical Df\")\n",
    "            print(categorical_df)\n",
    "            \n",
    "        else:\n",
    "            print(\"The length of X_train and optional are different.\")\n",
    "            \n",
    "\n",
    "##################### Correlation between columns (numerical) Code ############################\n",
    "    # Takes the X_train data to find correlation between NUMERICAL features\n",
    "    def num_corr(X_train_numerical):\n",
    "        matrix = X_train_numerical.corr(method='pearson')\n",
    "        print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "    #Calls the function so the matrix prints out    \n",
    "    num_corr(numerical_df)\n",
    "    \n",
    "##################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "    print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "    # Finds dependency between all CATEGORICAL features in X_train\n",
    "    def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "        # Extract variable names\n",
    "        variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "        # Initialize matrices to store chi-squared and p-values\n",
    "        num_variables = len(variable_names)\n",
    "        chi_squared = np.zeros((num_variables, num_variables))\n",
    "        p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "        # Compute chi-squared and p-values for each pair of variables\n",
    "        for i, j in combinations(range(num_variables), 2):\n",
    "            contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "            # Compute chi-squared and p-values\n",
    "            chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "            p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "            # Assign results to chi_squared and p_values matrices\n",
    "            chi_squared[i, j] = chi2\n",
    "            chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "            p_values[i, j] = p\n",
    "            p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "        # Create a DataFrame with variable names as index and columns\n",
    "        chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "        p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "        # Printing the matrix-like output with variable names\n",
    "        print(\"Chi-Squared Values:\")\n",
    "        print(chi_squared_df)\n",
    "        print(\"\\nP-Values:\")\n",
    "        print(p_values_df)\n",
    "    \n",
    "    chi_squared_fvf(categorical_df)\n",
    "    \n",
    "##################### Chi-Square (F vs label column) Code ####################################\n",
    "    \n",
    "    print(\"\\n------------------------Chi-Square (F vs label column)------------------------\")\n",
    "    # Finds dependency between all CATEGORICAL features in X_train & the label in y_train\n",
    "    def chi_squared_fvl(X_train_categorical, y_train):\n",
    "        \n",
    "        # Combining CATEGORICAL X_train and y_train\n",
    "        df = X_train_categorical\n",
    "        df['label'] = y_train\n",
    "\n",
    "        # Number of features, excluding label\n",
    "        var_count = len(df.columns)-1\n",
    "\n",
    "        # Creates an empty array to print values in a table\n",
    "        results = []\n",
    "\n",
    "        for i in range(0, var_count):\n",
    "\n",
    "            # Create contigency table of all features v. label\n",
    "            crosstab = pd.crosstab(df.iloc[:, i], df.iloc[:,-1])\n",
    "            \n",
    "            # Compute chi-squared and p-values\n",
    "            chi2 = stats.chi2_contingency(crosstab)[0]\n",
    "            p = stats.chi2_contingency(crosstab)[1]\n",
    "            \n",
    "            # Append results to the list\n",
    "            results.append({\n",
    "                \"Feature\": df.columns[i],\n",
    "                \"Chi Squared Statistic\": chi2,\n",
    "                \"P-Value\": p})\n",
    "\n",
    "        # Create a DataFrame from the results\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Print the DataFrame\n",
    "        print(\"Label:\", df.columns.values[-1])\n",
    "        print(results_df.to_string(index=False))\n",
    "    \n",
    "    chi_squared_fvl(categorical_df, y_train)\n",
    "################################# KS Test ###########################################\n",
    "    print(\"\\n---------------------Kolmogorov Smirnov Test--------------------------\")\n",
    "\n",
    "    # Subset to select only numerical variables columns --> KS Test only works with numerical\n",
    "    # Subset to select only numerical variables columns --> KS Test only works with numerical\n",
    "    df_KS = df_table.select_dtypes(include = [\"float64\"])\n",
    "    # Add label column to new KS dataset to compare Feature to Label\n",
    "    label_column = df_table.iloc[:, -1]\n",
    "    df_KS['label_column'] = label_column\n",
    "    df_KS.head()\n",
    "\n",
    "    def standardize(sample):\n",
    "        return (sample - np.mean(sample)) / np.std(sample)\n",
    "\n",
    "    def ks_test(sample):\n",
    "        # Sort the sample\n",
    "        sample_sorted = np.sort(sample)\n",
    "        # Evaluate the empirical CDF (ECDF)\n",
    "        ecdf = np.arange(1, len(sample_sorted)+1) / len(sample_sorted)\n",
    "        # Evaluate the theoretical CDF\n",
    "        cdf = stats.norm.cdf(sample_sorted)\n",
    "        # Calculate the KS statistic\n",
    "        ks_stat = np.max(np.abs(ecdf - cdf))\n",
    "        # Calculate the p-value\n",
    "        p_value = stats.kstest(sample_sorted, 'norm').pvalue\n",
    "        return ks_stat, p_value\n",
    "    \n",
    "    # Temporary KS Test\n",
    "    var_count = len(df_KS.columns)-1\n",
    "\n",
    "    #creates an empty array to print values in a table\n",
    "    results = [] \n",
    "\n",
    "    for i in range(0, var_count):\n",
    "        # Select one feature from the dataset (Example: assuming the first column is numeric)\n",
    "        sample = df_KS.iloc[:, i]  # Change the column index as needed\n",
    "        # Standardize the sample\n",
    "        standardized_sample = standardize(sample)\n",
    "        # Perform the KS test on standardize sample\n",
    "        ks_stat, p_value = ks_test(standardized_sample)\n",
    "        # Determine if we reject or fail to reject the null hypothesis\n",
    "        # If sample does not come from a normal distribution ---> reject H0\n",
    "        # If sample comes from a normal distribution ---> fail to reject H0\n",
    "        normal_dist = p_value > 0.05\n",
    "        hypothesis_result = \"Fail to reject H0\" if normal_dist else \"Reject H0\"\n",
    "\n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            \"Feature\": df_KS.columns[i],\n",
    "            \"KS Statistic\": f\"{ks_stat:.4f}\",\n",
    "            \"P-Value\": f\"{p_value:.3e}\",\n",
    "            \"Normal Distribution\": normal_dist,\n",
    "            \"Hypothesis Result\": hypothesis_result})\n",
    "    \n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "########################## Histogram/Graphing ###############################\n",
    "\n",
    "print(\"------------------------Histogram/Graphing-----------------------------\")\n",
    "# Ensure data is 2D\n",
    "if data.ndim == 1:\n",
    "    data = data.reshape(-1, 1)  # Reshape 1D array to 2D array with one column\n",
    "\n",
    "# Number of features (columns) in the dataset\n",
    "num_features = data.shape[1]\n",
    "\n",
    "# Loop through each feature\n",
    "for feature_idx in range(num_features):\n",
    "    # Extract the current feature data (column)\n",
    "    feature_data = data[:, feature_idx]\n",
    "\n",
    "    # Compute histogram with 10 bins\n",
    "    hist, bin_edges = np.histogram(feature_data, bins=10)\n",
    "\n",
    "    # Print feature number\n",
    "    print(f\"Feature {feature_idx + 1}:\")\n",
    "    \n",
    "    # Print bin edges\n",
    "    print(\"Bin Edges:\", bin_edges)\n",
    "\n",
    "    # Store bin heights in a list\n",
    "    bin_heights = []\n",
    "    bin_heights.extend(hist)\n",
    "    print(\"Array with bin heights:\", bin_heights)\n",
    "\n",
    "    # Store bin probabilities in a list and normalize\n",
    "    bin_probs = []\n",
    "    bin_probs.extend(hist)\n",
    "    bin_probs = np.array(bin_probs) / sum(bin_heights)\n",
    "    print(\"Array with bin probabilities:\", bin_probs)\n",
    "\n",
    "    # Loop through each bin to print range and probabilities\n",
    "    for i in range(len(hist)):\n",
    "        bin_range = f\"{bin_edges[i]:.2f} to {bin_edges[i+1]:.2f}\"  # Bin range\n",
    "        bin_probability = hist[i] / sum(hist)  # Bin probability\n",
    "        print(f\"Bin {i + 1} ({bin_range}): Height = {hist[i]}, Probability = {bin_probability:.2f}\")\n",
    "\n",
    "    # Separator between features for clarity\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "############################ KL Divergence ####################################\n",
    "\n",
    "optional_test = []\n",
    "\n",
    "for i in range(151):\n",
    "    optional_test.append(bool(random.getrandbits(1)))\n",
    "\n",
    "# Call the measure_patterns function\n",
    "Measure_Patterns(X_train, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
