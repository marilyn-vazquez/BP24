{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Important: F vs L --> Chi-Square Test \n",
    "- Chi-Square prints a p-values column  that will be changed to True and False. If the p-value is less than 0.05, then there is a relationship, this is print TRUE (H0: null hypothesis). Otherwise, if p > 0.05 there is no relationship, this will print FALSE (Ha:  Alternative hypothesis)\n",
    "- Goal is to print the count of the changes -->  from True to False OR from False to True\n",
    "- Both data1 and data2 MUST have the same number of numerical and categorical columns. We will test 13 columns for all datasets with 8 'numerical'(at the beginning) and 5 'categorical' columns (at the end, including the label column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets before augmentation (synthetic)\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "\n",
    "\n",
    "# Datasets after augmentation\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Fabiana/Data/HAT (synthetic datasets)/stacked_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Fabiana/Data/HAT (synthetic datasets)/uniform_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Fabiana/Data/HAT (synthetic datasets)/gaussian_HAT.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Shapes of Datasets\n",
    "- They must be the same, if they are not--> run specific cells to make them have the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes for debugging \n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d026e7b-e0be-4cf2-b068-dd2fd0bfb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data1 is your DataFrame\n",
    "# indexes 2, 7, 10, 15, 24 are 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data1.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data1 = data1.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fac50d-4e8e-40e9-8e67-c1cdfc3fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data1 is your DataFrame\n",
    "# indexes 2, 7, 10, 15, 24 are 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data2.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data2 = data2.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fbade-0f5e-4752-8110-2d6f812ae665",
   "metadata": {},
   "source": [
    "# Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743336-8bf3-433e-a128-e8fc8aa271a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes 2, 3, 7, 9, 12 are 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data1.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data1 = data1.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7b1d3-21b2-46c9-aa8c-a812252bdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes 2, 3, 7, 9, 12 are 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data2.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data2 = data2.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2 .dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Stacked Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52c5ceb-1aed-47cd-ae7e-e3b4a3d29d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data1.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data1 = data1.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d77a2f5-985d-4e5f-8eb9-d0eb5be1887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data2.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data2 = data2.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Data1: Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1261910205.py, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 61\u001b[0;36m\u001b[0m\n\u001b[0;31m    p = chi_squared_fvl(categorical_df[:,], categorical_df[]:,-1)\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in data1.columns[-5:]:\n",
    "    data1[col] = data1[col].astype(int)\n",
    "\n",
    "# Convert the last 5 columns to categorical\n",
    "for col in data1.columns[-5:]:\n",
    "    data1[col] = data1[col].astype('category')\n",
    "\n",
    "print(data1.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = data1.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = data1.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "##################### Chi-Square (F vs label column) Code ####################################\n",
    "    \n",
    "print(\"\\n------------------------Chi-Square (F vs label column)------------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train & the label in y_train\n",
    "def chi_squared_fvl(X_train_categorical, y_train):\n",
    "        \n",
    "    # Combining CATEGORICAL X_train and y_train\n",
    "    df = X_train_categorical\n",
    "    df['label'] = y_train\n",
    "\n",
    "    # Number of features, excluding label\n",
    "    var_count = len(df.columns)-1\n",
    "\n",
    "    # Creates an empty array to print values in a table\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, var_count):\n",
    "\n",
    "        # Create contigency table of all features v. label\n",
    "        crosstab = pd.crosstab(df.iloc[:, i], df.iloc[:,-1])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(crosstab)[0]\n",
    "        p = stats.chi2_contingency(crosstab)[1]\n",
    "            \n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            \"Feature\": df.columns[i],\n",
    "            \"Chi Squared Statistic\": chi2,\n",
    "            \"P-Value\": p})\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(\"Label:\", df.columns.values[-1])\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    return p\n",
    "    \n",
    "p = chi_squared_fvl(categorical_df[:,], categorical_df[]:,-1)\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df1 = p < 0.05\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Data1 + Data2: Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      float64\n",
      "1      float64\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "5      float64\n",
      "6      float64\n",
      "7      float64\n",
      "8     category\n",
      "9     category\n",
      "10    category\n",
      "11    category\n",
      "12    category\n",
      "dtype: object\n",
      "---------------------------Correlation Matrix------------------------- \n",
      "           0         1         2         3         4         5         6  \\\n",
      "0  1.000000  0.067284  0.009230  0.021866  0.287206  0.024427  0.061738   \n",
      "1  0.067284  1.000000  0.175178  0.274739  0.256645  0.173970  0.258445   \n",
      "2  0.009230  0.175178  1.000000  0.186715  0.219841  0.135958  0.268791   \n",
      "3  0.021866  0.274739  0.186715  1.000000  0.227818  0.150026  0.090108   \n",
      "4  0.287206  0.256645  0.219841  0.227818  1.000000  0.219706  0.167674   \n",
      "5  0.024427  0.173970  0.135958  0.150026  0.219706  1.000000 -0.040622   \n",
      "6  0.061738  0.258445  0.268791  0.090108  0.167674 -0.040622  1.000000   \n",
      "7  0.285796  0.101757  0.071208 -0.042263  0.088846  0.029369  0.108098   \n",
      "\n",
      "          7  \n",
      "0  0.285796  \n",
      "1  0.101757  \n",
      "2  0.071208  \n",
      "3 -0.042263  \n",
      "4  0.088846  \n",
      "5  0.029369  \n",
      "6  0.108098  \n",
      "7  1.000000  \n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  1.000000  0.067284  0.009230  0.021866  0.287206  0.024427  0.061738   \n",
      "1  0.067284  1.000000  0.175178  0.274739  0.256645  0.173970  0.258445   \n",
      "2  0.009230  0.175178  1.000000  0.186715  0.219841  0.135958  0.268791   \n",
      "3  0.021866  0.274739  0.186715  1.000000  0.227818  0.150026  0.090108   \n",
      "4  0.287206  0.256645  0.219841  0.227818  1.000000  0.219706  0.167674   \n",
      "5  0.024427  0.173970  0.135958  0.150026  0.219706  1.000000 -0.040622   \n",
      "6  0.061738  0.258445  0.268791  0.090108  0.167674 -0.040622  1.000000   \n",
      "7  0.285796  0.101757  0.071208 -0.042263  0.088846  0.029369  0.108098   \n",
      "\n",
      "          7  \n",
      "0  0.285796  \n",
      "1  0.101757  \n",
      "2  0.071208  \n",
      "3 -0.042263  \n",
      "4  0.088846  \n",
      "5  0.029369  \n",
      "6  0.108098  \n",
      "7  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################## Concat Data1 +  Data2 ##################################\n",
    "# Combine the DataFrames using pd.concat to maintain the data types\n",
    "combined_data = pd.concat([data1, data2], ignore_index=True)\n",
    "\n",
    " \n",
    "\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in combined_data.columns[-5:]:\n",
    "    combined_data[col] = combined_data[col].astype(int)\n",
    "\n",
    "# Convert the last 5 columns to categorical\n",
    "for col in combined_data.columns[-5:]:\n",
    "    combined_data[col] = combined_data[col].astype('category')\n",
    "\n",
    "print(combined_data.dtypes)\n",
    "\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = combined_data.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = combined_data.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "##################### Chi-Square (F vs label column) Code ####################################\n",
    "    \n",
    "print(\"\\n------------------------Chi-Square (F vs label column)------------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train & the label in y_train\n",
    "def chi_squared_fvl(X_train_categorical, y_train):\n",
    "        \n",
    "    # Combining CATEGORICAL X_train and y_train\n",
    "    df = X_train_categorical\n",
    "    df['label'] = y_train\n",
    "\n",
    "    # Number of features, excluding label\n",
    "    var_count = len(df.columns)-1\n",
    "\n",
    "    # Creates an empty array to print values in a table\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, var_count):\n",
    "\n",
    "        # Create contigency table of all features v. label\n",
    "        crosstab = pd.crosstab(df.iloc[:, i], df.iloc[:,-1])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(crosstab)[0]\n",
    "        p = stats.chi2_contingency(crosstab)[1]\n",
    "            \n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            \"Feature\": df.columns[i],\n",
    "            \"Chi Squared Statistic\": chi2,\n",
    "            \"P-Value\": p})\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(\"Label:\", df.columns.values[-1])\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    return p\n",
    "    \n",
    "p = chi_squared_fvl(categorical_df, y_train)\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df2 = p < 0.05\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Count of Changes in p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correlation_df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the dataframes to numpy arrays\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m matrix1 \u001b[38;5;241m=\u001b[39m correlation_df1\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      3\u001b[0m matrix2 \u001b[38;5;241m=\u001b[39m correlation_df_combined\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Compute the Frobenius norm of the difference between the matrices. \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'correlation_df1' is not defined"
     ]
    }
   ],
   "source": [
    "# Count the changes between the two DataFrames\n",
    "changes = (p_value_df1 != p_value_df2).sum().sum()\n",
    "\n",
    "# Display the number of changes\n",
    "print(f\"Number of changes between p_value_df1 and p_value_df2: {changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc684e8-8f56-4515-856e-3acfc391156e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
