{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Important: F vs L --> Chi-Square Test \n",
    "- Chi-Square prints a p-values column  that will be changed to True and False. If the p-value is less than 0.05, then there is NO relationship, this is print TRUE (H0: null hypothesis). Otherwise, if p > 0.05 there is a relationship, this will print FALSE (Ha:  Alternative hypothesis)\n",
    "- Goal is to print the count of the changes -->  from True to False OR from False to True\n",
    "- Both data1 and data2 MUST have the same number of numerical and categorical columns. We will test 13 columns for all datasets with 8 'numerical'(at the beginning) and 5 'categorical' columns (at the end, including the label column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets before augmentation (synthetic)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "\n",
    "\n",
    "\n",
    "# Datasets after augmentation\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_modpmone.csv\")\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_randswap.csv\")\n",
    "\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_modpmone.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_randswap.csv\")\n",
    "\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_modpmone.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_randswap.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4da3c-70a9-4341-ab46-96503acf41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342ce62-6b9f-490b-b217-955882244eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a276c-f28c-4cca-8662-f7f1f936a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Shapes of Datasets\n",
    "- They must be the same, if they are not--> run specific cells to make them have the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes for debugging \n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d026e7b-e0be-4cf2-b068-dd2fd0bfb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end    \n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data1_last_13 = data1.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "#data1_last_13.iloc[:, -5:] = data1_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)   #only for synthetic dataset\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a988e-8a03-404a-9206-7faaf36f7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_last_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fac50d-4e8e-40e9-8e67-c1cdfc3fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data2_last_13 = data2.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "data2_last_13.iloc[:, -5:] = data2_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8798a63-605b-48ee-b620-dba800edeacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_last_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fbade-0f5e-4752-8110-2d6f812ae665",
   "metadata": {},
   "source": [
    "# Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743336-8bf3-433e-a128-e8fc8aa271a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data1_last_13 = data1.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "#data1_last_13.iloc[:, -5:] = data1_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce98c2-f7dc-49e1-9624-7427b50635dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_last_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7b1d3-21b2-46c9-aa8c-a812252bdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data2_last_13 = data2.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "data2_last_13.iloc[:, -5:] = data2_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a4bcc-c113-4b03-bca2-e09c816f7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_last_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Stacked Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52c5ceb-1aed-47cd-ae7e-e3b4a3d29d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the first 8 columns and the last 5 columns (which are the primary columns)\n",
    "data1_last_13 = pd.concat([data1.iloc[:, :8], data1.iloc[:, -5:]], axis=1)\n",
    "\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea51e75-0b6a-4b86-a71a-1ce4ad8eda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_last_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d77a2f5-985d-4e5f-8eb9-d0eb5be1887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the first 8 columns and the last 5 columns (which are the primary columns)\n",
    "data2_last_13 = pd.concat([data2.iloc[:, :8], data2.iloc[:, -5:]], axis=1)\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a621944f-c74d-4601-b537-8eb42b1311f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_last_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Data1: Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8       int64\n",
      "9       int64\n",
      "10      int64\n",
      "11      int64\n",
      "12      int64\n",
      "dtype: object\n",
      "\n",
      "------------------------Chi-Square (F vs label column)------------------------\n",
      "Label: label\n",
      " Feature  Chi Squared Statistic      P-Value\n",
      "       8               6.492573 2.611937e-01\n",
      "       9               1.711738 9.442115e-01\n",
      "      10               2.030934 8.448483e-01\n",
      "      11               1.653664 8.946848e-01\n",
      "      12             236.016667 2.905894e-53\n",
      "----------- Chi-Square (F vs L) True and False ------------\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "Name: P-Value, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in data1_last_13.columns[-5:]:\n",
    "    data1_last_13[col] = data1_last_13[col].astype(int)\n",
    "\n",
    "print(data1_last_13.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting numerical subset \n",
    "numerical_df = data1_last_13.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting categorical subset \n",
    "categorical_df = data1_last_13.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "##################### Chi-Square (F vs label column) Code ####################################\n",
    "# Extract y_train (column with index 12)\n",
    "y_train = data1_last_13.iloc[:, 12]    \n",
    "\n",
    "print(\"\\n------------------------Chi-Square (F vs label column)------------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train & the label in y_train\n",
    "def chi_squared_fvl(X_train_categorical, y_train):\n",
    "        \n",
    "    # Combining CATEGORICAL X_train and y_train\n",
    "    df = X_train_categorical\n",
    "    df['label'] = y_train\n",
    "\n",
    "    # Number of features, excluding label\n",
    "    var_count = len(df.columns)-1\n",
    "\n",
    "    # Creates an empty array to print values in a table\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, var_count):\n",
    "\n",
    "        # Create contigency table of all features v. label\n",
    "        crosstab = pd.crosstab(df.iloc[:, i], df.iloc[:,-1])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(crosstab)[0]\n",
    "        p = stats.chi2_contingency(crosstab)[1]\n",
    "            \n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            \"Feature\": df.columns[i],\n",
    "            \"Chi Squared Statistic\": chi2,\n",
    "            \"P-Value\": p})\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(\"Label:\", df.columns.values[-1])\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    return results_df\n",
    "    \n",
    "results_df = chi_squared_fvl(categorical_df, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "print(\"----------- Chi-Square (F vs L) True and False ------------\")\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df1 = results_df['P-Value'] < 0.05\n",
    "#p_value_df1 = pd.DataFrame(p_value_df1, columns=['Significant'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Data1 + Data2: Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Concat Data1 +  Data2 ##################################\n",
    "# Combine the DataFrames using pd.concat to maintain the data types\n",
    "combined_data = pd.concat([data1_last_13, data2_last_13], ignore_index=True)\n",
    "\n",
    " \n",
    "\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in combined_data.columns[-5:]:\n",
    "    combined_data[col] = combined_data[col].astype(int)\n",
    "\n",
    "\n",
    "print(combined_data.dtypes)\n",
    "\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = combined_data.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = combined_data.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "##################### Chi-Square (F vs label column) Code ####################################\n",
    "# Extract y_train (column with index 12)\n",
    "y_train = combined_data.iloc[:, 12]    \n",
    "\n",
    "print(\"\\n------------------------Chi-Square (F vs label column)------------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train & the label in y_train\n",
    "def chi_squared_fvl(X_train_categorical, y_train):\n",
    "        \n",
    "    # Combining CATEGORICAL X_train and y_train\n",
    "    df = X_train_categorical\n",
    "    df['label'] = y_train\n",
    "\n",
    "    # Number of features, excluding label\n",
    "    var_count = len(df.columns)-1\n",
    "\n",
    "    # Creates an empty array to print values in a table\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, var_count):\n",
    "\n",
    "        # Create contigency table of all features v. label\n",
    "        crosstab = pd.crosstab(df.iloc[:, i], df.iloc[:,-1])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(crosstab)[0]\n",
    "        p = stats.chi2_contingency(crosstab)[1]\n",
    "            \n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            \"Feature\": df.columns[i],\n",
    "            \"Chi Squared Statistic\": chi2,\n",
    "            \"P-Value\": p})\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(\"Label:\", df.columns.values[-1])\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    return results_df\n",
    "    \n",
    "results_df = chi_squared_fvl(categorical_df, y_train)\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "print(\"----------- Chi-Square (F vs L) True and False ------------\")\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df2 = results_df['P-Value'] < 0.05\n",
    "#p_value_df1 = pd.DataFrame(p_value_df1, columns=['Significant'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f87bee-ae3e-4003-a259-a684b812c873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8       int64\n",
      "9       int64\n",
      "10      int64\n",
      "11      int64\n",
      "12      int64\n",
      "dtype: object\n",
      "\n",
      "------------------------Chi-Square (F vs label column)------------------------\n",
      "Label: label\n",
      " Feature  Chi Squared Statistic       P-Value\n",
      "       8              14.135766  1.476963e-02\n",
      "       9              11.575815  7.212909e-02\n",
      "      10               2.692093  7.473276e-01\n",
      "      11               5.998937  3.063224e-01\n",
      "      12             474.972883 2.652437e-105\n",
      "----------- Chi-Square (F vs L) True and False ------------\n",
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "Name: P-Value, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#IF YOU DO NOT NEED TO CONCAT USE THIS\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in data2_last_13.columns[-5:]:\n",
    "    data2_last_13[col] = data2_last_13[col].astype(int)\n",
    "\n",
    "print(data2_last_13.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting numerical subset \n",
    "numerical_df = data2_last_13.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting categorical subset \n",
    "categorical_df = data2_last_13.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "##################### Chi-Square (F vs label column) Code ####################################\n",
    "# Extract y_train (column with index 12)\n",
    "y_train = data2_last_13.iloc[:, 12]    \n",
    "\n",
    "print(\"\\n------------------------Chi-Square (F vs label column)------------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train & the label in y_train\n",
    "def chi_squared_fvl(X_train_categorical, y_train):\n",
    "        \n",
    "    # Combining CATEGORICAL X_train and y_train\n",
    "    df = X_train_categorical\n",
    "    df['label'] = y_train\n",
    "\n",
    "    # Number of features, excluding label\n",
    "    var_count = len(df.columns)-1\n",
    "\n",
    "    # Creates an empty array to print values in a table\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, var_count):\n",
    "\n",
    "        # Create contigency table of all features v. label\n",
    "        crosstab = pd.crosstab(df.iloc[:, i], df.iloc[:,-1])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(crosstab)[0]\n",
    "        p = stats.chi2_contingency(crosstab)[1]\n",
    "            \n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            \"Feature\": df.columns[i],\n",
    "            \"Chi Squared Statistic\": chi2,\n",
    "            \"P-Value\": p})\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(\"Label:\", df.columns.values[-1])\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    return results_df\n",
    "    \n",
    "results_df = chi_squared_fvl(categorical_df, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "print(\"----------- Chi-Square (F vs L) True and False ------------\")\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df2 = results_df['P-Value'] < 0.05\n",
    "#p_value_df1 = pd.DataFrame(p_value_df1, columns=['Significant'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Count of Changes in p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of changes between p_value_df1 and p_value_df2: 1\n"
     ]
    }
   ],
   "source": [
    "# Count the changes between the two DataFrames\n",
    "changes = (p_value_df1 != p_value_df2).sum().sum()\n",
    "\n",
    "# Display the number of changes\n",
    "print(f\"Number of changes between p_value_df1 and p_value_df2: {changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177aebf5-574e-43f5-802c-1cefc552cf49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
