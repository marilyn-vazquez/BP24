{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Note:\n",
    "-(make sure both data1 and data2 have the same number of numerical and categorical columns)\n",
    "- Run all the cells for data1\n",
    "- Then, run all the cells for data2\n",
    "- Then after you have the correlation matrices for both (data1 and data2) --> run the difference between matrices test\n",
    "- This is the only way this file will work. If you dont follow the steps you will get a result of ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset before augmentation\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "\n",
    "# Dataset after augmentation\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Check Shapes of Datasets (they must be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data1: (240, 25)\n",
      "Shape of data2: (172, 13)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes for debugging\n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d71858-9d7a-4db8-a3b0-e99c76cecf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the datasets do not have the same columns ---> make one dataset match the other one (order does not matter)\n",
    "# Subset columns so both have the same \n",
    "# (we need to make sure we have the same categorical and numerical columns) ---> you do this after this cell\n",
    "data1 = data1.iloc[:, -13:]\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Convert columns into Categorical (Only for Uniform and Gaussian Distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19945cd3-4527-4754-96d4-0e0f5576c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-5,0):\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype(int) # Integer\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype('category') # Categories\n",
    "data1.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e56a28d-5d28-4f27-bab4-c783ae3a7443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      float64\n",
       "1      float64\n",
       "2      float64\n",
       "3      float64\n",
       "4      float64\n",
       "5      float64\n",
       "6      float64\n",
       "7      float64\n",
       "8     category\n",
       "9     category\n",
       "10    category\n",
       "11    category\n",
       "12    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(-5,0):\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype(int) # Integer\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype('category') # Categories\n",
    "data2.dtypes\n",
    "#data2.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Convert columns into Categorical (Only for Stacked Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab01b550-9ba2-4d84-8bc0-a5d28d05d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12     float64\n",
      "13     float64\n",
      "14     float64\n",
      "15     float64\n",
      "16     float64\n",
      "17     float64\n",
      "18     float64\n",
      "19     float64\n",
      "20    category\n",
      "21    category\n",
      "22    category\n",
      "23    category\n",
      "24    category\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gq/wfvm6zt96_vgyjdb9mtbd22w0000gn/T/ipykernel_52019/4157493419.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1[column] = data1[column].astype('category')\n"
     ]
    }
   ],
   "source": [
    "for column in data1.columns[-5:]:\n",
    "    data1[column] = data1[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe6694-f2b0-43b4-90a1-fc8e2034b417",
   "metadata": {},
   "source": [
    "# Concat Synthetic Dataset with New generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bc977ca-c4fc-45e1-8a6b-1d11a262ae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12     float64\n",
      "13     float64\n",
      "14     float64\n",
      "15     float64\n",
      "16     float64\n",
      "17     float64\n",
      "18     float64\n",
      "19     float64\n",
      "20    category\n",
      "21    category\n",
      "22    category\n",
      "23    category\n",
      "24    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Concat (adding rows)\n",
    "combined_df = np.vstack((data1, data2))\n",
    "\n",
    "# change numpy array into a dataframe\n",
    "combined_data = pd.DataFrame(combined_df, columns=data1.columns)\n",
    "\n",
    "# Convert the last number of columns to categorical (to make sure they have the same)\n",
    "for column in combined_data.columns[-5:]:\n",
    "    combined_data[column] = combined_data[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Split Dataset for combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into X and y (data1)\n",
    "X = combined_data.iloc[:, :-1]  # All columns except the last one\n",
    "y = combined_data.iloc[:, -1]   # Only the last column\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Split Dataset for Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2\n",
    "X = data1.iloc[:, :-1]\n",
    "y = data1.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30441ffc-4e6b-44be-94fb-4366c680c6ec",
   "metadata": {},
   "source": [
    "# Correlation between columns test (Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7781a524-15f7-4da5-95ab-24800c49ed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Correlation Matrix------------------------- \n",
      "           12        13        14        15        16        17        18  \\\n",
      "12  1.000000  0.943284  0.939711  0.934689  0.898560  0.870749  0.899566   \n",
      "13  0.943284  1.000000  0.936787  0.932852  0.898200  0.869270  0.902307   \n",
      "14  0.939711  0.936787  1.000000  0.922441  0.897029  0.868319  0.888365   \n",
      "15  0.934689  0.932852  0.922441  1.000000  0.880236  0.865008  0.876035   \n",
      "16  0.898560  0.898200  0.897029  0.880236  1.000000  0.818155  0.852094   \n",
      "17  0.870749  0.869270  0.868319  0.865008  0.818155  1.000000  0.829553   \n",
      "18  0.899566  0.902307  0.888365  0.876035  0.852094  0.829553  1.000000   \n",
      "19  0.901112  0.897352  0.880754  0.889584  0.849885  0.838820  0.854342   \n",
      "\n",
      "          19  \n",
      "12  0.901112  \n",
      "13  0.897352  \n",
      "14  0.880754  \n",
      "15  0.889584  \n",
      "16  0.849885  \n",
      "17  0.838820  \n",
      "18  0.854342  \n",
      "19  1.000000  \n"
     ]
    }
   ],
   "source": [
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f7e8a-ca00-46fa-be6a-7daa0025486e",
   "metadata": {},
   "source": [
    "# Save Correlation Matrix into a Dataframe for combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3bb1258-3e08-4365-a4eb-364b74bb224b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          12        13        14        15        16        17        18  \\\n",
      "12  1.000000  0.943284  0.939711  0.934689  0.898560  0.870749  0.899566   \n",
      "13  0.943284  1.000000  0.936787  0.932852  0.898200  0.869270  0.902307   \n",
      "14  0.939711  0.936787  1.000000  0.922441  0.897029  0.868319  0.888365   \n",
      "15  0.934689  0.932852  0.922441  1.000000  0.880236  0.865008  0.876035   \n",
      "16  0.898560  0.898200  0.897029  0.880236  1.000000  0.818155  0.852094   \n",
      "17  0.870749  0.869270  0.868319  0.865008  0.818155  1.000000  0.829553   \n",
      "18  0.899566  0.902307  0.888365  0.876035  0.852094  0.829553  1.000000   \n",
      "19  0.901112  0.897352  0.880754  0.889584  0.849885  0.838820  0.854342   \n",
      "\n",
      "          19  \n",
      "12  0.901112  \n",
      "13  0.897352  \n",
      "14  0.880754  \n",
      "15  0.889584  \n",
      "16  0.849885  \n",
      "17  0.838820  \n",
      "18  0.854342  \n",
      "19  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combined_data\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df_combined = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df_combined)\n",
    "\n",
    "correlation_df_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49456482-97cc-4ee1-86d8-f89bf61e4f8f",
   "metadata": {},
   "source": [
    "# Save Correlation Matrix into a Dataframe for Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37eb9739-986a-486b-b499-053be1e7031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          12        13        14        15        16        17        18  \\\n",
      "12  1.000000  0.236666  0.273645  0.318585  0.123840  0.046459  0.023146   \n",
      "13  0.236666  1.000000  0.247445  0.269546  0.101889 -0.092261 -0.066529   \n",
      "14  0.273645  0.247445  1.000000  0.441324  0.015980  0.021592 -0.079043   \n",
      "15  0.318585  0.269546  0.441324  1.000000  0.040692  0.038481 -0.051545   \n",
      "16  0.123840  0.101889  0.015980  0.040692  1.000000 -0.041861  0.016662   \n",
      "17  0.046459 -0.092261  0.021592  0.038481 -0.041861  1.000000  0.073212   \n",
      "18  0.023146 -0.066529 -0.079043 -0.051545  0.016662  0.073212  1.000000   \n",
      "19  0.096953 -0.117292 -0.023616  0.066835  0.044408  0.031343  0.034735   \n",
      "\n",
      "          19  \n",
      "12  0.096953  \n",
      "13 -0.117292  \n",
      "14 -0.023616  \n",
      "15  0.066835  \n",
      "16  0.044408  \n",
      "17  0.031343  \n",
      "18  0.034735  \n",
      "19  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data1\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df1 = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df1)\n",
    "\n",
    "correlation_df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Differences in Matrices (Frobenius Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm difference:  6.139\n",
      "Frobenius absolute error :  2.012\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataframes to numpy arrays\n",
    "matrix1 = correlation_df1.to_numpy()\n",
    "matrix2 = correlation_df_combined.to_numpy()\n",
    "\n",
    "# Compute the Frobenius norm of the difference between the matrices. \n",
    "frobenius_abs = np.linalg.norm(matrix1 - matrix2, ord='fro')   # Absolute error with Frobenius norm\n",
    "\n",
    "frobenius_rel = frobenius_abs/np.linalg.norm(matrix1, ord='fro')    # Relative error with Frobenius norm\n",
    "\n",
    "print(f\"Frobenius norm difference (absolute error) : {frobenius_abs: .3f}\")\n",
    "print(f\"Frobenius notrelative error : {frobenius_rel: .3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893a07c-00f8-4041-ae4b-77e155738f6f",
   "metadata": {},
   "source": [
    "# Differences in Arrays (L2 Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e65e78-7871-4fc8-a693-b5c2ad10229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array1 ...\n",
    "#array2 ...\n",
    "\n",
    "# Compute the L2 norm (Euclidean norm) of the difference between the arrays\n",
    "L2_norm = np.linalg.norm(array1 - array2, ord=2)\n",
    "\n",
    "print(f\"L2 norm difference: {L2_norm: .3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996e1a0-7162-478b-87bc-f7ac46404aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
