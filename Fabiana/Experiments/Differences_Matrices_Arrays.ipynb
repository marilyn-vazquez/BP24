{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Note:\n",
    "-(make sure both data1 and data2 have the same number of numerical and categorical columns)\n",
    "- Run all the cells for data1\n",
    "- Then, run all the cells for data2\n",
    "- Then after you have the correlation matrices for both (data1 and data2) --> run the difference between matrices test\n",
    "- This is the only way this file will work. If you dont follow the steps you will get a result of ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset before augmentation\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "\n",
    "# Dataset after augmentation\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data1: (240, 25)\n",
      "Shape of data2: (172, 13)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes for debugging\n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b8d71858-9d7a-4db8-a3b0-e99c76cecf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 13)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset the last 13 columns for the dataset with the 25 columns \n",
    "#(we need to make sure we have the same categorical and numerical columns)\n",
    "data1 = data1.iloc[:, -13:]\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Convert columns into categorical (Only for Uniform and Gaussian Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "19945cd3-4527-4754-96d4-0e0f5576c01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      float64\n",
       "1      float64\n",
       "2      float64\n",
       "3      float64\n",
       "4      float64\n",
       "5      float64\n",
       "6      float64\n",
       "7      float64\n",
       "8      float64\n",
       "9      float64\n",
       "10     float64\n",
       "11     float64\n",
       "12     float64\n",
       "13     float64\n",
       "14     float64\n",
       "15     float64\n",
       "16    category\n",
       "17    category\n",
       "18    category\n",
       "19    category\n",
       "20    category\n",
       "21    category\n",
       "22    category\n",
       "23    category\n",
       "24    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(-5,0):\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype(int) # Integer\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype('category') # Categories\n",
    "data1.dtypes\n",
    "#data2.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2e56a28d-5d28-4f27-bab4-c783ae3a7443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      float64\n",
       "1      float64\n",
       "2      float64\n",
       "3      float64\n",
       "4      float64\n",
       "5      float64\n",
       "6      float64\n",
       "7      float64\n",
       "8     category\n",
       "9     category\n",
       "10    category\n",
       "11    category\n",
       "12    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(-5,0):\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype(int) # Integer\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype('category') # Categories\n",
    "data2.dtypes\n",
    "#data2.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Convert Last 9 columns to Categorical (Only for Stacked Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ab01b550-9ba2-4d84-8bc0-a5d28d05d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12     float64\n",
      "13     float64\n",
      "14     float64\n",
      "15     float64\n",
      "16     float64\n",
      "17     float64\n",
      "18     float64\n",
      "19     float64\n",
      "20    category\n",
      "21    category\n",
      "22    category\n",
      "23    category\n",
      "24    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#data1\n",
    "# Convert the last 9 columns to categorical\n",
    "for column in data1.columns[-5:]:\n",
    "    data1[column] = data1[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe6694-f2b0-43b4-90a1-fc8e2034b417",
   "metadata": {},
   "source": [
    "# Concat Original dataset with New generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1bc977ca-c4fc-45e1-8a6b-1d11a262ae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12     float64\n",
      "13     float64\n",
      "14     float64\n",
      "15     float64\n",
      "16     float64\n",
      "17     float64\n",
      "18     float64\n",
      "19     float64\n",
      "20    category\n",
      "21    category\n",
      "22    category\n",
      "23    category\n",
      "24    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Concat (adding rows)\n",
    "combined_df = np.vstack((data1, data2))\n",
    "\n",
    "# Reset the index to ensure a clean, continuous index\n",
    "#combined_df.reset_index(drop=True, inplace=True)\n",
    "combined_df.shape\n",
    "combined_df\n",
    "\n",
    "# change numpy array into a dataframe\n",
    "combined_data = pd.DataFrame(combined_df, columns=data1.columns)\n",
    "combined_data\n",
    "\n",
    "# Convert the last 9 columns to categorical\n",
    "for column in combined_data.columns[-5:]:\n",
    "    combined_data[column] = combined_data[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into X and y (data1)\n",
    "X = combined_data.iloc[:, :-1]  # All columns except the last one\n",
    "y = combined_data.iloc[:, -1]   # Only the last column\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "84a9fde3-72eb-48dd-a97a-879cf278b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2\n",
    "X = data1.iloc[:, :-1]\n",
    "y = data1.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30441ffc-4e6b-44be-94fb-4366c680c6ec",
   "metadata": {},
   "source": [
    "# Correlation between columns test (Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7781a524-15f7-4da5-95ab-24800c49ed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Correlation Matrix------------------------- \n",
      "           12        13        14        15        16        17        18  \\\n",
      "12  1.000000  0.943284  0.939711  0.934689  0.898560  0.870749  0.899566   \n",
      "13  0.943284  1.000000  0.936787  0.932852  0.898200  0.869270  0.902307   \n",
      "14  0.939711  0.936787  1.000000  0.922441  0.897029  0.868319  0.888365   \n",
      "15  0.934689  0.932852  0.922441  1.000000  0.880236  0.865008  0.876035   \n",
      "16  0.898560  0.898200  0.897029  0.880236  1.000000  0.818155  0.852094   \n",
      "17  0.870749  0.869270  0.868319  0.865008  0.818155  1.000000  0.829553   \n",
      "18  0.899566  0.902307  0.888365  0.876035  0.852094  0.829553  1.000000   \n",
      "19  0.901112  0.897352  0.880754  0.889584  0.849885  0.838820  0.854342   \n",
      "\n",
      "          19  \n",
      "12  0.901112  \n",
      "13  0.897352  \n",
      "14  0.880754  \n",
      "15  0.889584  \n",
      "16  0.849885  \n",
      "17  0.838820  \n",
      "18  0.854342  \n",
      "19  1.000000  \n"
     ]
    }
   ],
   "source": [
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n",
    "\n",
    "# Print the dataframe to verify\n",
    "#print(correlation_matrix)\n",
    "#0.860\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f7e8a-ca00-46fa-be6a-7daa0025486e",
   "metadata": {},
   "source": [
    "# Save Correlation Matrix into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c3bb1258-3e08-4365-a4eb-364b74bb224b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          12        13        14        15        16        17        18  \\\n",
      "12  1.000000  0.943284  0.939711  0.934689  0.898560  0.870749  0.899566   \n",
      "13  0.943284  1.000000  0.936787  0.932852  0.898200  0.869270  0.902307   \n",
      "14  0.939711  0.936787  1.000000  0.922441  0.897029  0.868319  0.888365   \n",
      "15  0.934689  0.932852  0.922441  1.000000  0.880236  0.865008  0.876035   \n",
      "16  0.898560  0.898200  0.897029  0.880236  1.000000  0.818155  0.852094   \n",
      "17  0.870749  0.869270  0.868319  0.865008  0.818155  1.000000  0.829553   \n",
      "18  0.899566  0.902307  0.888365  0.876035  0.852094  0.829553  1.000000   \n",
      "19  0.901112  0.897352  0.880754  0.889584  0.849885  0.838820  0.854342   \n",
      "\n",
      "          19  \n",
      "12  0.901112  \n",
      "13  0.897352  \n",
      "14  0.880754  \n",
      "15  0.889584  \n",
      "16  0.849885  \n",
      "17  0.838820  \n",
      "18  0.854342  \n",
      "19  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combined_data\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df_combined = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df_combined)\n",
    "\n",
    "correlation_df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "37eb9739-986a-486b-b499-053be1e7031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          12        13        14        15        16        17        18  \\\n",
      "12  1.000000  0.236666  0.273645  0.318585  0.123840  0.046459  0.023146   \n",
      "13  0.236666  1.000000  0.247445  0.269546  0.101889 -0.092261 -0.066529   \n",
      "14  0.273645  0.247445  1.000000  0.441324  0.015980  0.021592 -0.079043   \n",
      "15  0.318585  0.269546  0.441324  1.000000  0.040692  0.038481 -0.051545   \n",
      "16  0.123840  0.101889  0.015980  0.040692  1.000000 -0.041861  0.016662   \n",
      "17  0.046459 -0.092261  0.021592  0.038481 -0.041861  1.000000  0.073212   \n",
      "18  0.023146 -0.066529 -0.079043 -0.051545  0.016662  0.073212  1.000000   \n",
      "19  0.096953 -0.117292 -0.023616  0.066835  0.044408  0.031343  0.034735   \n",
      "\n",
      "          19  \n",
      "12  0.096953  \n",
      "13 -0.117292  \n",
      "14 -0.023616  \n",
      "15  0.066835  \n",
      "16  0.044408  \n",
      "17  0.031343  \n",
      "18  0.034735  \n",
      "19  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data1\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df1 = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df1)\n",
    "\n",
    "correlation_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fdaf84-9cc3-4746-aa8b-8ce5f9a6bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df2 = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df2)\n",
    "\n",
    "correlation_df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Differences in Matrices (Frobenius Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm difference:  6.139\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataframes to numpy arrays\n",
    "matrix1 = correlation_df1.to_numpy()\n",
    "matrix2 = correlation_df_combined.to_numpy()\n",
    "\n",
    "# Compute the Frobenius norm of the difference between the matrices. \n",
    "frobenius_norm = np.linalg.norm(matrix1 - matrix2, ord='fro')\n",
    "#axis= 1 goes across columns\n",
    "#axis = 0 goes across rows\n",
    "\n",
    "\n",
    "print(f\"Frobenius norm difference: {frobenius_norm: .3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893a07c-00f8-4041-ae4b-77e155738f6f",
   "metadata": {},
   "source": [
    "# Differences in Arrays (L2 Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e65e78-7871-4fc8-a693-b5c2ad10229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array1 ...\n",
    "#array2 ...\n",
    "\n",
    "# Compute the L2 norm (Euclidean norm) of the difference between the arrays\n",
    "L2_norm = np.linalg.norm(array1 - array2, ord=2)\n",
    "\n",
    "print(f\"L2 norm difference: {L2_norm: .3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996e1a0-7162-478b-87bc-f7ac46404aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
