{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Note:\n",
    "-(make sure both data1 and data2 have the same number of numerical and categorical columns)\n",
    "- Run all the cells for data1\n",
    "- Then, run all the cells for data2\n",
    "- Then after you have the correlation matrices for both (data1 and data2) --> run the difference between matrices test\n",
    "- This is the only way this file will work. If you dont follow the steps you will get a result of ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset before augmentation\n",
    "# data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "\n",
    "\n",
    "# Dataset after augmentation\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Check Shapes of Datasets (they must be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data1: (172, 13)\n",
      "Shape of data2: (240, 25)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes for debugging\n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d71858-9d7a-4db8-a3b0-e99c76cecf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the datasets do not have the same columns ---> make one dataset match the other one (order does not matter)\n",
    "# Subset columns so both have the same \n",
    "# (we need to make sure we have the same categorical and numerical columns) ---> you do this after this cell\n",
    "data2 = data2.iloc[:, -13:]\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Convert columns into Categorical (Only for Uniform and Gaussian Distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19945cd3-4527-4754-96d4-0e0f5576c01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      float64\n",
       "1      float64\n",
       "2      float64\n",
       "3      float64\n",
       "4      float64\n",
       "5      float64\n",
       "6      float64\n",
       "7      float64\n",
       "8     category\n",
       "9     category\n",
       "10    category\n",
       "11    category\n",
       "12    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(-5,0):\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype(int) # Integer\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype('category') # Categories\n",
    "data1.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56a28d-5d28-4f27-bab4-c783ae3a7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-5,0):\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype(int) # Integer\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype('category') # Categories\n",
    "data2.dtypes\n",
    "#data2.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Convert columns into Categorical (Only for Stacked Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01b550-9ba2-4d84-8bc0-a5d28d05d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data1.columns[-9:]:\n",
    "    data1[column] = data1[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80cb0028-67a8-4fec-bcac-e4cee2a22d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12     float64\n",
      "13     float64\n",
      "14     float64\n",
      "15     float64\n",
      "16     float64\n",
      "17     float64\n",
      "18     float64\n",
      "19     float64\n",
      "20    category\n",
      "21    category\n",
      "22    category\n",
      "23    category\n",
      "24    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "for column in data2.columns[-5:]:\n",
    "    data2[column] = data2[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(data2.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Data1: Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2\n",
    "X = data1.iloc[:, :-1]\n",
    "y = data1.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n",
    "\n",
    "\n",
    "\n",
    "#################### save Data1 matrix as a dataframe #################################\n",
    "#data1\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df1 = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df1)\n",
    "\n",
    "correlation_df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Data1 + Data2: Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Concat Data1 +  Data2 ##################################\n",
    "# Concat (adding rows)\n",
    "combined_df = np.vstack((data1, data2))\n",
    "\n",
    "# change numpy array into a dataframe\n",
    "combined_data = pd.DataFrame(combined_df, columns=data1.columns)\n",
    "\n",
    "# Convert the last number of columns to categorical (to make sure they have the same)\n",
    "for column in combined_data.columns[-5:]:\n",
    "    combined_data[column] = combined_data[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_data.dtypes)\n",
    "\n",
    "\n",
    "##################### Split Combined_data ################################\n",
    "\n",
    "# Split dataset into X and y (data1)\n",
    "X = combined_data.iloc[:, :-1]  # All columns except the last one\n",
    "y = combined_data.iloc[:, -1]   # Only the last column\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n",
    "\n",
    "\n",
    "############################## save combined_data matrix as a dataframe ############################\n",
    "#combined_data\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df_combined = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df_combined)\n",
    "\n",
    "correlation_df_combined.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Differences in Matrices (Frobenius Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm (absolute error) :  5.313\n",
      "Frobenius norm (relative error) :  1.669\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataframes to numpy arrays\n",
    "matrix1 = correlation_df1.to_numpy()\n",
    "matrix2 = correlation_df_combined.to_numpy()\n",
    "\n",
    "# Compute the Frobenius norm of the difference between the matrices. \n",
    "frobenius_abs = np.linalg.norm(matrix1 - matrix2, ord='fro')   # Absolute error with Frobenius norm\n",
    "\n",
    "frobenius_rel = frobenius_abs/np.linalg.norm(matrix1, ord='fro')    # Relative error with Frobenius norm\n",
    "\n",
    "print(f\"Frobenius norm (absolute error) : {frobenius_abs: .3f}\")\n",
    "print(f\"Frobenius norm (relative error) : {frobenius_rel: .3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893a07c-00f8-4041-ae4b-77e155738f6f",
   "metadata": {},
   "source": [
    "# Differences in Arrays (L2 Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e65e78-7871-4fc8-a693-b5c2ad10229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array1 ...\n",
    "#array2 ...\n",
    "\n",
    "# Compute the L2 norm (Euclidean norm) of the difference between the arrays\n",
    "L2_norm = np.linalg.norm(array1 - array2, ord=2)\n",
    "\n",
    "print(f\"L2 norm difference: {L2_norm: .3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
