{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Note:\n",
    "-(make sure both data1 and data2 have the same number of numerical and categorical columns)\n",
    "- Run all the cells for data1\n",
    "- Then, run all the cells for data2\n",
    "- Then after you have the correlation matrices for both (data1 and data2) --> run the difference between matrices test\n",
    "- This is the only way this file will work. If you dont follow the steps you will get a result of ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset before augmentation\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "\n",
    "# Dataset after augmentation\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Check Shapes of Datasets (they must be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes for debugging\n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d71858-9d7a-4db8-a3b0-e99c76cecf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the datasets do not have the same columns ---> make one dataset match the other one (order does not matter)\n",
    "# Subset columns so both have the same \n",
    "# (we need to make sure we have the same categorical and numerical columns) ---> you do this after this cell\n",
    "data1 = data1.iloc[:, -13:]\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Convert columns into Categorical (Only for Uniform and Gaussian Distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19945cd3-4527-4754-96d4-0e0f5576c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-5,0):\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype(int) # Integer\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype('category') # Categories\n",
    "data1.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56a28d-5d28-4f27-bab4-c783ae3a7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-5,0):\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype(int) # Integer\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype('category') # Categories\n",
    "data2.dtypes\n",
    "#data2.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Convert columns into Categorical (Only for Stacked Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01b550-9ba2-4d84-8bc0-a5d28d05d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data1.columns[-5:]:\n",
    "    data1[column] = data1[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe6694-f2b0-43b4-90a1-fc8e2034b417",
   "metadata": {},
   "source": [
    "# Concat Synthetic Dataset with New generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc977ca-c4fc-45e1-8a6b-1d11a262ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat (adding rows)\n",
    "combined_df = np.vstack((data1, data2))\n",
    "\n",
    "# change numpy array into a dataframe\n",
    "combined_data = pd.DataFrame(combined_df, columns=data1.columns)\n",
    "\n",
    "# Convert the last number of columns to categorical (to make sure they have the same)\n",
    "#for column in combined_data.columns[-5:]:\n",
    "    #combined_data[column] = combined_data[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Split Dataset for combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into X and y (data1)\n",
    "X = combined_data.iloc[:, :-1]  # All columns except the last one\n",
    "y = combined_data.iloc[:, -1]   # Only the last column\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Split Dataset for Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2\n",
    "X = data1.iloc[:, :-1]\n",
    "y = data1.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30441ffc-4e6b-44be-94fb-4366c680c6ec",
   "metadata": {},
   "source": [
    "# Correlation between columns test (Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781a524-15f7-4da5-95ab-24800c49ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n",
    "\n",
    "# Print the dataframe to verify\n",
    "#print(correlation_matrix)\n",
    "#0.860\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f7e8a-ca00-46fa-be6a-7daa0025486e",
   "metadata": {},
   "source": [
    "# Save Correlation Matrix into a Dataframe for combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb1258-3e08-4365-a4eb-364b74bb224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_data\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df_combined = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df_combined)\n",
    "\n",
    "correlation_df_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49456482-97cc-4ee1-86d8-f89bf61e4f8f",
   "metadata": {},
   "source": [
    "# Save Correlation Matrix into a Dataframe for Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb9739-986a-486b-b499-053be1e7031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df1 = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df1)\n",
    "\n",
    "correlation_df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Differences in Matrices (Frobenius Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframes to numpy arrays\n",
    "matrix1 = correlation_df1.to_numpy()\n",
    "matrix2 = correlation_df_combined.to_numpy()\n",
    "\n",
    "# Compute the Frobenius norm of the difference between the matrices. \n",
    "frobenius_abs = np.linalg.norm(matrix1 - matrix2, ord='fro')   # Absolute error with Frobenius norm\n",
    "\n",
    "frobenius_rel = frobenius_abs/np.linalg.norm(matrix1, ord='fro')    # Relative error with Frobenius norm\n",
    "\n",
    "print(f\"Frobenius norm difference: {frobenius_abs: .3f}\")\n",
    "print(f\"Frobenius absolute error : {frobenius_rel .3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893a07c-00f8-4041-ae4b-77e155738f6f",
   "metadata": {},
   "source": [
    "# Differences in Arrays (L2 Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e65e78-7871-4fc8-a693-b5c2ad10229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array1 ...\n",
    "#array2 ...\n",
    "\n",
    "# Compute the L2 norm (Euclidean norm) of the difference between the arrays\n",
    "L2_norm = np.linalg.norm(array1 - array2, ord=2)\n",
    "\n",
    "print(f\"L2 norm difference: {L2_norm: .3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996e1a0-7162-478b-87bc-f7ac46404aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
