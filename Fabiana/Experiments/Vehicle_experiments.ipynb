{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990c4d04-17ec-47bf-b85a-2c29f389b185",
   "metadata": {},
   "source": [
    "# Upload Vehicle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2b12b3-28da-4d1d-a49f-c84eace7450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc263116-6242-4b56-bd9e-50fb250e8f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Make</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>AgeOfVehicle</th>\n",
       "      <th>AgeOfPolicyHolder</th>\n",
       "      <th>PoliceReportFiled</th>\n",
       "      <th>WitnessPresent</th>\n",
       "      <th>AgentType</th>\n",
       "      <th>NumberOfSuppliments</th>\n",
       "      <th>AddressChange_Claim</th>\n",
       "      <th>NumberOfCars</th>\n",
       "      <th>Year</th>\n",
       "      <th>BasePolicy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>3 years</td>\n",
       "      <td>26 to 30</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>1 year</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>6 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oct</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>7 years</td>\n",
       "      <td>41 to 50</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun</td>\n",
       "      <td>2</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Jul</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>more than 7</td>\n",
       "      <td>51 to 65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan</td>\n",
       "      <td>5</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>5 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  WeekOfMonth  DayOfWeek    Make AccidentArea DayOfWeekClaimed  \\\n",
       "0   Dec            5  Wednesday   Honda        Urban          Tuesday   \n",
       "1   Jan            3  Wednesday   Honda        Urban           Monday   \n",
       "2   Oct            5     Friday   Honda        Urban         Thursday   \n",
       "3   Jun            2   Saturday  Toyota        Rural           Friday   \n",
       "4   Jan            5     Monday   Honda        Urban          Tuesday   \n",
       "\n",
       "  MonthClaimed  WeekOfMonthClaimed     Sex MaritalStatus  ...  AgeOfVehicle  \\\n",
       "0          Jan                   1  Female        Single  ...       3 years   \n",
       "1          Jan                   4    Male        Single  ...       6 years   \n",
       "2          Nov                   2    Male       Married  ...       7 years   \n",
       "3          Jul                   1    Male       Married  ...   more than 7   \n",
       "4          Feb                   2  Female        Single  ...       5 years   \n",
       "\n",
       "  AgeOfPolicyHolder PoliceReportFiled WitnessPresent AgentType  \\\n",
       "0          26 to 30                No             No  External   \n",
       "1          31 to 35               Yes             No  External   \n",
       "2          41 to 50                No             No  External   \n",
       "3          51 to 65               Yes             No  External   \n",
       "4          31 to 35                No             No  External   \n",
       "\n",
       "   NumberOfSuppliments  AddressChange_Claim  NumberOfCars  Year  BasePolicy  \n",
       "0                 none               1 year        3 to 4  1994   Liability  \n",
       "1                 none            no change     1 vehicle  1994   Collision  \n",
       "2                 none            no change     1 vehicle  1994   Collision  \n",
       "3          more than 5            no change     1 vehicle  1994   Liability  \n",
       "4                 none            no change     1 vehicle  1994   Collision  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################## vehicle dataset\n",
    "df = pd.read_csv('fraud_oracle.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827a7dcb-d0e6-40f3-84c8-d5c969976dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15420 entries, 0 to 15419\n",
      "Data columns (total 33 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Month                 15420 non-null  object\n",
      " 1   WeekOfMonth           15420 non-null  int64 \n",
      " 2   DayOfWeek             15420 non-null  object\n",
      " 3   Make                  15420 non-null  object\n",
      " 4   AccidentArea          15420 non-null  object\n",
      " 5   DayOfWeekClaimed      15420 non-null  object\n",
      " 6   MonthClaimed          15420 non-null  object\n",
      " 7   WeekOfMonthClaimed    15420 non-null  int64 \n",
      " 8   Sex                   15420 non-null  object\n",
      " 9   MaritalStatus         15420 non-null  object\n",
      " 10  Age                   15420 non-null  int64 \n",
      " 11  Fault                 15420 non-null  object\n",
      " 12  PolicyType            15420 non-null  object\n",
      " 13  VehicleCategory       15420 non-null  object\n",
      " 14  VehiclePrice          15420 non-null  object\n",
      " 15  FraudFound_P          15420 non-null  int64 \n",
      " 16  PolicyNumber          15420 non-null  int64 \n",
      " 17  RepNumber             15420 non-null  int64 \n",
      " 18  Deductible            15420 non-null  int64 \n",
      " 19  DriverRating          15420 non-null  int64 \n",
      " 20  Days_Policy_Accident  15420 non-null  object\n",
      " 21  Days_Policy_Claim     15420 non-null  object\n",
      " 22  PastNumberOfClaims    15420 non-null  object\n",
      " 23  AgeOfVehicle          15420 non-null  object\n",
      " 24  AgeOfPolicyHolder     15420 non-null  object\n",
      " 25  PoliceReportFiled     15420 non-null  object\n",
      " 26  WitnessPresent        15420 non-null  object\n",
      " 27  AgentType             15420 non-null  object\n",
      " 28  NumberOfSuppliments   15420 non-null  object\n",
      " 29  AddressChange_Claim   15420 non-null  object\n",
      " 30  NumberOfCars          15420 non-null  object\n",
      " 31  Year                  15420 non-null  int64 \n",
      " 32  BasePolicy            15420 non-null  object\n",
      "dtypes: int64(9), object(24)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995aea10-8a25-4285-aad4-a6acadbdf158",
   "metadata": {},
   "source": [
    "# Use OneHotEncoder\n",
    "- this changes categorical into binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9f70ab-c467-415c-8802-59aae693832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Month_Apr  Month_Aug  Month_Dec  Month_Feb  Month_Jan  Month_Jul  \\\n",
      "0            0.0        0.0        1.0        0.0        0.0        0.0   \n",
      "1            0.0        0.0        0.0        0.0        1.0        0.0   \n",
      "2            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4            0.0        0.0        0.0        0.0        1.0        0.0   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "15415        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "15416        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "15417        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "15418        0.0        0.0        1.0        0.0        0.0        0.0   \n",
      "15419        0.0        0.0        1.0        0.0        0.0        0.0   \n",
      "\n",
      "       Month_Jun  Month_Mar  Month_May  Month_Nov  ...  BasePolicy_Liability  \\\n",
      "0            0.0        0.0        0.0        0.0  ...                   1.0   \n",
      "1            0.0        0.0        0.0        0.0  ...                   0.0   \n",
      "2            0.0        0.0        0.0        0.0  ...                   0.0   \n",
      "3            1.0        0.0        0.0        0.0  ...                   1.0   \n",
      "4            0.0        0.0        0.0        0.0  ...                   0.0   \n",
      "...          ...        ...        ...        ...  ...                   ...   \n",
      "15415        0.0        0.0        0.0        1.0  ...                   0.0   \n",
      "15416        0.0        0.0        0.0        1.0  ...                   1.0   \n",
      "15417        0.0        0.0        0.0        1.0  ...                   0.0   \n",
      "15418        0.0        0.0        0.0        0.0  ...                   0.0   \n",
      "15419        0.0        0.0        0.0        0.0  ...                   0.0   \n",
      "\n",
      "       WeekOfMonth  WeekOfMonthClaimed  Age  FraudFound_P  PolicyNumber  \\\n",
      "0                5                   1   21             0             1   \n",
      "1                3                   4   34             0             2   \n",
      "2                5                   2   47             0             3   \n",
      "3                2                   1   65             0             4   \n",
      "4                5                   2   27             0             5   \n",
      "...            ...                 ...  ...           ...           ...   \n",
      "15415            4                   5   35             1         15416   \n",
      "15416            5                   1   30             0         15417   \n",
      "15417            5                   1   24             1         15418   \n",
      "15418            1                   2   34             0         15419   \n",
      "15419            2                   3   21             1         15420   \n",
      "\n",
      "       RepNumber  Deductible  DriverRating  Year  \n",
      "0             12         300             1  1994  \n",
      "1             15         400             4  1994  \n",
      "2              7         400             3  1994  \n",
      "3              4         400             2  1994  \n",
      "4              3         400             1  1994  \n",
      "...          ...         ...           ...   ...  \n",
      "15415          5         400             4  1996  \n",
      "15416         11         400             3  1996  \n",
      "15417          4         400             4  1996  \n",
      "15418          6         400             4  1996  \n",
      "15419          3         400             4  1996  \n",
      "\n",
      "[15420 rows x 149 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# USE OneHotEncoder to change categorical into binary columns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Separate categorical and numerical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "integer_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Instantiate the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "encoded_categorical = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Convert the encoded array back to a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Combine the encoded columns with the integer columns\n",
    "final_df = pd.concat([encoded_df, df[integer_columns].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c27b7-8a83-4645-935c-57a1a10f8229",
   "metadata": {},
   "source": [
    "# Change y_train to the label column you want to explore (Is there Fraud?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82fe020f-8b7c-480b-a8ff-c694bf21570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train\n",
    "y = final_df[\"FraudFound_P\"]\n",
    "\n",
    "# X_train\n",
    "X = final_df.drop(columns=['FraudFound_P'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebffd7d-7646-48c3-be58-00800dac3aaf",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0323e41-734d-4300-a685-b6f4b44dab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=52)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(final_df.iloc[:,0:32], final_df.iloc[:,-1], test_size=0.2, random_state=52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "683eb33f-6334-4b6d-9096-96f273712587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4721     0\n",
       "9747     0\n",
       "5777     1\n",
       "7084     0\n",
       "12237    0\n",
       "Name: FraudFound_P, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c4dc6-6aa8-4fbe-88a7-1e1d45c8aedb",
   "metadata": {},
   "source": [
    "# XG-BOOST\n",
    "- classify dataset. The score should be 80 or below!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34b5231e-e21a-4910-b4ac-304e8ab87cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.4)\n",
      "[0 0 0 ... 0 0 0]\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# First, put this prompt: \"conda install -c conda-forge py-xgboost\" in anaconda to download xgboost package\n",
    "# install xgboost in jupyter\n",
    "!pip install xgboost\n",
    "\n",
    "# import the classifier from the xgboost package\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Import F1 score\n",
    "#import sklearn.metrics as skm\n",
    "\n",
    "\n",
    "# create model instance\n",
    "# n_estimators: number of trees(estimators) the model uses --> the more used, the more accurate the model is\n",
    "# max_depth: maximum depth of tree --> higher number makes model more complex, but too high can cause overfitting\n",
    "# learning_rate: quantifies each tree's contribution to total prediction --> lower number takes longer, but can lead to better generalization\n",
    "# objective: binary:logistic outputs probabilities. if classification is wanted, use binary:hinge\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic', enable_categorical=True)\n",
    "\n",
    "# fit model with the training data\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for the test dataset\n",
    "preds = bst.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(preds)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, preds))\n",
    "\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc44b3e-2630-4fde-b097-5045358596cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "#Create a svm Classifier\n",
    "# kernel: options for kernel include linear, poly, rbf, sigmoid\n",
    "    # linear: use this when data can be split by a linear function\n",
    "    # poly (polynomial): use this when data can be split by a polynomial function\n",
    "    # rbf (radial basis function): use this when there are clusters of one class inside another\n",
    "    # sigmoid: use this when the split between classes is curved and irregular\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(y_pred)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab247370-33b9-484c-a7bc-390847b68996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "#create a knn classifier\n",
    "#n_neighbors: predicting the label of the data point by looking at the 3 closest data points and getting them to \"vote\"\n",
    "#algorithm: we may need to look at this if it misbehaves\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#train the model using the training sets\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "#predict the response for the test dataset\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "#print predictions\n",
    "print(y_pred)\n",
    "\n",
    "#model accuracy (how often the classifier is correct)\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9862d20-725d-4429-b396-a32d7ce41cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "[143, 19, 9, 34, 2, 22, 7, 28, 1, 29, 17, 24, 35, 8, 21, 15, 18, 5, 25, 14, 12, 32, 20, 30, 3, 10, 26, 16, 36, 33, 31, 11, 23, 27, 13, 4, 6, 0, 40, 48, 79, 78, 86, 75, 95, 139, 71, 68, 137, 69, 67, 142, 128, 131, 73, 99, 98, 85, 138, 91, 38, 145, 110, 58, 82, 108, 80, 50, 93, 61, 125, 81, 70, 107, 122, 51, 57, 97, 126, 102, 54, 101, 124, 144, 103, 134, 106, 118, 89, 56, 105, 37, 140, 114, 41, 109, 45, 115, 123, 92, 39, 104, 72, 62, 77, 66, 130, 120, 43, 100, 141, 146, 112, 49, 129, 127, 47, 60, 83, 59, 63, 42, 96, 44, 132, 133, 90, 76, 121, 117, 74, 136, 111, 46, 87, 52, 88, 94, 113, 53, 119, 135, 116, 64, 147, 65, 84, 55]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(DecisionTreeClassifier(max_depth=3), 9026.074516463581, 143),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.204370370540783, 19),\n",
       " (DecisionTreeClassifier(max_depth=3), 6.315473278112889, 9),\n",
       " (DecisionTreeClassifier(max_depth=3), 4.1849371782126354, 34),\n",
       " (DecisionTreeClassifier(max_depth=3), 4.101518510657454, 2),\n",
       " (DecisionTreeClassifier(max_depth=3), 3.560347381298562, 22),\n",
       " (DecisionTreeClassifier(max_depth=3), 3.330508077340481, 7),\n",
       " (DecisionTreeClassifier(max_depth=3), 3.118154901259443, 28),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.969601757072435, 1),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.6106059525500527, 29),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.5140199143924327, 17),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.2150608934895852, 24),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.7365937956598034, 35),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.7318783265296416, 8),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.6721783776930432, 21),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.546860861788571, 15),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.3853967228506245, 18),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.2091093809905358, 5),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.097466033456664, 25),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.0941976803276574, 14),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.9341300232262327, 12),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.903595785548781, 32),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.7558810857389054, 20),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.7486569718816657, 30),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.6992790250575153, 3),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.41621110378890325, 10),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.31495045239121067, 26),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.2535096266853238, 16),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.20650675456317363, 36),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.18897027143472636, 33),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.16631220445454015, 31),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.14095966297910045, 11),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.12598018095648428, 23),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.06299009047824214, 27),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.016281345543832253, 13),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.0066411764459543155, 4),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.0011083028100754907, 6),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.0104969386156609e-05, 0),\n",
       " (DecisionTreeClassifier(max_depth=3), nan, 40),\n",
       " (DecisionTreeClassifier(max_depth=3), nan, 48),\n",
       " (DecisionTreeClassifier(max_depth=3), 145.7370268737728, 79),\n",
       " (DecisionTreeClassifier(max_depth=3), 70.57337960553737, 78),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.03468130633107, 86),\n",
       " (DecisionTreeClassifier(max_depth=3), 11.520012640881466, 75),\n",
       " (DecisionTreeClassifier(max_depth=3), nan, 95),\n",
       " (DecisionTreeClassifier(max_depth=3), 194.32669949858223, 139),\n",
       " (DecisionTreeClassifier(max_depth=3), 193.20989253241393, 71),\n",
       " (DecisionTreeClassifier(max_depth=3), 158.9277967038856, 68),\n",
       " (DecisionTreeClassifier(max_depth=3), 111.27553197021359, 137),\n",
       " (DecisionTreeClassifier(max_depth=3), 102.40556735161204, 69),\n",
       " (DecisionTreeClassifier(max_depth=3), 59.07879732915481, 67),\n",
       " (DecisionTreeClassifier(max_depth=3), 44.16055193150393, 142),\n",
       " (DecisionTreeClassifier(max_depth=3), 40.742984613149815, 128),\n",
       " (DecisionTreeClassifier(max_depth=3), 34.23565176338563, 131),\n",
       " (DecisionTreeClassifier(max_depth=3), 32.451505517038484, 73),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.71457260150669, 99),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.10797841651433, 98),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.173554025711443, 85),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.426925284307814, 138),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.076057895230074, 91),\n",
       " (DecisionTreeClassifier(max_depth=3), 11.918045036948989, 38),\n",
       " (DecisionTreeClassifier(max_depth=3), 11.018441665938356, 145),\n",
       " (DecisionTreeClassifier(max_depth=3), 9.941948917068403, 110),\n",
       " (DecisionTreeClassifier(max_depth=3), 9.164230003695511, 58),\n",
       " (DecisionTreeClassifier(max_depth=3), 9.0333195841008, 82),\n",
       " (DecisionTreeClassifier(max_depth=3), 8.977750260247985, 108),\n",
       " (DecisionTreeClassifier(max_depth=3), 8.039246262424985, 80),\n",
       " (DecisionTreeClassifier(max_depth=3), 7.586699387618732, 50),\n",
       " (DecisionTreeClassifier(max_depth=3), 6.859894308529885, 93),\n",
       " (DecisionTreeClassifier(max_depth=3), 6.590663673647752, 61),\n",
       " (DecisionTreeClassifier(max_depth=3), 6.394867501005844, 125),\n",
       " (DecisionTreeClassifier(max_depth=3), 6.330777743298809, 81),\n",
       " (DecisionTreeClassifier(max_depth=3), 5.806958832354433, 70),\n",
       " (DecisionTreeClassifier(max_depth=3), 5.5099973983643125, 107),\n",
       " (DecisionTreeClassifier(max_depth=3), 5.195621001025142, 122),\n",
       " (DecisionTreeClassifier(max_depth=3), 5.158192421326521, 51),\n",
       " (DecisionTreeClassifier(max_depth=3), 5.085058204798839, 57),\n",
       " (DecisionTreeClassifier(max_depth=3), 4.592976457512438, 97),\n",
       " (DecisionTreeClassifier(max_depth=3), 4.46705490151675, 126),\n",
       " (DecisionTreeClassifier(max_depth=3), 3.8072992806818426, 102),\n",
       " (DecisionTreeClassifier(max_depth=3), 3.7395767912101077, 54),\n",
       " (DecisionTreeClassifier(max_depth=3), 3.4583399700911044, 101),\n",
       " (DecisionTreeClassifier(max_depth=3), 3.3726517620296996, 124),\n",
       " (DecisionTreeClassifier(max_depth=3), 3.0390666969057345, 144),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.882280685432787, 103),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.8217007079646055, 134),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.7412200309990555, 106),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.6953796501599494, 118),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.6933633038598637, 89),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.3272945909806837, 56),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.3031356358439052, 105),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.1872186730676635, 37),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.951863916425632, 140),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.915807797900832, 114),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.8319344199411016, 41),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.7551875008893574, 109),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.6925378709139465, 45),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.5967873781271393, 115),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.586266148077364, 123),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.4888551623168231, 92),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.3966627674164078, 39),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.2995589887336012, 104),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.2598018095648427, 72),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.2261257771856937, 62),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.0708315381301163, 77),\n",
       " (DecisionTreeClassifier(max_depth=3), 1.0158937284950338, 66),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.959038615290396, 130),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.9005618715929203, 120),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.8247855655320128, 43),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.8107480275041259, 100),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.5860590398430016, 141),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.41398886629271425, 146),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.3733582539296828, 112),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.34318079356362363, 49),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.3399592463480057, 129),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.29218888153306577, 127),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.2875894997712847, 47),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.26246507369735733, 60),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.2623551408285404, 83),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.22866302155602153, 59),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.17602724425942634, 63),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.16368524928479522, 42),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.14963465826020195, 96),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.1253114901746317, 44),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.11786333106217343, 132),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.10863754537615575, 133),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.10547821728490159, 90),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.10272681684196637, 76),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.08301354589020526, 121),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.07639455493951167, 117),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.06299009047824214, 74),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.06299009047824214, 136),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.058862908250281766, 111),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.04239408705924803, 46),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.03720273476563959, 87),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.0336880505024961, 52),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.029926559036472084, 88),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.02660945615856108, 94),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.020636192217637263, 113),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.011374341570540989, 53),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.004696541703222288, 119),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.0044249524504450235, 135),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.002398174584002486, 116),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.0022704831072072776, 64),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.0019105834647763214, 147),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.0014324033319470535, 65),\n",
       " (DecisionTreeClassifier(max_depth=3), 0.00022968431200468304, 84),\n",
       " (DecisionTreeClassifier(max_depth=3), 2.1556572673173217e-05, 55)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Authors: Balachander S, Prahalad Srinivas C G, Yogesh Chandra Singh Samant, B Varshin Hariharan\n",
    "'''\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "#import scikit learn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc=0.01,classifier='DesicionTree',bias=[],control=None,n_jobs=None,random_state=None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred\n",
    "      \n",
    "#train the model using the training sets\n",
    "clf1=FeatureClassifier(0,classifier='DecisionTree',control=3)\n",
    "# clf1.fit(X_train,y_train.reshape(-1,1))\n",
    "clf1.fit(np.array(X_train), np.array(y_train)[:,np.newaxis].astype(int))\n",
    "\n",
    "#predict the response for the test dataset\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",skm.f1_score(np.array(y_test).astype(int),clf1.predict(np.array(X_test))))\n",
    "\n",
    "print(clf1.indexLs)\n",
    "clf1.featureClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2e19b-3ff2-4d32-89de-8c1c665e7fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
