{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Important: F vs F --> Chi-Square Test \n",
    "- Chi-Square prints a p-values matrix (only takes categorical columns) that will be changed to True and False. If the p-value is less than 0.05, then there is NO relationship, this is print TRUE (H0: null hypothesis). Otherwise, if p > 0.05 there is a relationship, this will print FALSE (Ha:  Alternative hypothesis)\n",
    "- Goal is to print the count of the changes -->  from True to False OR from False to True\n",
    "- Both data1 and data2 MUST have the same number of numerical and categorical columns. We will test 13 columns for all datasets with 8 'numerical'(at the beginning) and 5 'categorical' columns (at the end, including the label column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets before augmentation (synthetic)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "\n",
    "\n",
    "\n",
    "# Datasets after augmentation\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_modpmone.csv\")\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_randswap.csv\")\n",
    "\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_modpmone.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_randswap.csv\")\n",
    "\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_modpmone.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_randswap.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931307b7-1d76-4807-bd25-9618a65a47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f9d84-7ccd-4742-9c90-3d46dbf6b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1593183-6b7f-40f3-bd27-f13e0c9f9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Shapes of Datasets\n",
    "- They must be the same, if they are not--> run specific cells to make them have the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes for debugging \n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269defd2-a772-4548-bcbe-fd406a635bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end    \n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data1_last_13 = data1.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "#data1_last_13.iloc[:, -5:] = data1_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)   #only for synthetic dataset\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc62c5-205e-4efc-886b-845accf5faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_last_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fac50d-4e8e-40e9-8e67-c1cdfc3fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data2_last_13 = data2.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "data2_last_13.iloc[:, -5:] = data2_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d349618-32eb-489e-a9b8-0e3af074d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_last_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fbade-0f5e-4752-8110-2d6f812ae665",
   "metadata": {},
   "source": [
    "# Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743336-8bf3-433e-a128-e8fc8aa271a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data1_last_13 = data1.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "#data1_last_13.iloc[:, -5:] = data1_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cddd99-5618-4f86-81c2-beffb6344f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_last_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7b1d3-21b2-46c9-aa8c-a812252bdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data2_last_13 = data2.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "data2_last_13.iloc[:, -5:] = data2_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edc978-8cc4-40d6-8280-e8db639f81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_last_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Stacked Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c5ceb-1aed-47cd-ae7e-e3b4a3d29d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the first 8 columns and the last 5 columns (which are the primary columns)\n",
    "data1_last_13 = pd.concat([data1.iloc[:, :8], data1.iloc[:, -5:]], axis=1)\n",
    "\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af7bf2-e19b-45d2-995e-bf72f4efaa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_last_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d77a2f5-985d-4e5f-8eb9-d0eb5be1887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the first 8 columns and the last 5 columns (which are the primary columns)\n",
    "data2_last_13 = pd.concat([data2.iloc[:, :8], data2.iloc[:, -5:]], axis=1)\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2114a4-650a-46fe-8320-7372916e2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_last_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Data1: Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in data1_last_13.columns[-5:]:\n",
    "    data1_last_13[col] = data1_last_13[col].astype(int)\n",
    "\n",
    "print(data1_last_13.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting numerical subset \n",
    "numerical_df = data1_last_13.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting categorical subset \n",
    "categorical_df = data1_last_13.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "\n",
    "    return p_values_df\n",
    "    \n",
    "p_values_df = chi_squared_fvf(categorical_df)\n",
    "\n",
    "\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "print(\"----------- Chi-Square (F vs F) True and False ------------\")\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df1 = p_values_df < 0.05\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Data1 + Data2: Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Concat Data1 +  Data2 ##################################\n",
    "# Combine the DataFrames using pd.concat to maintain the data types\n",
    "combined_data = pd.concat([data1_last_13, data2_last_13], ignore_index=True)\n",
    "\n",
    " \n",
    "\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in combined_data.columns[-5:]:\n",
    "    combined_data[col] = combined_data[col].astype(int)\n",
    "\n",
    "\n",
    "print(combined_data.dtypes)\n",
    "\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = combined_data.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = combined_data.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "\n",
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "\n",
    "    return p_values_df\n",
    "    \n",
    "p_values_df = chi_squared_fvf(categorical_df)\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df2 = p_values_df < 0.05\n",
    "\n",
    "# Save the new DataFrame\n",
    "#p_value_df1 = pd.DataFrame(p_value_df1, columns=['significant'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c50ff-acb2-4ad1-a974-28a8aa97d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF YOU DO NOT NEED TO CONCAT USE THIS\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in data2_last_13.columns[-5:]:\n",
    "    data2_last_13[col] = data2_last_13[col].astype(int)\n",
    "\n",
    "print(data2_last_13.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting numerical subset \n",
    "numerical_df = data2_last_13.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting categorical subset \n",
    "categorical_df = data2_last_13.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "\n",
    "    return p_values_df\n",
    "    \n",
    "p_values_df = chi_squared_fvf(categorical_df)\n",
    "\n",
    "\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "print(\"----------- Chi-Square (F vs F) True and False ------------\")\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df2 = p_values_df < 0.05\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Count of Changes in p-values (significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the changes between the two DataFrames\n",
    "changes = (p_value_df1 != p_value_df2).sum().sum()\n",
    "\n",
    "# Display the number of changes\n",
    "print(f\"Number of changes between p_value_df1 and p_value_df2: {changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fba99e-4b7b-4a62-8500-ce9d3b32b85c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
