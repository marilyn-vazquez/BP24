{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Important: F vs F --> Chi-Square Test \n",
    "- Chi-Square prints a p-values matrix (only takes categorical columns) that will be changed to True and False. If the p-value is less than 0.05, then there is a relationship, this is print TRUE (H0: null hypothesis). Otherwise, if p > 0.05 there is no relationship, this will print FALSE (Ha:  Alternative hypothesis)\n",
    "- Goal is to print the count of the changes -->  from True to False OR from False to True\n",
    "- Both data1 and data2 MUST have the same number of numerical and categorical columns. We will test 13 columns for all datasets with 8 'numerical'(at the beginning) and 5 'categorical' columns (at the end, including the label column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets before augmentation (synthetic)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "\n",
    "\n",
    "# Datasets after augmentation\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Fabiana/Data/HAT (synthetic datasets)/stacked_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Aug. Syn. Datasets/stacked_modpmone.csv\")\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Fabiana/Data/HAT (synthetic datasets)/uniform_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Aug. Syn. Datasets/uniform_modpmone.csv\")\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Fabiana/Data/HAT (synthetic datasets)/gaussian_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Aug. Syn. Datasets/gaussian_modpmone.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931307b7-1d76-4807-bd25-9618a65a47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f9d84-7ccd-4742-9c90-3d46dbf6b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1593183-6b7f-40f3-bd27-f13e0c9f9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4201a3d-48a1-487e-bae1-b1e20e823b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Shapes of Datasets\n",
    "- They must be the same, if they are not--> run specific cells to make them have the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes for debugging \n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d026e7b-e0be-4cf2-b068-dd2fd0bfb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data1 is your DataFrame\n",
    "# indexes 2, 7, 10, 15, 24 are 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data1.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data1 = data1.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fac50d-4e8e-40e9-8e67-c1cdfc3fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data1 is your DataFrame\n",
    "# indexes 2, 7, 10, 15, 24 are 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data2.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data2 = data2.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fbade-0f5e-4752-8110-2d6f812ae665",
   "metadata": {},
   "source": [
    "# Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743336-8bf3-433e-a128-e8fc8aa271a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes 2, 3, 7, 9, 12 are 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data1.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data1 = data1.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7b1d3-21b2-46c9-aa8c-a812252bdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes 2, 3, 7, 9, 12 are 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data2.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data2 = data2.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2 .dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Stacked Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c5ceb-1aed-47cd-ae7e-e3b4a3d29d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data1.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data1 = data1.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d77a2f5-985d-4e5f-8eb9-d0eb5be1887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns (0 to 8), excluding the primary columns\n",
    "initial_indices = list(range(13))\n",
    "initial_indices = [i for i in initial_indices if i not in primary_indices]\n",
    "initial_columns = data2.columns[initial_indices]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = list(initial_columns) + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Ensure the DataFrame has exactly 13 columns\n",
    "data2 = data2.iloc[:, :13]\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Data1: Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "#for col in data1.columns[-5:]:\n",
    "#    data1[col] = data1[col].astype(int)\n",
    "\n",
    "# Convert the last 5 columns to categorical\n",
    "for col in data1.columns[-5:]:\n",
    "    data1[col] = data1[col].astype('category')\n",
    "\n",
    "print(data1.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = data1.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = data1.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "\n",
    "    return p_values_df\n",
    "    \n",
    "p_values_df = chi_squared_fvf(categorical_df)\n",
    "\n",
    "\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df1 = p_values_df < 0.05\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a6d86-c242-4b9c-8ccd-57fc563a07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "#for col in data1.columns[-5:]:\n",
    "#    data1[col] = data1[col].astype(int)\n",
    "\n",
    "# Convert the last 5 columns to categorical\n",
    "for col in data2.columns[-5:]:\n",
    "    data2[col] = data2[col].astype('category')\n",
    "\n",
    "print(data2.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = data2.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = data2.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "\n",
    "    return p_values_df\n",
    "    \n",
    "p_values_df = chi_squared_fvf(categorical_df)\n",
    "\n",
    "\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df2 = p_values_df < 0.05\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Data1 + Data2: Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Concat Data1 +  Data2 ##################################\n",
    "# Combine the DataFrames using pd.concat to maintain the data types\n",
    "combined_data = pd.concat([data1, data2], ignore_index=True)\n",
    "\n",
    " \n",
    "\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "#for col in combined_data.columns[-5:]:\n",
    "#    combined_data[col] = combined_data[col].astype(int)\n",
    "\n",
    "# Convert the last 5 columns to categorical\n",
    "for col in combined_data.columns[-5:]:\n",
    "    combined_data[col] = combined_data[col].astype('category')\n",
    "\n",
    "print(combined_data.dtypes)\n",
    "\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = combined_data.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = combined_data.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "\n",
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "\n",
    "    return p_values_df\n",
    "    \n",
    "p_values_df = chi_squared_fvf(categorical_df)\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df2 = p_values_df < 0.05\n",
    "\n",
    "# Save the new DataFrame\n",
    "#p_value_df1 = pd.DataFrame(p_value_df1, columns=['significant'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Count of Changes in p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the changes between the two DataFrames\n",
    "changes = (p_value_df1 != p_value_df2).sum().sum()\n",
    "\n",
    "# Display the number of changes\n",
    "print(f\"Number of changes between p_value_df1 and p_value_df2: {changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79249b7d-d381-483b-bd11-5c6b6da89955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#x_data1 = p_value_df1.index\n",
    "#y_data1 = p_value_df1.iloc[:, 0]  # Column 8\n",
    "\n",
    "x_data1 = data1.index\n",
    "y_data1 = data1.iloc[:,7]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 2))\n",
    "plt.scatter(x_data1, y_data1, color='blue', label='Data1 - Column 8')\n",
    "plt.xlabel('Rows')\n",
    "plt.title('Uniform - Column 8')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#x_data2 = p_value_df2.index\n",
    "#y_data2 = p_value_df2.iloc[:, 0]  \n",
    "\n",
    "x_data2 = data2.index\n",
    "y_data2 = data2.iloc[:,7]\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 2))\n",
    "plt.scatter(x_data2, y_data2, color='green', label='Data2 - Column 8')\n",
    "plt.xlabel('Rows')\n",
    "plt.title('Stacked: Column 8')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf7aae-bac4-4e6f-8332-68fdf429e833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
