{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Important: F vs F --> Chi-Square Test \n",
    "- Chi-Square prints a p-values matrix (only takes categorical columns) that will be changed to True and False. If the p-value is less than 0.05, then there is NO relationship, this is print TRUE (H0: null hypothesis). Otherwise, if p > 0.05 there is a relationship, this will print FALSE (Ha:  Alternative hypothesis)\n",
    "- Goal is to print the count of the changes -->  from True to False OR from False to True\n",
    "- Both data1 and data2 MUST have the same number of numerical and categorical columns. We will test 13 columns for all datasets with 8 'numerical'(at the beginning) and 5 'categorical' columns (at the end, including the label column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets before augmentation (synthetic)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "\n",
    "\n",
    "\n",
    "# Datasets after augmentation\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_modpmone.csv\")\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_randswap.csv\")\n",
    "\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_modpmone.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_randswap.csv\")\n",
    "\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_modpmone.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_randswap.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931307b7-1d76-4807-bd25-9618a65a47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f9d84-7ccd-4742-9c90-3d46dbf6b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1593183-6b7f-40f3-bd27-f13e0c9f9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Shapes of Datasets\n",
    "- They must be the same, if they are not--> run specific cells to make them have the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes for debugging \n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269defd2-a772-4548-bcbe-fd406a635bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end    \n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data1_last_13 = data1.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "#data1_last_13.iloc[:, -5:] = data1_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)   #only for synthetic dataset\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc62c5-205e-4efc-886b-845accf5faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_last_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fac50d-4e8e-40e9-8e67-c1cdfc3fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data2_last_13 = data2.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "data2_last_13.iloc[:, -5:] = data2_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d349618-32eb-489e-a9b8-0e3af074d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_last_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fbade-0f5e-4752-8110-2d6f812ae665",
   "metadata": {},
   "source": [
    "# Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743336-8bf3-433e-a128-e8fc8aa271a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data1_last_13 = data1.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "#data1_last_13.iloc[:, -5:] = data1_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cddd99-5618-4f86-81c2-beffb6344f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_last_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7b1d3-21b2-46c9-aa8c-a812252bdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data2_last_13 = data2.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "data2_last_13.iloc[:, -5:] = data2_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edc978-8cc4-40d6-8280-e8db639f81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_last_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Stacked Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f52c5ceb-1aed-47cd-ae7e-e3b4a3d29d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the first 8 columns and the last 5 columns (which are the primary columns)\n",
    "data1_last_13 = pd.concat([data1.iloc[:, :8], data1.iloc[:, -5:]], axis=1)\n",
    "\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38af7bf2-e19b-45d2-995e-bf72f4efaa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.523644</td>\n",
       "      <td>-0.273276</td>\n",
       "      <td>-0.116495</td>\n",
       "      <td>0.405252</td>\n",
       "      <td>1.197326</td>\n",
       "      <td>0.596777</td>\n",
       "      <td>0.538033</td>\n",
       "      <td>0.354814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.910844</td>\n",
       "      <td>0.797754</td>\n",
       "      <td>3.256096</td>\n",
       "      <td>1.803028</td>\n",
       "      <td>-1.190719</td>\n",
       "      <td>0.792517</td>\n",
       "      <td>1.187202</td>\n",
       "      <td>1.193782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.614962</td>\n",
       "      <td>1.306320</td>\n",
       "      <td>-0.156224</td>\n",
       "      <td>0.208113</td>\n",
       "      <td>-0.142056</td>\n",
       "      <td>0.331569</td>\n",
       "      <td>-0.139525</td>\n",
       "      <td>1.683484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.070894</td>\n",
       "      <td>0.848884</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.232592</td>\n",
       "      <td>1.261394</td>\n",
       "      <td>0.678807</td>\n",
       "      <td>0.218641</td>\n",
       "      <td>0.276284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.493572</td>\n",
       "      <td>0.730451</td>\n",
       "      <td>0.669870</td>\n",
       "      <td>0.671474</td>\n",
       "      <td>0.927129</td>\n",
       "      <td>-0.167649</td>\n",
       "      <td>0.735716</td>\n",
       "      <td>0.356140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.794388</td>\n",
       "      <td>0.274516</td>\n",
       "      <td>0.180763</td>\n",
       "      <td>0.435718</td>\n",
       "      <td>1.275335</td>\n",
       "      <td>0.705205</td>\n",
       "      <td>1.317206</td>\n",
       "      <td>0.945085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.520387</td>\n",
       "      <td>-1.083603</td>\n",
       "      <td>0.621607</td>\n",
       "      <td>0.629536</td>\n",
       "      <td>0.751939</td>\n",
       "      <td>-0.883465</td>\n",
       "      <td>0.337003</td>\n",
       "      <td>-0.412355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>3.168389</td>\n",
       "      <td>1.261369</td>\n",
       "      <td>2.362146</td>\n",
       "      <td>1.498775</td>\n",
       "      <td>3.540290</td>\n",
       "      <td>-0.528903</td>\n",
       "      <td>0.764048</td>\n",
       "      <td>-0.492612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>3.957235</td>\n",
       "      <td>2.410099</td>\n",
       "      <td>0.698402</td>\n",
       "      <td>-1.049969</td>\n",
       "      <td>0.876141</td>\n",
       "      <td>-0.665939</td>\n",
       "      <td>0.346620</td>\n",
       "      <td>0.034450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1.903798</td>\n",
       "      <td>0.637188</td>\n",
       "      <td>0.683087</td>\n",
       "      <td>0.521806</td>\n",
       "      <td>0.537816</td>\n",
       "      <td>0.756112</td>\n",
       "      <td>0.143213</td>\n",
       "      <td>0.374679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.523644 -0.273276 -0.116495  0.405252  1.197326  0.596777  0.538033   \n",
       "1    1.910844  0.797754  3.256096  1.803028 -1.190719  0.792517  1.187202   \n",
       "2    0.614962  1.306320 -0.156224  0.208113 -0.142056  0.331569 -0.139525   \n",
       "3   -0.070894  0.848884  0.023903  0.232592  1.261394  0.678807  0.218641   \n",
       "4    0.493572  0.730451  0.669870  0.671474  0.927129 -0.167649  0.735716   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "235  0.794388  0.274516  0.180763  0.435718  1.275335  0.705205  1.317206   \n",
       "236  0.520387 -1.083603  0.621607  0.629536  0.751939 -0.883465  0.337003   \n",
       "237  3.168389  1.261369  2.362146  1.498775  3.540290 -0.528903  0.764048   \n",
       "238  3.957235  2.410099  0.698402 -1.049969  0.876141 -0.665939  0.346620   \n",
       "239  1.903798  0.637188  0.683087  0.521806  0.537816  0.756112  0.143213   \n",
       "\n",
       "           7    8    9    10   11   12  \n",
       "0    0.354814  0.0  6.0  2.0  2.0  0.0  \n",
       "1    1.193782  1.0  1.0  2.0  0.0  1.0  \n",
       "2    1.683484  1.0  0.0  0.0  0.0  0.0  \n",
       "3    0.276284  1.0  1.0  0.0  0.0  0.0  \n",
       "4    0.356140  0.0  0.0  2.0  1.0  0.0  \n",
       "..        ...  ...  ...  ...  ...  ...  \n",
       "235  0.945085  0.0  0.0  0.0  1.0  0.0  \n",
       "236 -0.412355  0.0  1.0  1.0  1.0  0.0  \n",
       "237 -0.492612  0.0  1.0  2.0  0.0  1.0  \n",
       "238  0.034450  1.0  2.0  0.0  0.0  1.0  \n",
       "239  0.374679  1.0  2.0  3.0  0.0  0.0  \n",
       "\n",
       "[240 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_last_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d77a2f5-985d-4e5f-8eb9-d0eb5be1887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the first 8 columns and the last 5 columns (which are the primary columns)\n",
    "data2_last_13 = pd.concat([data2.iloc[:, :8], data2.iloc[:, -5:]], axis=1)\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab2114a4-650a-46fe-8320-7372916e2bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.910844</td>\n",
       "      <td>0.797754</td>\n",
       "      <td>3.256096</td>\n",
       "      <td>1.803028</td>\n",
       "      <td>-1.190719</td>\n",
       "      <td>0.792517</td>\n",
       "      <td>1.187202</td>\n",
       "      <td>1.193782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.614962</td>\n",
       "      <td>1.306320</td>\n",
       "      <td>-0.156224</td>\n",
       "      <td>0.208113</td>\n",
       "      <td>-0.142056</td>\n",
       "      <td>0.331569</td>\n",
       "      <td>-0.139525</td>\n",
       "      <td>1.683484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.070894</td>\n",
       "      <td>0.848884</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.232592</td>\n",
       "      <td>1.261394</td>\n",
       "      <td>0.678807</td>\n",
       "      <td>0.218641</td>\n",
       "      <td>0.276284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493572</td>\n",
       "      <td>0.730451</td>\n",
       "      <td>0.669870</td>\n",
       "      <td>0.671474</td>\n",
       "      <td>0.927129</td>\n",
       "      <td>-0.167649</td>\n",
       "      <td>0.735716</td>\n",
       "      <td>0.356140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018944</td>\n",
       "      <td>0.429406</td>\n",
       "      <td>0.178888</td>\n",
       "      <td>0.085866</td>\n",
       "      <td>-0.136803</td>\n",
       "      <td>0.513678</td>\n",
       "      <td>0.443401</td>\n",
       "      <td>0.431295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.414757</td>\n",
       "      <td>1.572467</td>\n",
       "      <td>0.498227</td>\n",
       "      <td>-0.280880</td>\n",
       "      <td>0.072822</td>\n",
       "      <td>0.833823</td>\n",
       "      <td>-0.900200</td>\n",
       "      <td>2.002458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.633351</td>\n",
       "      <td>1.227757</td>\n",
       "      <td>2.938073</td>\n",
       "      <td>2.393558</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.451999</td>\n",
       "      <td>0.026032</td>\n",
       "      <td>1.183106</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1.211799</td>\n",
       "      <td>2.463494</td>\n",
       "      <td>0.852726</td>\n",
       "      <td>0.629616</td>\n",
       "      <td>0.230524</td>\n",
       "      <td>1.292093</td>\n",
       "      <td>2.731894</td>\n",
       "      <td>0.188351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>-0.536855</td>\n",
       "      <td>0.478004</td>\n",
       "      <td>1.109635</td>\n",
       "      <td>1.005100</td>\n",
       "      <td>-1.822491</td>\n",
       "      <td>-0.167649</td>\n",
       "      <td>1.309079</td>\n",
       "      <td>-0.297547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>-0.532639</td>\n",
       "      <td>3.238793</td>\n",
       "      <td>0.695212</td>\n",
       "      <td>-0.046575</td>\n",
       "      <td>0.846914</td>\n",
       "      <td>-0.183261</td>\n",
       "      <td>-0.102792</td>\n",
       "      <td>-1.920203</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    1.910844  0.797754  3.256096  1.803028 -1.190719  0.792517  1.187202   \n",
       "1    0.614962  1.306320 -0.156224  0.208113 -0.142056  0.331569 -0.139525   \n",
       "2   -0.070894  0.848884  0.023903  0.232592  1.261394  0.678807  0.218641   \n",
       "3    0.493572  0.730451  0.669870  0.671474  0.927129 -0.167649  0.735716   \n",
       "4    0.018944  0.429406  0.178888  0.085866 -0.136803  0.513678  0.443401   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "474  0.414757  1.572467  0.498227 -0.280880  0.072822  0.833823 -0.900200   \n",
       "475  0.633351  1.227757  2.938073  2.393558  0.038900  0.451999  0.026032   \n",
       "476  1.211799  2.463494  0.852726  0.629616  0.230524  1.292093  2.731894   \n",
       "477 -0.536855  0.478004  1.109635  1.005100 -1.822491 -0.167649  1.309079   \n",
       "478 -0.532639  3.238793  0.695212 -0.046575  0.846914 -0.183261 -0.102792   \n",
       "\n",
       "           7    8    9    10   11   12  \n",
       "0    1.193782  1.0  1.0  2.0  0.0  1.0  \n",
       "1    1.683484  1.0  0.0  0.0  0.0  0.0  \n",
       "2    0.276284  1.0  1.0  0.0  0.0  0.0  \n",
       "3    0.356140  0.0  0.0  2.0  1.0  0.0  \n",
       "4    0.431295  0.0  2.0  0.0  1.0  0.0  \n",
       "..        ...  ...  ...  ...  ...  ...  \n",
       "474  2.002458  0.0  3.0  2.0  0.0  0.0  \n",
       "475  1.183106  2.0  1.0  0.0  0.0  1.0  \n",
       "476  0.188351  0.0  1.0  0.0  1.0  1.0  \n",
       "477 -0.297547  0.0  2.0  1.0  0.0  0.0  \n",
       "478 -1.920203  3.0  1.0  0.0  2.0  0.0  \n",
       "\n",
       "[479 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_last_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Data1: Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8       int64\n",
      "9       int64\n",
      "10      int64\n",
      "11      int64\n",
      "12      int64\n",
      "dtype: object\n",
      "\n",
      "------------------Chi-Squared for Features v. Features-----------------------\n",
      "Chi-Squared Values:\n",
      "           8          9          10         11        12\n",
      "8    0.000000  17.653931   9.068808  30.229482  6.492573\n",
      "9   17.653931   0.000000  20.313016  22.702746  1.711738\n",
      "10   9.068808  20.313016   0.000000  45.341096  2.030934\n",
      "11  30.229482  22.702746  45.341096   0.000000  1.653664\n",
      "12   6.492573   1.711738   2.030934   1.653664  0.000000\n",
      "\n",
      "P-Values:\n",
      "          8         9         10        11        12\n",
      "8   0.000000  0.963872  0.998503  0.215811  0.261194\n",
      "9   0.963872  0.000000  0.908135  0.827280  0.944211\n",
      "10  0.998503  0.908135  0.000000  0.007645  0.844848\n",
      "11  0.215811  0.827280  0.007645  0.000000  0.894685\n",
      "12  0.261194  0.944211  0.844848  0.894685  0.000000\n",
      "----------- Chi-Square (F vs F) True and False ------------\n",
      "       8      9      10     11     12\n",
      "8    True  False  False  False  False\n",
      "9   False   True  False  False  False\n",
      "10  False  False   True   True  False\n",
      "11  False  False   True   True  False\n",
      "12  False  False  False  False   True\n"
     ]
    }
   ],
   "source": [
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in data1_last_13.columns[-5:]:\n",
    "    data1_last_13[col] = data1_last_13[col].astype(int)\n",
    "\n",
    "print(data1_last_13.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting numerical subset \n",
    "numerical_df = data1_last_13.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting categorical subset \n",
    "categorical_df = data1_last_13.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "\n",
    "    return p_values_df\n",
    "    \n",
    "p_values_df = chi_squared_fvf(categorical_df)\n",
    "\n",
    "\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "print(\"----------- Chi-Square (F vs F) True and False ------------\")\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df1 = p_values_df < 0.05\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Data1 + Data2: Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Concat Data1 +  Data2 ##################################\n",
    "# Combine the DataFrames using pd.concat to maintain the data types\n",
    "combined_data = pd.concat([data1_last_13, data2_last_13], ignore_index=True)\n",
    "\n",
    " \n",
    "\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in combined_data.columns[-5:]:\n",
    "    combined_data[col] = combined_data[col].astype(int)\n",
    "\n",
    "\n",
    "print(combined_data.dtypes)\n",
    "\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = combined_data.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = combined_data.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "\n",
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "\n",
    "    return p_values_df\n",
    "    \n",
    "p_values_df = chi_squared_fvf(categorical_df)\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df2 = p_values_df < 0.05\n",
    "\n",
    "# Save the new DataFrame\n",
    "#p_value_df1 = pd.DataFrame(p_value_df1, columns=['significant'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c50ff-acb2-4ad1-a974-28a8aa97d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF YOU DO NOT NEED TO CONCAT USE THIS\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in data2_last_13.columns[-5:]:\n",
    "    data2_last_13[col] = data2_last_13[col].astype(int)\n",
    "\n",
    "print(data2_last_13.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting numerical subset \n",
    "numerical_df = data2_last_13.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting categorical subset \n",
    "categorical_df = data2_last_13.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "####################### Chi-Square (F vs F) Code ################################################\n",
    "    \n",
    "print(\"\\n------------------Chi-Squared for Features v. Features-----------------------\")\n",
    "# Finds dependency between all CATEGORICAL features in X_train\n",
    "def chi_squared_fvf(X_train_categorical):\n",
    "        \n",
    "    # Extract variable names\n",
    "    variable_names = list(X_train_categorical.columns)\n",
    "\n",
    "    # Initialize matrices to store chi-squared and p-values\n",
    "    num_variables = len(variable_names)\n",
    "    chi_squared = np.zeros((num_variables, num_variables))\n",
    "    p_values = np.zeros((num_variables, num_variables))\n",
    "\n",
    "    # Compute chi-squared and p-values for each pair of variables\n",
    "    for i, j in combinations(range(num_variables), 2):\n",
    "        contingency_table = pd.crosstab(X_train_categorical.iloc[:, i], X_train_categorical.iloc[:, j])\n",
    "            \n",
    "        # Compute chi-squared and p-values\n",
    "        chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "        p = stats.chi2_contingency(contingency_table)[1]\n",
    "            \n",
    "        # Assign results to chi_squared and p_values matrices\n",
    "        chi_squared[i, j] = chi2\n",
    "        chi_squared[j, i] = chi2  # Assign to symmetric position in the matrix\n",
    "        p_values[i, j] = p\n",
    "        p_values[j, i] = p  # Assign to symmetric position in the matrix\n",
    "\n",
    "    # Create a DataFrame with variable names as index and columns\n",
    "    chi_squared_df = pd.DataFrame(chi_squared, index=variable_names, columns=variable_names)\n",
    "    p_values_df = pd.DataFrame(p_values, index=variable_names, columns=variable_names)\n",
    "\n",
    "    # Printing the matrix-like output with variable names\n",
    "    print(\"Chi-Squared Values:\")\n",
    "    print(chi_squared_df)\n",
    "    print(\"\\nP-Values:\")\n",
    "    print(p_values_df)\n",
    "\n",
    "    return p_values_df\n",
    "    \n",
    "p_values_df = chi_squared_fvf(categorical_df)\n",
    "\n",
    "\n",
    "\n",
    "#################### Change p_values_df to True and False Table #################################\n",
    "print(\"----------- Chi-Square (F vs F) True and False ------------\")\n",
    "# Create a new DataFrame with True/False based on the p_value condition\n",
    "p_value_df2 = p_values_df < 0.05\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(p_value_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Count of Changes in p-values (significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the changes between the two DataFrames\n",
    "changes = (p_value_df1 != p_value_df2).sum().sum()\n",
    "\n",
    "# Display the number of changes\n",
    "print(f\"Number of changes between p_value_df1 and p_value_df2: {changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fba99e-4b7b-4a62-8500-ce9d3b32b85c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
