{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Important: F vs F --> Correlation Matrices Differences\n",
    "- Both data1 and data2 MUST have the same number of numerical and categorical columns\n",
    "- We will test 13 columns for all datasets with 8 'numerical'(at the beginning) and 5 'categorical' columns (at the end, including the label column)\n",
    "- Run all the cells for data1\n",
    "- Then, run all the cells for data2\n",
    "- Then, run cell to concat data1 and data2 (Called combined_data)\n",
    "- Then after you have the correlation matrices for both (data1 and combined_data) --> run the difference between matrices test\n",
    "- This is the only way this file will work. If you dont follow the steps you will get an inaccurate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets before augmentation (synthetic)\n",
    "data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "#data1 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "\n",
    "\n",
    "\n",
    "# Datasets after augmentation\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_modpmone.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/stacked_randswap.csv\")\n",
    "\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_modpmone.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/uniform_randswap.csv\")\n",
    "\n",
    "\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_HAT.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_modpmone.csv\")\n",
    "#data2 = pd.read_csv(\"/Users/fabianafazio/Documents/GitHub/BP24/AugSynDatasets/gaussian_randswap.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Shapes of Datasets\n",
    "- They must be the same, if they are not--> run specific cells to make them have the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data1: (240, 25)\n",
      "Shape of data2: (407, 25)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes for debugging \n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d026e7b-e0be-4cf2-b068-dd2fd0bfb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end    \n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data1_last_13 = data1.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "#data1_last_13.iloc[:, -5:] = data1_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)   #only for synthetic dataset\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fac50d-4e8e-40e9-8e67-c1cdfc3fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 7, 10, 15, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data2_last_13 = data2.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "data2_last_13.iloc[:, -5:] = data2_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fbade-0f5e-4752-8110-2d6f812ae665",
   "metadata": {},
   "source": [
    "# Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe743336-8bf3-433e-a128-e8fc8aa271a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data1_last_13 = data1.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "#data1_last_13.iloc[:, -5:] = data1_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff7b1d3-21b2-46c9-aa8c-a812252bdb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the primary columns to move to the end\n",
    "primary_indices = [2, 3, 7, 9, 12]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the last 13 columns\n",
    "data2_last_13 = data2.iloc[:, -13:]\n",
    "\n",
    "# Apply rounding and conversion to integers for the last 5 columns\n",
    "data2_last_13.iloc[:, -5:] = data2_last_13.iloc[:, -5:].round().astype(int)  # only for new generated points\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# Stacked Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f52c5ceb-1aed-47cd-ae7e-e3b4a3d29d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data1.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data1.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data1 = data1[new_column_order]\n",
    "\n",
    "# Grab the first 8 columns and the last 5 columns (which are the primary columns)\n",
    "data1_last_13 = pd.concat([data1.iloc[:, :8], data1.iloc[:, -5:]], axis=1)\n",
    "\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data1_last_13.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data1_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d77a2f5-985d-4e5f-8eb9-d0eb5be1887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# indexes 16, 17, 18, 19, 20, 21, 22, 23, 24 'categorical' --> we will change this later on \n",
    "# Define the primary columns to move to the end\n",
    "primary_indices = [16, 17, 18, 19, 24]\n",
    "primary_columns = data2.columns[primary_indices]\n",
    "\n",
    "# Define the initial columns, excluding the primary columns\n",
    "initial_columns = [col for col in data2.columns if col not in primary_columns]\n",
    "\n",
    "# Combine the initial columns with the primary columns\n",
    "new_column_order = initial_columns + list(primary_columns)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data2 = data2[new_column_order]\n",
    "\n",
    "# Grab the first 8 columns and the last 5 columns (which are the primary columns)\n",
    "data2_last_13 = pd.concat([data2.iloc[:, :8], data2.iloc[:, -5:]], axis=1)\n",
    "\n",
    "# Reset the column index to go from 0 to 12\n",
    "data2_last_13.columns = range(13)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(data2_last_13.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Data1: Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8       int64\n",
      "9       int64\n",
      "10      int64\n",
      "11      int64\n",
      "12      int64\n",
      "dtype: object\n",
      "---------------------------Correlation Matrix------------------------- \n",
      "           0         1         2         3         4         5         6  \\\n",
      "0  1.000000  0.231641  0.232815  0.111468  0.173032  0.234210  0.078157   \n",
      "1  0.231641  1.000000  0.162701  0.171856  0.140915  0.170447  0.148437   \n",
      "2  0.232815  0.162701  1.000000  0.108909  0.234001  0.116071  0.218272   \n",
      "3  0.111468  0.171856  0.108909  1.000000  0.267870  0.087709  0.142893   \n",
      "4  0.173032  0.140915  0.234001  0.267870  1.000000  0.069908  0.097955   \n",
      "5  0.234210  0.170447  0.116071  0.087709  0.069908  1.000000  0.149437   \n",
      "6  0.078157  0.148437  0.218272  0.142893  0.097955  0.149437  1.000000   \n",
      "7  0.238179  0.153569  0.185935  0.259552  0.231160  0.174242  0.140399   \n",
      "\n",
      "          7  \n",
      "0  0.238179  \n",
      "1  0.153569  \n",
      "2  0.185935  \n",
      "3  0.259552  \n",
      "4  0.231160  \n",
      "5  0.174242  \n",
      "6  0.140399  \n",
      "7  1.000000  \n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  1.000000  0.231641  0.232815  0.111468  0.173032  0.234210  0.078157   \n",
      "1  0.231641  1.000000  0.162701  0.171856  0.140915  0.170447  0.148437   \n",
      "2  0.232815  0.162701  1.000000  0.108909  0.234001  0.116071  0.218272   \n",
      "3  0.111468  0.171856  0.108909  1.000000  0.267870  0.087709  0.142893   \n",
      "4  0.173032  0.140915  0.234001  0.267870  1.000000  0.069908  0.097955   \n",
      "5  0.234210  0.170447  0.116071  0.087709  0.069908  1.000000  0.149437   \n",
      "6  0.078157  0.148437  0.218272  0.142893  0.097955  0.149437  1.000000   \n",
      "7  0.238179  0.153569  0.185935  0.259552  0.231160  0.174242  0.140399   \n",
      "\n",
      "          7  \n",
      "0  0.238179  \n",
      "1  0.153569  \n",
      "2  0.185935  \n",
      "3  0.259552  \n",
      "4  0.231160  \n",
      "5  0.174242  \n",
      "6  0.140399  \n",
      "7  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in data1_last_13.columns[-5:]:\n",
    "    data1_last_13[col] = data1_last_13[col].astype(int)\n",
    "\n",
    "print(data1_last_13.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting numerical subset \n",
    "numerical_df = data1_last_13.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting categorical subset \n",
    "categorical_df = data1_last_13.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n",
    "\n",
    "\n",
    "\n",
    "#################### save Data1 matrix as a dataframe #################################\n",
    "#data1\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df1 = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df1)\n",
    "\n",
    "correlation_df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# Data1 + Data2: Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      float64\n",
      "1      float64\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "5      float64\n",
      "6      float64\n",
      "7      float64\n",
      "8     category\n",
      "9     category\n",
      "10    category\n",
      "11    category\n",
      "12    category\n",
      "dtype: object\n",
      "---------------------------Correlation Matrix------------------------- \n",
      "           0         1         2         3         4         5         6  \\\n",
      "0  1.000000  0.102261  0.116502  0.129387  0.193902  0.034066  0.052608   \n",
      "1  0.102261  1.000000  0.166269  0.238847  0.142084  0.177643  0.115819   \n",
      "2  0.116502  0.166269  1.000000  0.145216  0.110002  0.020071  0.184814   \n",
      "3  0.129387  0.238847  0.145216  1.000000  0.165347  0.098661  0.063803   \n",
      "4  0.193902  0.142084  0.110002  0.165347  1.000000  0.166684  0.117307   \n",
      "5  0.034066  0.177643  0.020071  0.098661  0.166684  1.000000  0.002092   \n",
      "6  0.052608  0.115819  0.184814  0.063803  0.117307  0.002092  1.000000   \n",
      "7  0.364102  0.158065  0.089626  0.066719  0.085546 -0.041837  0.097900   \n",
      "\n",
      "          7  \n",
      "0  0.364102  \n",
      "1  0.158065  \n",
      "2  0.089626  \n",
      "3  0.066719  \n",
      "4  0.085546  \n",
      "5 -0.041837  \n",
      "6  0.097900  \n",
      "7  1.000000  \n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  1.000000  0.102261  0.116502  0.129387  0.193902  0.034066  0.052608   \n",
      "1  0.102261  1.000000  0.166269  0.238847  0.142084  0.177643  0.115819   \n",
      "2  0.116502  0.166269  1.000000  0.145216  0.110002  0.020071  0.184814   \n",
      "3  0.129387  0.238847  0.145216  1.000000  0.165347  0.098661  0.063803   \n",
      "4  0.193902  0.142084  0.110002  0.165347  1.000000  0.166684  0.117307   \n",
      "5  0.034066  0.177643  0.020071  0.098661  0.166684  1.000000  0.002092   \n",
      "6  0.052608  0.115819  0.184814  0.063803  0.117307  0.002092  1.000000   \n",
      "7  0.364102  0.158065  0.089626  0.066719  0.085546 -0.041837  0.097900   \n",
      "\n",
      "          7  \n",
      "0  0.364102  \n",
      "1  0.158065  \n",
      "2  0.089626  \n",
      "3  0.066719  \n",
      "4  0.085546  \n",
      "5 -0.041837  \n",
      "6  0.097900  \n",
      "7  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################## Concat Data1 +  Data2 ##################################\n",
    "# Combine the DataFrames using pd.concat to maintain the data types\n",
    "combined_data = pd.concat([data1_last_13, data2_last_13], ignore_index=True)\n",
    "\n",
    " \n",
    "\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in combined_data.columns[-5:]:\n",
    "    combined_data[col] = combined_data[col].astype(int)\n",
    "\n",
    "\n",
    "print(combined_data.dtypes)\n",
    "\n",
    "\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = combined_data.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = combined_data.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "\n",
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n",
    "\n",
    "\n",
    "############################## save combined_data matrix as a dataframe ############################\n",
    "#combined_data\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df_combined = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df_combined)\n",
    "\n",
    "correlation_df_combined.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b1875b5-b5a3-4680-bcbf-18f39bfd4cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8       int64\n",
      "9       int64\n",
      "10      int64\n",
      "11      int64\n",
      "12      int64\n",
      "dtype: object\n",
      "---------------------------Correlation Matrix------------------------- \n",
      "           0         1         2         3         4         5         6  \\\n",
      "0  1.000000  0.301180  0.249205  0.105289  0.168166  0.298743  0.085454   \n",
      "1  0.301180  1.000000  0.106488  0.164493  0.109978  0.174281  0.052448   \n",
      "2  0.249205  0.106488  1.000000  0.026022  0.234422  0.179540  0.225841   \n",
      "3  0.105289  0.164493  0.026022  1.000000  0.191274 -0.006738  0.105210   \n",
      "4  0.168166  0.109978  0.234422  0.191274  1.000000 -0.008498  0.067716   \n",
      "5  0.298743  0.174281  0.179540 -0.006738 -0.008498  1.000000  0.160469   \n",
      "6  0.085454  0.052448  0.225841  0.105210  0.067716  0.160469  1.000000   \n",
      "7  0.297242  0.148967  0.177028  0.273069  0.199133  0.194398  0.204289   \n",
      "\n",
      "          7  \n",
      "0  0.297242  \n",
      "1  0.148967  \n",
      "2  0.177028  \n",
      "3  0.273069  \n",
      "4  0.199133  \n",
      "5  0.194398  \n",
      "6  0.204289  \n",
      "7  1.000000  \n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  1.000000  0.301180  0.249205  0.105289  0.168166  0.298743  0.085454   \n",
      "1  0.301180  1.000000  0.106488  0.164493  0.109978  0.174281  0.052448   \n",
      "2  0.249205  0.106488  1.000000  0.026022  0.234422  0.179540  0.225841   \n",
      "3  0.105289  0.164493  0.026022  1.000000  0.191274 -0.006738  0.105210   \n",
      "4  0.168166  0.109978  0.234422  0.191274  1.000000 -0.008498  0.067716   \n",
      "5  0.298743  0.174281  0.179540 -0.006738 -0.008498  1.000000  0.160469   \n",
      "6  0.085454  0.052448  0.225841  0.105210  0.067716  0.160469  1.000000   \n",
      "7  0.297242  0.148967  0.177028  0.273069  0.199133  0.194398  0.204289   \n",
      "\n",
      "          7  \n",
      "0  0.297242  \n",
      "1  0.148967  \n",
      "2  0.177028  \n",
      "3  0.273069  \n",
      "4  0.199133  \n",
      "5  0.194398  \n",
      "6  0.204289  \n",
      "7  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IF YOU DONT HAVE TO CONCAT USE THIS\n",
    "\n",
    "################### Convert 5 last columns to int then categorical ############\n",
    "# Convert the last 5 columns to integers\n",
    "for col in data2_last_13.columns[-5:]:\n",
    "    data2_last_13[col] = data2_last_13[col].astype(int)\n",
    "\n",
    "print(data2_last_13.dtypes)\n",
    "##################### Subsetting data ################################\n",
    "\n",
    "\n",
    "# Splitting numerical subset \n",
    "numerical_df = data2_last_13.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting categorical subset \n",
    "categorical_df = data2_last_13.select_dtypes(exclude=['float', 'float64'])\n",
    "\n",
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n",
    "\n",
    "\n",
    "\n",
    "#################### save Data1 matrix as a dataframe #################################\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df_combined = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df_combined)\n",
    "\n",
    "correlation_df_combined.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Differences in Matrices (Frobenius Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm (absolute error) :  0.364\n",
      "Frobenius norm (relative error) :  0.117\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataframes to numpy arrays\n",
    "matrix1 = correlation_df1.to_numpy()\n",
    "matrix2 = correlation_df_combined.to_numpy()\n",
    "\n",
    "# Compute the Frobenius norm of the difference between the matrices. \n",
    "frobenius_abs = np.linalg.norm(matrix1 - matrix2, ord='fro')   # Absolute error with Frobenius norm\n",
    "\n",
    "frobenius_rel = frobenius_abs/np.linalg.norm(matrix1, ord='fro')    # Relative error with Frobenius norm\n",
    "\n",
    "print(f\"Frobenius norm (absolute error) : {frobenius_abs: .3f}\")\n",
    "print(f\"Frobenius norm (relative error) : {frobenius_rel: .3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f48003-2eaf-4a9f-8b42-07c459c3d419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
