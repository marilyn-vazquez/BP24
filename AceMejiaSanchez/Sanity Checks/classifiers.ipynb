{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975e2c1f-5e05-4835-801d-4263aae6f310",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33083511-5a97-4f13-9b9b-ea3746b444b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39179e0a-ebed-4582-907a-5fe57bff1559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.444140</td>\n",
       "      <td>3.835115</td>\n",
       "      <td>3.291091</td>\n",
       "      <td>5.501369</td>\n",
       "      <td>3.428899</td>\n",
       "      <td>4.922020</td>\n",
       "      <td>6.679717</td>\n",
       "      <td>4.207196</td>\n",
       "      <td>5.551717</td>\n",
       "      <td>4.834592</td>\n",
       "      <td>...</td>\n",
       "      <td>5.827100</td>\n",
       "      <td>5.536030</td>\n",
       "      <td>5.505949</td>\n",
       "      <td>3.871041</td>\n",
       "      <td>4.820020</td>\n",
       "      <td>6.893534</td>\n",
       "      <td>4.675085</td>\n",
       "      <td>6.774422</td>\n",
       "      <td>4.013287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.751552</td>\n",
       "      <td>7.292662</td>\n",
       "      <td>5.983595</td>\n",
       "      <td>6.379493</td>\n",
       "      <td>5.236658</td>\n",
       "      <td>5.765614</td>\n",
       "      <td>5.973641</td>\n",
       "      <td>4.951007</td>\n",
       "      <td>4.739128</td>\n",
       "      <td>5.221459</td>\n",
       "      <td>...</td>\n",
       "      <td>6.917924</td>\n",
       "      <td>6.177616</td>\n",
       "      <td>3.985334</td>\n",
       "      <td>7.088912</td>\n",
       "      <td>6.713774</td>\n",
       "      <td>6.083684</td>\n",
       "      <td>3.632900</td>\n",
       "      <td>4.680444</td>\n",
       "      <td>3.866624</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.271994</td>\n",
       "      <td>6.196881</td>\n",
       "      <td>6.260575</td>\n",
       "      <td>5.059051</td>\n",
       "      <td>7.156964</td>\n",
       "      <td>5.242397</td>\n",
       "      <td>5.938668</td>\n",
       "      <td>6.792579</td>\n",
       "      <td>5.949605</td>\n",
       "      <td>4.961027</td>\n",
       "      <td>...</td>\n",
       "      <td>5.436174</td>\n",
       "      <td>5.076978</td>\n",
       "      <td>5.613830</td>\n",
       "      <td>4.757041</td>\n",
       "      <td>7.940103</td>\n",
       "      <td>5.800670</td>\n",
       "      <td>6.505194</td>\n",
       "      <td>5.033843</td>\n",
       "      <td>8.216384</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.175813</td>\n",
       "      <td>3.704364</td>\n",
       "      <td>3.481604</td>\n",
       "      <td>4.074979</td>\n",
       "      <td>4.708090</td>\n",
       "      <td>5.923180</td>\n",
       "      <td>3.811577</td>\n",
       "      <td>5.946279</td>\n",
       "      <td>5.894935</td>\n",
       "      <td>4.305289</td>\n",
       "      <td>...</td>\n",
       "      <td>3.936844</td>\n",
       "      <td>4.982322</td>\n",
       "      <td>5.583355</td>\n",
       "      <td>3.444634</td>\n",
       "      <td>5.448884</td>\n",
       "      <td>5.031922</td>\n",
       "      <td>5.339520</td>\n",
       "      <td>4.730453</td>\n",
       "      <td>5.299622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.471645</td>\n",
       "      <td>5.372742</td>\n",
       "      <td>6.487397</td>\n",
       "      <td>5.160722</td>\n",
       "      <td>6.983509</td>\n",
       "      <td>5.484562</td>\n",
       "      <td>8.489674</td>\n",
       "      <td>6.386151</td>\n",
       "      <td>5.103722</td>\n",
       "      <td>6.382228</td>\n",
       "      <td>...</td>\n",
       "      <td>5.699915</td>\n",
       "      <td>4.489785</td>\n",
       "      <td>4.401668</td>\n",
       "      <td>5.614796</td>\n",
       "      <td>6.298538</td>\n",
       "      <td>6.293809</td>\n",
       "      <td>5.578622</td>\n",
       "      <td>6.118113</td>\n",
       "      <td>7.776001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  5.444140  3.835115  3.291091  5.501369  3.428899  4.922020  6.679717   \n",
       "1  4.751552  7.292662  5.983595  6.379493  5.236658  5.765614  5.973641   \n",
       "2  6.271994  6.196881  6.260575  5.059051  7.156964  5.242397  5.938668   \n",
       "3  4.175813  3.704364  3.481604  4.074979  4.708090  5.923180  3.811577   \n",
       "4  5.471645  5.372742  6.487397  5.160722  6.983509  5.484562  8.489674   \n",
       "\n",
       "        7         8         9    ...       141       142       143       144  \\\n",
       "0  4.207196  5.551717  4.834592  ...  5.827100  5.536030  5.505949  3.871041   \n",
       "1  4.951007  4.739128  5.221459  ...  6.917924  6.177616  3.985334  7.088912   \n",
       "2  6.792579  5.949605  4.961027  ...  5.436174  5.076978  5.613830  4.757041   \n",
       "3  5.946279  5.894935  4.305289  ...  3.936844  4.982322  5.583355  3.444634   \n",
       "4  6.386151  5.103722  6.382228  ...  5.699915  4.489785  4.401668  5.614796   \n",
       "\n",
       "        145       146       147       148       149  150  \n",
       "0  4.820020  6.893534  4.675085  6.774422  4.013287  1.0  \n",
       "1  6.713774  6.083684  3.632900  4.680444  3.866624  1.0  \n",
       "2  7.940103  5.800670  6.505194  5.033843  8.216384  0.0  \n",
       "3  5.448884  5.031922  5.339520  4.730453  5.299622  1.0  \n",
       "4  6.298538  6.293809  5.578622  6.118113  7.776001  0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/AceMejiaSanchez/Data/gaussian_small_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Kate/Data/uniform_small_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Fabiana/Data/uniform_large_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/gaussian_large_d_1.tex\")\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df = pd.DataFrame(array)\n",
    "\n",
    "# Look at data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47374f2a-42f2-4690-9035-3d6086010171",
   "metadata": {},
   "source": [
    "# Convert 25/150 Columns into CONSECUTIVE Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42db5971-5001-4ee9-8742-201d0d6b700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 25 columns from numerical floats -> categorical integers\n",
    "for i in range(25):\n",
    "    \n",
    "    df.iloc[:,i] = df.iloc[:,i].round() # Rounding\n",
    "    df.iloc[:,i] = df.iloc[:,i].astype(int) # Integer\n",
    "    df.iloc[:,i] = df.iloc[:,i].astype('category') # Categories\n",
    "    \n",
    "# Turn label into categorical label\n",
    "df.iloc[:,150] = df.iloc[:,150].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee4c61bf-8320-4d97-badf-75d933daa5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.827100</td>\n",
       "      <td>5.536030</td>\n",
       "      <td>5.505949</td>\n",
       "      <td>3.871041</td>\n",
       "      <td>4.820020</td>\n",
       "      <td>6.893534</td>\n",
       "      <td>4.675085</td>\n",
       "      <td>6.774422</td>\n",
       "      <td>4.013287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.917924</td>\n",
       "      <td>6.177616</td>\n",
       "      <td>3.985334</td>\n",
       "      <td>7.088912</td>\n",
       "      <td>6.713774</td>\n",
       "      <td>6.083684</td>\n",
       "      <td>3.632900</td>\n",
       "      <td>4.680444</td>\n",
       "      <td>3.866624</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.436174</td>\n",
       "      <td>5.076978</td>\n",
       "      <td>5.613830</td>\n",
       "      <td>4.757041</td>\n",
       "      <td>7.940103</td>\n",
       "      <td>5.800670</td>\n",
       "      <td>6.505194</td>\n",
       "      <td>5.033843</td>\n",
       "      <td>8.216384</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.936844</td>\n",
       "      <td>4.982322</td>\n",
       "      <td>5.583355</td>\n",
       "      <td>3.444634</td>\n",
       "      <td>5.448884</td>\n",
       "      <td>5.031922</td>\n",
       "      <td>5.339520</td>\n",
       "      <td>4.730453</td>\n",
       "      <td>5.299622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.699915</td>\n",
       "      <td>4.489785</td>\n",
       "      <td>4.401668</td>\n",
       "      <td>5.614796</td>\n",
       "      <td>6.298538</td>\n",
       "      <td>6.293809</td>\n",
       "      <td>5.578622</td>\n",
       "      <td>6.118113</td>\n",
       "      <td>7.776001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...       141       142  \\\n",
       "0  5.0  4.0  3.0  6.0  3.0  5.0  7.0  4.0  6.0  5.0  ...  5.827100  5.536030   \n",
       "1  5.0  7.0  6.0  6.0  5.0  6.0  6.0  5.0  5.0  5.0  ...  6.917924  6.177616   \n",
       "2  6.0  6.0  6.0  5.0  7.0  5.0  6.0  7.0  6.0  5.0  ...  5.436174  5.076978   \n",
       "3  4.0  4.0  3.0  4.0  5.0  6.0  4.0  6.0  6.0  4.0  ...  3.936844  4.982322   \n",
       "4  5.0  5.0  6.0  5.0  7.0  5.0  8.0  6.0  5.0  6.0  ...  5.699915  4.489785   \n",
       "\n",
       "        143       144       145       146       147       148       149  150  \n",
       "0  5.505949  3.871041  4.820020  6.893534  4.675085  6.774422  4.013287  1.0  \n",
       "1  3.985334  7.088912  6.713774  6.083684  3.632900  4.680444  3.866624  1.0  \n",
       "2  5.613830  4.757041  7.940103  5.800670  6.505194  5.033843  8.216384  0.0  \n",
       "3  5.583355  3.444634  5.448884  5.031922  5.339520  4.730453  5.299622  1.0  \n",
       "4  4.401668  5.614796  6.298538  6.293809  5.578622  6.118113  7.776001  0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cd94e-5734-4ad0-84a4-26261dcc3970",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1bb13f3-63e8-4849-aaca-82a08a8ce06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:150], df.iloc[:,-1], test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e4fab0-e311-4eac-9256-d03181c3dd14",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db93291b-647d-4998-b7fe-2b702d8e743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter = plt.scatter(X_train.iloc[:,6], X_train.iloc[:,7], c=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c8cb0-be5d-46d3-bdd1-b589aea83e3f",
   "metadata": {},
   "source": [
    "# XG-BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b556a05d-cddb-48dc-9228-890e7857dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\aceme\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\aceme\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\aceme\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "# First, put this prompt: \"conda install -c conda-forge py-xgboost\" in anaconda to download xgboost package\n",
    "# install xgboost in jupyter\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8486047d-e245-44b0-b266-223cf1d04aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1\n",
      " 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0]\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# import the classifier from the xgboost package\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# read data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# create model instance\n",
    "# n_estimators: number of trees(estimators) the model uses --> the more used, the more accurate the model is\n",
    "# max_depth: maximum depth of tree --> higher number makes model more complex, but too high can cause overfitting\n",
    "# learning_rate: quantifies each tree's contribution to total prediction --> lower number takes longer, but can lead to better generalization\n",
    "# objective: binary:logistic outputs probabilities. if classification is wanted, use binary:hinge\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic', enable_categorical=True)\n",
    "\n",
    "# fit model with the training data\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for the test dataset\n",
    "preds = bst.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(preds)\n",
    "\n",
    "# print model F1-Score\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd9727-fa96-4eed-84fd-ab332fee941d",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9815a9c1-2ef9-468e-a32b-15eee40f443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "# kernel: options for kernel include linear, poly, rbf, sigmoid\n",
    "    # linear: use this when data can be split by a linear function\n",
    "    # poly (polynomial): use this when data can be split by a polynomial function\n",
    "    # rbf (radial basis function): use this when there are clusters of one class inside another\n",
    "    # sigmoid: use this when the split between classes is curved and irregular\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(y_pred)\n",
    "\n",
    "# print model F1-Score\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbb0a4-af3e-4f69-84aa-258df7d433b1",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "43a30467-013d-4449-beeb-9d53774928c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#import knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#create a knn classifier\n",
    "#n_neighbors: predicting the label of the data point by looking at the 3 closest data points and getting them to \"vote\"\n",
    "#algorithm: we may need to look at this if it misbehaves\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#train the model using the training sets\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "#predict the response for the test dataset\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "#print predictions\n",
    "print(y_pred)\n",
    "\n",
    "# print model F1-Score\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a38be0-c339-4bc9-ba85-450adfd743f3",
   "metadata": {},
   "source": [
    "# FIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c0eb0c28-3b5a-4cea-a2b9-eb11d65d1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc = 0.01, classifier = 'DecisionTree', bias = [], control = None, n_jobs = None, random_state = None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73db710-5f77-4fd5-bd77-da872810c6cb",
   "metadata": {},
   "source": [
    "# F1-SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e350123-8349-4ab6-bed8-6743cbd19a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 1.0\n",
      "[137, 103, 14, 13, 100, 140, 104, 110, 130, 0, 113, 95, 5, 15, 59, 94, 138, 48, 135, 30, 121, 43, 55, 123, 66, 122, 65, 125, 128, 132, 2, 68, 124, 149, 131, 146, 60, 112, 144, 58, 1, 145, 134, 53, 127, 44, 24, 39, 3, 25, 118, 40, 49, 26, 129, 46, 21, 114, 76, 107, 111, 61, 91, 105, 36, 120, 32, 78, 63, 84, 90, 67, 143, 108, 115, 57, 20, 6, 42, 74, 89, 77, 139, 87, 38, 97, 8, 52, 29, 45, 70, 19, 109, 81, 22, 34, 101, 7, 31, 98, 12, 72, 69, 23, 51, 62, 119, 18, 142, 37, 64, 99, 106, 28, 27, 80, 93, 75, 126, 116, 54, 86, 9, 79, 35, 85, 33, 82, 83, 141, 47, 41, 96, 102, 4, 133, 11, 17, 50, 71, 10, 136, 148, 92, 117, 88, 16, 56, 147, 73]\n"
     ]
    }
   ],
   "source": [
    "# Assuming FeatureClassifier is correctly implemented for DecisionTreeClassifier\n",
    "clf1 = FeatureClassifier(0, classifier='DecisionTree', control=3, random_state = 52)\n",
    "\n",
    "# Fit model with the training data\n",
    "clf1.fit(np.array(X_train), np.array(y_train).astype(int))\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred = clf1.predict(np.array(X_test))\n",
    "\n",
    "# Calculate and print F1 score\n",
    "f1 = metrics.f1_score(np.array(y_test).astype(int), y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Print other relevant outputs for debugging\n",
    "print(clf1.indexLs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
