{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0d46db-653f-4d57-8c27-03c90b6d22cb",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f53352d8-22d2-4075-b31f-d0ef01c764f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e2c78482-a1c3-4fc3-9a32-422305278d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('C:/Users/aceme/OneDrive/Documents/SIAM Simons Summer Opportunity/Datasets/D3Softball.xlsx', index_col=[0])\n",
    "df.replace('---', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924e959-5c63-41bc-ac61-bf285cc1e4b9",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a914886-1f4b-4340-84c7-3a8e6f506d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing data\n",
    "# test_size: this is the percentage of data used for testing (20% in this case), so the rest is used for training data (80% in this case)\n",
    "# random_state: this is a random number chosen that should be used each time to ensure we get the same data split each time\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size = 0.4, random_state = 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d63487-3dd7-49ed-bdd2-3b4432a519ef",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "868df05f-7458-4286-bef6-62df87febe7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_to_convert = [\n",
    "    'G', 'AB', 'H (Offensive)', 'H/G', 'BA', '2B (Offensive)', '2B/G',\n",
    "    '3B (Offensive)', '3B/G', 'Innings Pitched', 'K (Def)', 'K/G (Def)',\n",
    "    'BB Allowed', 'BB/G (Def)', 'K/BB', 'HA', 'HA/G', 'Runs Allowed',\n",
    "    'Runs Allowed/G', 'ER Allowed', 'ERA', 'WHIP', 'PO', 'A', 'E', 'E/G',\n",
    "    'FPCT', 'HBP (Offensive)', 'HBP/G', 'BB (Offensive)', 'BB/G (Off)',\n",
    "    'SF (Offensive)', 'SH (Offensive)', 'OBP', 'SHO', 'SHO %', 'SB',\n",
    "    'SB/G', 'TB', 'TB/G', 'SLG PCT', 'R', 'R/G', 'DP', 'DP/G',\n",
    "    'K (Off)', 'K/G (Off)'\n",
    "]\n",
    "\n",
    "# Convert the columns to float\n",
    "df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d3bfc-09bc-416e-b7c7-1f8c8370f16a",
   "metadata": {},
   "source": [
    "# FIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "16d03cd9-1b77-4591-adc5-a5ac9e6fa031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc = 0.01, classifier = 'DecisionTree', bias = [], control = None, n_jobs = None, random_state = None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1bb7d-aa12-4ffc-aca3-573a9ee87008",
   "metadata": {},
   "source": [
    "# ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0009d4fe-6bf7-47fd-bd66-f67858d1504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9745222929936306\n",
      "[38, 41, 1, 2, 22, 36, 10, 29, 17, 34, 27, 5, 19, 9, 23, 24, 31, 15, 0, 7, 43, 18, 45, 42, 20, 16, 39, 14, 37, 46, 25, 35, 3, 28, 30, 11, 13, 12, 21, 6, 32, 40, 8, 33, 4, 44, 26]\n",
      "[38, 41, 1, 2, 22, 36, 10, 29, 17, 34, 27, 5, 19, 9, 23, 24, 31, 15, 0, 7, 43, 18, 45, 42, 20, 16, 39, 14, 37, 46, 25, 35, 3, 28, 30, 11, 13, 12, 21, 6, 32, 40, 8, 33, 4, 44, 26]\n"
     ]
    }
   ],
   "source": [
    "#train the model using the training sets\n",
    "clf1=FeatureClassifier(0,classifier='DecisionTree',control=3, random_state = 52)\n",
    "# clf1.fit(X_train,y_train.reshape(-1,1))\n",
    "clf1.fit(np.array(X_train), np.array(y_train)[:,np.newaxis].astype(int))\n",
    "\n",
    "#predict the response for the test dataset\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(np.array(y_test).astype(int),clf1.predict(np.array(X_test))))\n",
    "\n",
    "print(clf1.indexLs)\n",
    "clf1.featureClassifiers\n",
    "print(clf1.indexLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e8ecc-77b1-4e10-9351-e8174e392c5b",
   "metadata": {},
   "source": [
    "# F1-SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cae97d84-13e6-4d02-971d-5e622aa4d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5\n",
      "[38, 41, 1, 2, 22, 36, 10, 29, 17, 34, 27, 5, 19, 9, 23, 24, 31, 15, 0, 7, 43, 18, 45, 42, 20, 16, 39, 14, 37, 46, 25, 35, 3, 28, 30, 11, 13, 12, 21, 6, 32, 40, 8, 33, 4, 44, 26]\n"
     ]
    }
   ],
   "source": [
    "# Assuming FeatureClassifier is correctly implemented for DecisionTreeClassifier\n",
    "clf1 = FeatureClassifier(0, classifier='DecisionTree', control=3, random_state = 52)\n",
    "\n",
    "# Fit model with the training data\n",
    "clf1.fit(np.array(X_train), np.array(y_train).astype(int))\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred = clf1.predict(np.array(X_test))\n",
    "\n",
    "# Calculate and print F1 score\n",
    "f1 = metrics.f1_score(np.array(y_test).astype(int), y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Print other relevant outputs for debugging\n",
    "print(clf1.indexLs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
