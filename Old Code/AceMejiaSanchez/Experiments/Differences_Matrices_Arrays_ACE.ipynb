{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0b58dd-f789-429f-9f35-9c42480c76d1",
   "metadata": {},
   "source": [
    "# Note:\n",
    "-(make sure both data1 and data2 have the same number of numerical and categorical columns)\n",
    "- Run all the cells for data1\n",
    "- Then, run all the cells for data2\n",
    "- Then after you have the correlation matrices for both (data1 and data2) --> run the difference between matrices test\n",
    "- This is the only way this file will work. If you dont follow the steps you will get a result of ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4061dbbd-b593-4839-9ca5-aa8ada5bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfdd5-302c-42ef-9f05-e4ccbefd8ead",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198910fa-c38e-49d7-b3e5-ec9e71e9ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset before augmentation\n",
    "#data1 = pd.read_csv(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "data1 = pd.read_csv(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "\n",
    "# Dataset after augmentation\n",
    "#data2 = pd.read_csv(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_new.csv\", header=None)\n",
    "data2 = pd.read_csv(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_new.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "#data2 = pd.read_csv(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_new.csv\", header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66147c8f-3866-4f2a-81ea-798ca6d35109",
   "metadata": {},
   "source": [
    "# Check Shapes of Datasets (they must be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc4a540-4ab8-46fb-9d49-0629d8580b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data1: (343, 25)\n",
      "Shape of data2: (342, 25)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes for debugging\n",
    "print(f\"Shape of data1: {data1.shape}\")\n",
    "print(f\"Shape of data2: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d71858-9d7a-4db8-a3b0-e99c76cecf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the datasets do not have the same columns ---> make one dataset match the other one (order does not matter)\n",
    "# Subset columns so both have the same \n",
    "# (we need to make sure we have the same categorical and numerical columns) ---> you do this after this cell\n",
    "data1 = data1.iloc[:, -13:]\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91f83e-168c-4b2f-9119-c0858d5e0007",
   "metadata": {},
   "source": [
    "# Convert columns into Categorical (Only for Uniform and Gaussian Distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19945cd3-4527-4754-96d4-0e0f5576c01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      float64\n",
       "1      float64\n",
       "2      float64\n",
       "3      float64\n",
       "4      float64\n",
       "5      float64\n",
       "6      float64\n",
       "7      float64\n",
       "8      float64\n",
       "9      float64\n",
       "10     float64\n",
       "11     float64\n",
       "12     float64\n",
       "13     float64\n",
       "14     float64\n",
       "15     float64\n",
       "16    category\n",
       "17    category\n",
       "18    category\n",
       "19    category\n",
       "20    category\n",
       "21    category\n",
       "22    category\n",
       "23    category\n",
       "24    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(-9,0):\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype(int) # Integer\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype('category') # Categories\n",
    "data1.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e56a28d-5d28-4f27-bab4-c783ae3a7443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      float64\n",
       "1      float64\n",
       "2      float64\n",
       "3      float64\n",
       "4      float64\n",
       "5      float64\n",
       "6      float64\n",
       "7      float64\n",
       "8      float64\n",
       "9      float64\n",
       "10     float64\n",
       "11     float64\n",
       "12     float64\n",
       "13     float64\n",
       "14     float64\n",
       "15     float64\n",
       "16    category\n",
       "17    category\n",
       "18    category\n",
       "19    category\n",
       "20    category\n",
       "21    category\n",
       "22    category\n",
       "23    category\n",
       "24    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(-9,0):\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype(int) # Integer\n",
    "    data2.iloc[:,i] = data2.iloc[:,i].astype('category') # Categories\n",
    "data2.dtypes\n",
    "#data2.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74374e-7a53-4873-b426-f3c7f61e3b64",
   "metadata": {},
   "source": [
    "# STACKED: Convert columns into Categorical (Only for Stacked Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab01b550-9ba2-4d84-8bc0-a5d28d05d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12     float64\n",
      "13     float64\n",
      "14     float64\n",
      "15     float64\n",
      "16     float64\n",
      "17     float64\n",
      "18     float64\n",
      "19     float64\n",
      "20    category\n",
      "21    category\n",
      "22    category\n",
      "23    category\n",
      "24    category\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aceme\\AppData\\Local\\Temp\\ipykernel_37628\\4157493419.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1[column] = data1[column].astype('category')\n"
     ]
    }
   ],
   "source": [
    "for column in data1.columns[-5:]:\n",
    "    data1[column] = data1[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(data1.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe6694-f2b0-43b4-90a1-fc8e2034b417",
   "metadata": {},
   "source": [
    "# ONLY AFTER DATA2: Concat Synthetic Dataset with New generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bc977ca-c4fc-45e1-8a6b-1d11a262ae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      float64\n",
      "1      float64\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "5      float64\n",
      "6      float64\n",
      "7      float64\n",
      "8      float64\n",
      "9      float64\n",
      "10     float64\n",
      "11     float64\n",
      "12     float64\n",
      "13     float64\n",
      "14     float64\n",
      "15     float64\n",
      "16    category\n",
      "17    category\n",
      "18    category\n",
      "19    category\n",
      "20    category\n",
      "21    category\n",
      "22    category\n",
      "23    category\n",
      "24    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Concat (adding rows)\n",
    "combined_df = np.vstack((data1, data2))\n",
    "\n",
    "# change numpy array into a dataframe\n",
    "combined_data = pd.DataFrame(combined_df, columns=data1.columns)\n",
    "\n",
    "# Convert the last number of columns to categorical (to make sure they have the same)\n",
    "for column in combined_data.columns[-9:]:\n",
    "    combined_data[column] = combined_data[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa6b9-8b74-4f34-b81c-00a47e09409d",
   "metadata": {},
   "source": [
    "# ONLY AFTER DATA2: Split Dataset for combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c152381-70d9-4432-9722-fd110d049a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into X and y (data1)\n",
    "X = combined_data.iloc[:, :-1]  # All columns except the last one\n",
    "y = combined_data.iloc[:, -1]   # Only the last column\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973baf6-f10f-4559-b034-1671b64dd548",
   "metadata": {},
   "source": [
    "# Split Dataset for Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d5edb0a-73dc-47d6-ba73-1c5e13cdda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2\n",
    "X = data1.iloc[:, :-1]\n",
    "y = data1.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Splitting X_train into numerical subset \n",
    "numerical_df = X_train.select_dtypes(include = ['float', 'float64'])\n",
    "\n",
    "# Splitting X_train into categorical subset \n",
    "categorical_df = X_train.select_dtypes(exclude=['float', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30441ffc-4e6b-44be-94fb-4366c680c6ec",
   "metadata": {},
   "source": [
    "# Correlation between columns test (Matrix) (RUN TWICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7781a524-15f7-4da5-95ab-24800c49ed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Correlation Matrix------------------------- \n",
      "           0         1         2         3         4         5         6   \\\n",
      "0   1.000000  0.175752  0.083122  0.119146  0.088334  0.143613  0.113277   \n",
      "1   0.175752  1.000000  0.042609  0.089722  0.063421  0.171262  0.058365   \n",
      "2   0.083122  0.042609  1.000000  0.030859  0.080126  0.042467  0.029534   \n",
      "3   0.119146  0.089722  0.030859  1.000000  0.113651  0.138753  0.140457   \n",
      "4   0.088334  0.063421  0.080126  0.113651  1.000000  0.130374  0.144231   \n",
      "5   0.143613  0.171262  0.042467  0.138753  0.130374  1.000000  0.094412   \n",
      "6   0.113277  0.058365  0.029534  0.140457  0.144231  0.094412  1.000000   \n",
      "7   0.054831  0.055909  0.094165  0.066709  0.057388  0.155300  0.055683   \n",
      "8   0.088817  0.097294  0.096592  0.141374  0.092202  0.195462  0.055579   \n",
      "9   0.089411  0.106878  0.024339  0.133227  0.136056  0.058501  0.170209   \n",
      "10  0.086188  0.108847  0.014867  0.046021  0.050390  0.027430  0.113613   \n",
      "11  0.067314  0.127607  0.068009  0.043285  0.139571  0.026525  0.032590   \n",
      "12  0.117344  0.127371  0.090116  0.095545  0.158211  0.085014  0.172548   \n",
      "13  0.130597  0.067821 -0.018355  0.109879  0.001807  0.110764  0.143234   \n",
      "14  0.121996  0.044828  0.100426  0.192110  0.182262  0.163807  0.017247   \n",
      "15  0.064830  0.061861  0.165738  0.090468  0.119095  0.062295  0.049907   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0   0.054831  0.088817  0.089411  0.086188  0.067314  0.117344  0.130597   \n",
      "1   0.055909  0.097294  0.106878  0.108847  0.127607  0.127371  0.067821   \n",
      "2   0.094165  0.096592  0.024339  0.014867  0.068009  0.090116 -0.018355   \n",
      "3   0.066709  0.141374  0.133227  0.046021  0.043285  0.095545  0.109879   \n",
      "4   0.057388  0.092202  0.136056  0.050390  0.139571  0.158211  0.001807   \n",
      "5   0.155300  0.195462  0.058501  0.027430  0.026525  0.085014  0.110764   \n",
      "6   0.055683  0.055579  0.170209  0.113613  0.032590  0.172548  0.143234   \n",
      "7   1.000000  0.123143  0.081622  0.016988  0.088818  0.075540  0.004889   \n",
      "8   0.123143  1.000000  0.133862  0.058980  0.115561  0.111092  0.129604   \n",
      "9   0.081622  0.133862  1.000000  0.105435  0.101011  0.194799  0.042760   \n",
      "10  0.016988  0.058980  0.105435  1.000000  0.089176 -0.072376  0.082793   \n",
      "11  0.088818  0.115561  0.101011  0.089176  1.000000  0.158271  0.077149   \n",
      "12  0.075540  0.111092  0.194799 -0.072376  0.158271  1.000000  0.157319   \n",
      "13  0.004889  0.129604  0.042760  0.082793  0.077149  0.157319  1.000000   \n",
      "14  0.116899  0.120493  0.118017  0.071281  0.070127  0.134368  0.099604   \n",
      "15  0.027016  0.085900  0.115702  0.014956  0.066954  0.111432  0.117605   \n",
      "\n",
      "          14        15  \n",
      "0   0.121996  0.064830  \n",
      "1   0.044828  0.061861  \n",
      "2   0.100426  0.165738  \n",
      "3   0.192110  0.090468  \n",
      "4   0.182262  0.119095  \n",
      "5   0.163807  0.062295  \n",
      "6   0.017247  0.049907  \n",
      "7   0.116899  0.027016  \n",
      "8   0.120493  0.085900  \n",
      "9   0.118017  0.115702  \n",
      "10  0.071281  0.014956  \n",
      "11  0.070127  0.066954  \n",
      "12  0.134368  0.111432  \n",
      "13  0.099604  0.117605  \n",
      "14  1.000000  0.106509  \n",
      "15  0.106509  1.000000  \n"
     ]
    }
   ],
   "source": [
    "##################### Correlation between columns (numerical) Code ############################\n",
    "# Takes the X_train data to find correlation between NUMERICAL features\n",
    "def num_corr(X_train_numerical):\n",
    "    matrix = X_train_numerical.corr(method='pearson')\n",
    "    print(\"---------------------------Correlation Matrix------------------------- \\n\", matrix)\n",
    "     \n",
    "#Calls the function so the matrix prints out    \n",
    "correlation_matrix = num_corr(numerical_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f7e8a-ca00-46fa-be6a-7daa0025486e",
   "metadata": {},
   "source": [
    "# ONLY AFTER DATA2: Save Correlation Matrix into a Dataframe for combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3bb1258-3e08-4365-a4eb-364b74bb224b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0   1.000000  0.175752  0.083122  0.119146  0.088334  0.143613  0.113277   \n",
      "1   0.175752  1.000000  0.042609  0.089722  0.063421  0.171262  0.058365   \n",
      "2   0.083122  0.042609  1.000000  0.030859  0.080126  0.042467  0.029534   \n",
      "3   0.119146  0.089722  0.030859  1.000000  0.113651  0.138753  0.140457   \n",
      "4   0.088334  0.063421  0.080126  0.113651  1.000000  0.130374  0.144231   \n",
      "5   0.143613  0.171262  0.042467  0.138753  0.130374  1.000000  0.094412   \n",
      "6   0.113277  0.058365  0.029534  0.140457  0.144231  0.094412  1.000000   \n",
      "7   0.054831  0.055909  0.094165  0.066709  0.057388  0.155300  0.055683   \n",
      "8   0.088817  0.097294  0.096592  0.141374  0.092202  0.195462  0.055579   \n",
      "9   0.089411  0.106878  0.024339  0.133227  0.136056  0.058501  0.170209   \n",
      "10  0.086188  0.108847  0.014867  0.046021  0.050390  0.027430  0.113613   \n",
      "11  0.067314  0.127607  0.068009  0.043285  0.139571  0.026525  0.032590   \n",
      "12  0.117344  0.127371  0.090116  0.095545  0.158211  0.085014  0.172548   \n",
      "13  0.130597  0.067821 -0.018355  0.109879  0.001807  0.110764  0.143234   \n",
      "14  0.121996  0.044828  0.100426  0.192110  0.182262  0.163807  0.017247   \n",
      "15  0.064830  0.061861  0.165738  0.090468  0.119095  0.062295  0.049907   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0   0.054831  0.088817  0.089411  0.086188  0.067314  0.117344  0.130597   \n",
      "1   0.055909  0.097294  0.106878  0.108847  0.127607  0.127371  0.067821   \n",
      "2   0.094165  0.096592  0.024339  0.014867  0.068009  0.090116 -0.018355   \n",
      "3   0.066709  0.141374  0.133227  0.046021  0.043285  0.095545  0.109879   \n",
      "4   0.057388  0.092202  0.136056  0.050390  0.139571  0.158211  0.001807   \n",
      "5   0.155300  0.195462  0.058501  0.027430  0.026525  0.085014  0.110764   \n",
      "6   0.055683  0.055579  0.170209  0.113613  0.032590  0.172548  0.143234   \n",
      "7   1.000000  0.123143  0.081622  0.016988  0.088818  0.075540  0.004889   \n",
      "8   0.123143  1.000000  0.133862  0.058980  0.115561  0.111092  0.129604   \n",
      "9   0.081622  0.133862  1.000000  0.105435  0.101011  0.194799  0.042760   \n",
      "10  0.016988  0.058980  0.105435  1.000000  0.089176 -0.072376  0.082793   \n",
      "11  0.088818  0.115561  0.101011  0.089176  1.000000  0.158271  0.077149   \n",
      "12  0.075540  0.111092  0.194799 -0.072376  0.158271  1.000000  0.157319   \n",
      "13  0.004889  0.129604  0.042760  0.082793  0.077149  0.157319  1.000000   \n",
      "14  0.116899  0.120493  0.118017  0.071281  0.070127  0.134368  0.099604   \n",
      "15  0.027016  0.085900  0.115702  0.014956  0.066954  0.111432  0.117605   \n",
      "\n",
      "          14        15  \n",
      "0   0.121996  0.064830  \n",
      "1   0.044828  0.061861  \n",
      "2   0.100426  0.165738  \n",
      "3   0.192110  0.090468  \n",
      "4   0.182262  0.119095  \n",
      "5   0.163807  0.062295  \n",
      "6   0.017247  0.049907  \n",
      "7   0.116899  0.027016  \n",
      "8   0.120493  0.085900  \n",
      "9   0.118017  0.115702  \n",
      "10  0.071281  0.014956  \n",
      "11  0.070127  0.066954  \n",
      "12  0.134368  0.111432  \n",
      "13  0.099604  0.117605  \n",
      "14  1.000000  0.106509  \n",
      "15  0.106509  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combined_data\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df_combined = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df_combined)\n",
    "\n",
    "correlation_df_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49456482-97cc-4ee1-86d8-f89bf61e4f8f",
   "metadata": {},
   "source": [
    "# DATA1 ONLY: Save Correlation Matrix into a Dataframe for Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37eb9739-986a-486b-b499-053be1e7031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0   1.000000  0.153738  0.136624  0.084442  0.065896  0.182015  0.132600   \n",
      "1   0.153738  1.000000  0.031240  0.146102  0.093639  0.203931  0.174417   \n",
      "2   0.136624  0.031240  1.000000  0.108437  0.062278  0.083978  0.070123   \n",
      "3   0.084442  0.146102  0.108437  1.000000  0.086641  0.160223  0.137962   \n",
      "4   0.065896  0.093639  0.062278  0.086641  1.000000  0.190358  0.044607   \n",
      "5   0.182015  0.203931  0.083978  0.160223  0.190358  1.000000  0.114466   \n",
      "6   0.132600  0.174417  0.070123  0.137962  0.044607  0.114466  1.000000   \n",
      "7  -0.022989  0.060006  0.086452  0.016870 -0.012884  0.135468  0.014761   \n",
      "8  -0.007064  0.084242  0.181168  0.064725  0.025051  0.156622 -0.003306   \n",
      "9   0.086244  0.105229  0.078262  0.158098  0.098994  0.092857  0.128217   \n",
      "10  0.039575  0.137728 -0.041335 -0.034744  0.081228 -0.007523  0.080895   \n",
      "11  0.065992  0.114128 -0.031285  0.034905  0.178465  0.110940  0.000335   \n",
      "12  0.084564  0.188954  0.148415  0.088043  0.171399  0.146997  0.189323   \n",
      "13  0.097929  0.086318  0.037046  0.057185  0.099178  0.175591  0.178317   \n",
      "14  0.129875  0.086466  0.155305  0.196424  0.157637  0.197652  0.008271   \n",
      "15 -0.016030  0.003165  0.095199  0.082405  0.063542  0.097313  0.038868   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0  -0.022989 -0.007064  0.086244  0.039575  0.065992  0.084564  0.097929   \n",
      "1   0.060006  0.084242  0.105229  0.137728  0.114128  0.188954  0.086318   \n",
      "2   0.086452  0.181168  0.078262 -0.041335 -0.031285  0.148415  0.037046   \n",
      "3   0.016870  0.064725  0.158098 -0.034744  0.034905  0.088043  0.057185   \n",
      "4  -0.012884  0.025051  0.098994  0.081228  0.178465  0.171399  0.099178   \n",
      "5   0.135468  0.156622  0.092857 -0.007523  0.110940  0.146997  0.175591   \n",
      "6   0.014761 -0.003306  0.128217  0.080895  0.000335  0.189323  0.178317   \n",
      "7   1.000000  0.114769 -0.030194  0.057462  0.056849  0.060638  0.040014   \n",
      "8   0.114769  1.000000  0.059255  0.032596  0.127832  0.156012  0.080372   \n",
      "9  -0.030194  0.059255  1.000000  0.047116  0.075936  0.264154 -0.015389   \n",
      "10  0.057462  0.032596  0.047116  1.000000  0.082608 -0.060547  0.170339   \n",
      "11  0.056849  0.127832  0.075936  0.082608  1.000000  0.166307  0.055487   \n",
      "12  0.060638  0.156012  0.264154 -0.060547  0.166307  1.000000  0.150753   \n",
      "13  0.040014  0.080372 -0.015389  0.170339  0.055487  0.150753  1.000000   \n",
      "14  0.155175  0.056257  0.236458 -0.002716  0.066928  0.154679  0.075919   \n",
      "15  0.044416  0.106193  0.124122 -0.022625  0.040047  0.115245  0.127991   \n",
      "\n",
      "          14        15  \n",
      "0   0.129875 -0.016030  \n",
      "1   0.086466  0.003165  \n",
      "2   0.155305  0.095199  \n",
      "3   0.196424  0.082405  \n",
      "4   0.157637  0.063542  \n",
      "5   0.197652  0.097313  \n",
      "6   0.008271  0.038868  \n",
      "7   0.155175  0.044416  \n",
      "8   0.056257  0.106193  \n",
      "9   0.236458  0.124122  \n",
      "10 -0.002716 -0.022625  \n",
      "11  0.066928  0.040047  \n",
      "12  0.154679  0.115245  \n",
      "13  0.075919  0.127991  \n",
      "14  1.000000  0.086422  \n",
      "15  0.086422  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data1\n",
    "correlation_matrix = numerical_df.corr()\n",
    "correlation_df1 = pd.DataFrame(correlation_matrix)\n",
    "print(correlation_df1)\n",
    "\n",
    "correlation_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce73f85-3fed-49c2-aef8-73a3a1c1a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF NOW DONE WITH DATA1, SCROLL UP TO DATA2 (repeat process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea54a-72ba-4ff8-a05b-4b52434b68cc",
   "metadata": {},
   "source": [
    "# Differences in Matrices (Frobenius Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a262690c-dfaf-40c8-863b-77001e14d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm difference (absolute error) :  0.749\n",
      "Frobenius notrelative error :  0.172\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataframes to numpy arrays\n",
    "matrix1 = correlation_df1.to_numpy()\n",
    "matrix2 = correlation_df_combined.to_numpy()\n",
    "\n",
    "# Compute the Frobenius norm of the difference between the matrices. \n",
    "frobenius_abs = np.linalg.norm(matrix1 - matrix2, ord='fro')   # Absolute error with Frobenius norm\n",
    "\n",
    "frobenius_rel = frobenius_abs/np.linalg.norm(matrix1, ord='fro')    # Relative error with Frobenius norm\n",
    "\n",
    "print(f\"Frobenius norm difference (absolute error) : {frobenius_abs: .3f}\")\n",
    "print(f\"Frobenius notrelative error : {frobenius_rel: .3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893a07c-00f8-4041-ae4b-77e155738f6f",
   "metadata": {},
   "source": [
    "# Differences in Arrays (L2 Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e65e78-7871-4fc8-a693-b5c2ad10229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array1 ...\n",
    "#array2 ...\n",
    "\n",
    "# Compute the L2 norm (Euclidean norm) of the difference between the arrays\n",
    "L2_norm = np.linalg.norm(array1 - array2, ord=2)\n",
    "\n",
    "print(f\"L2 norm difference: {L2_norm: .3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996e1a0-7162-478b-87bc-f7ac46404aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
