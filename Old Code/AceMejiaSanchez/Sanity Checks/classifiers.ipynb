{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975e2c1f-5e05-4835-801d-4263aae6f310",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33083511-5a97-4f13-9b9b-ea3746b444b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39179e0a-ebed-4582-907a-5fe57bff1559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.444140</td>\n",
       "      <td>3.835115</td>\n",
       "      <td>3.291091</td>\n",
       "      <td>5.501369</td>\n",
       "      <td>3.428899</td>\n",
       "      <td>4.922020</td>\n",
       "      <td>6.679717</td>\n",
       "      <td>4.207196</td>\n",
       "      <td>5.551717</td>\n",
       "      <td>4.834592</td>\n",
       "      <td>...</td>\n",
       "      <td>5.827100</td>\n",
       "      <td>5.536030</td>\n",
       "      <td>5.505949</td>\n",
       "      <td>3.871041</td>\n",
       "      <td>4.820020</td>\n",
       "      <td>6.893534</td>\n",
       "      <td>4.675085</td>\n",
       "      <td>6.774422</td>\n",
       "      <td>4.013287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.751552</td>\n",
       "      <td>7.292662</td>\n",
       "      <td>5.983595</td>\n",
       "      <td>6.379493</td>\n",
       "      <td>5.236658</td>\n",
       "      <td>5.765614</td>\n",
       "      <td>5.973641</td>\n",
       "      <td>4.951007</td>\n",
       "      <td>4.739128</td>\n",
       "      <td>5.221459</td>\n",
       "      <td>...</td>\n",
       "      <td>6.917924</td>\n",
       "      <td>6.177616</td>\n",
       "      <td>3.985334</td>\n",
       "      <td>7.088912</td>\n",
       "      <td>6.713774</td>\n",
       "      <td>6.083684</td>\n",
       "      <td>3.632900</td>\n",
       "      <td>4.680444</td>\n",
       "      <td>3.866624</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.271994</td>\n",
       "      <td>6.196881</td>\n",
       "      <td>6.260575</td>\n",
       "      <td>5.059051</td>\n",
       "      <td>7.156964</td>\n",
       "      <td>5.242397</td>\n",
       "      <td>5.938668</td>\n",
       "      <td>6.792579</td>\n",
       "      <td>5.949605</td>\n",
       "      <td>4.961027</td>\n",
       "      <td>...</td>\n",
       "      <td>5.436174</td>\n",
       "      <td>5.076978</td>\n",
       "      <td>5.613830</td>\n",
       "      <td>4.757041</td>\n",
       "      <td>7.940103</td>\n",
       "      <td>5.800670</td>\n",
       "      <td>6.505194</td>\n",
       "      <td>5.033843</td>\n",
       "      <td>8.216384</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.175813</td>\n",
       "      <td>3.704364</td>\n",
       "      <td>3.481604</td>\n",
       "      <td>4.074979</td>\n",
       "      <td>4.708090</td>\n",
       "      <td>5.923180</td>\n",
       "      <td>3.811577</td>\n",
       "      <td>5.946279</td>\n",
       "      <td>5.894935</td>\n",
       "      <td>4.305289</td>\n",
       "      <td>...</td>\n",
       "      <td>3.936844</td>\n",
       "      <td>4.982322</td>\n",
       "      <td>5.583355</td>\n",
       "      <td>3.444634</td>\n",
       "      <td>5.448884</td>\n",
       "      <td>5.031922</td>\n",
       "      <td>5.339520</td>\n",
       "      <td>4.730453</td>\n",
       "      <td>5.299622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.471645</td>\n",
       "      <td>5.372742</td>\n",
       "      <td>6.487397</td>\n",
       "      <td>5.160722</td>\n",
       "      <td>6.983509</td>\n",
       "      <td>5.484562</td>\n",
       "      <td>8.489674</td>\n",
       "      <td>6.386151</td>\n",
       "      <td>5.103722</td>\n",
       "      <td>6.382228</td>\n",
       "      <td>...</td>\n",
       "      <td>5.699915</td>\n",
       "      <td>4.489785</td>\n",
       "      <td>4.401668</td>\n",
       "      <td>5.614796</td>\n",
       "      <td>6.298538</td>\n",
       "      <td>6.293809</td>\n",
       "      <td>5.578622</td>\n",
       "      <td>6.118113</td>\n",
       "      <td>7.776001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  5.444140  3.835115  3.291091  5.501369  3.428899  4.922020  6.679717   \n",
       "1  4.751552  7.292662  5.983595  6.379493  5.236658  5.765614  5.973641   \n",
       "2  6.271994  6.196881  6.260575  5.059051  7.156964  5.242397  5.938668   \n",
       "3  4.175813  3.704364  3.481604  4.074979  4.708090  5.923180  3.811577   \n",
       "4  5.471645  5.372742  6.487397  5.160722  6.983509  5.484562  8.489674   \n",
       "\n",
       "        7         8         9    ...       141       142       143       144  \\\n",
       "0  4.207196  5.551717  4.834592  ...  5.827100  5.536030  5.505949  3.871041   \n",
       "1  4.951007  4.739128  5.221459  ...  6.917924  6.177616  3.985334  7.088912   \n",
       "2  6.792579  5.949605  4.961027  ...  5.436174  5.076978  5.613830  4.757041   \n",
       "3  5.946279  5.894935  4.305289  ...  3.936844  4.982322  5.583355  3.444634   \n",
       "4  6.386151  5.103722  6.382228  ...  5.699915  4.489785  4.401668  5.614796   \n",
       "\n",
       "        145       146       147       148       149  150  \n",
       "0  4.820020  6.893534  4.675085  6.774422  4.013287  1.0  \n",
       "1  6.713774  6.083684  3.632900  4.680444  3.866624  1.0  \n",
       "2  7.940103  5.800670  6.505194  5.033843  8.216384  0.0  \n",
       "3  5.448884  5.031922  5.339520  4.730453  5.299622  1.0  \n",
       "4  6.298538  6.293809  5.578622  6.118113  7.776001  0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/AceMejiaSanchez/Data/gaussian_small_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Kate/Data/uniform_small_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Fabiana/Data/uniform_large_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/gaussian_large_d_1.tex\")\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df = pd.DataFrame(array)\n",
    "\n",
    "# Look at data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47374f2a-42f2-4690-9035-3d6086010171",
   "metadata": {},
   "source": [
    "# Convert 25/150 Columns into CONSECUTIVE Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "42db5971-5001-4ee9-8742-201d0d6b700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 25 columns from numerical floats -> categorical integers\n",
    "for i in range(25):\n",
    "    \n",
    "    df.iloc[:,i] = df.iloc[:,i].round() # Rounding\n",
    "    df.iloc[:,i] = df.iloc[:,i].astype(int) # Integer\n",
    "    df.iloc[:,i] = df.iloc[:,i].astype('category') # Categories\n",
    "    \n",
    "# Turn label into categorical label\n",
    "df.iloc[:,150] = df.iloc[:,150].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee4c61bf-8320-4d97-badf-75d933daa5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.827100</td>\n",
       "      <td>5.536030</td>\n",
       "      <td>5.505949</td>\n",
       "      <td>3.871041</td>\n",
       "      <td>4.820020</td>\n",
       "      <td>6.893534</td>\n",
       "      <td>4.675085</td>\n",
       "      <td>6.774422</td>\n",
       "      <td>4.013287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.917924</td>\n",
       "      <td>6.177616</td>\n",
       "      <td>3.985334</td>\n",
       "      <td>7.088912</td>\n",
       "      <td>6.713774</td>\n",
       "      <td>6.083684</td>\n",
       "      <td>3.632900</td>\n",
       "      <td>4.680444</td>\n",
       "      <td>3.866624</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.436174</td>\n",
       "      <td>5.076978</td>\n",
       "      <td>5.613830</td>\n",
       "      <td>4.757041</td>\n",
       "      <td>7.940103</td>\n",
       "      <td>5.800670</td>\n",
       "      <td>6.505194</td>\n",
       "      <td>5.033843</td>\n",
       "      <td>8.216384</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.936844</td>\n",
       "      <td>4.982322</td>\n",
       "      <td>5.583355</td>\n",
       "      <td>3.444634</td>\n",
       "      <td>5.448884</td>\n",
       "      <td>5.031922</td>\n",
       "      <td>5.339520</td>\n",
       "      <td>4.730453</td>\n",
       "      <td>5.299622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.699915</td>\n",
       "      <td>4.489785</td>\n",
       "      <td>4.401668</td>\n",
       "      <td>5.614796</td>\n",
       "      <td>6.298538</td>\n",
       "      <td>6.293809</td>\n",
       "      <td>5.578622</td>\n",
       "      <td>6.118113</td>\n",
       "      <td>7.776001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...       141       142  \\\n",
       "0  5.0  4.0  3.0  6.0  3.0  5.0  7.0  4.0  6.0  5.0  ...  5.827100  5.536030   \n",
       "1  5.0  7.0  6.0  6.0  5.0  6.0  6.0  5.0  5.0  5.0  ...  6.917924  6.177616   \n",
       "2  6.0  6.0  6.0  5.0  7.0  5.0  6.0  7.0  6.0  5.0  ...  5.436174  5.076978   \n",
       "3  4.0  4.0  3.0  4.0  5.0  6.0  4.0  6.0  6.0  4.0  ...  3.936844  4.982322   \n",
       "4  5.0  5.0  6.0  5.0  7.0  5.0  8.0  6.0  5.0  6.0  ...  5.699915  4.489785   \n",
       "\n",
       "        143       144       145       146       147       148       149  150  \n",
       "0  5.505949  3.871041  4.820020  6.893534  4.675085  6.774422  4.013287  1.0  \n",
       "1  3.985334  7.088912  6.713774  6.083684  3.632900  4.680444  3.866624  1.0  \n",
       "2  5.613830  4.757041  7.940103  5.800670  6.505194  5.033843  8.216384  0.0  \n",
       "3  5.583355  3.444634  5.448884  5.031922  5.339520  4.730453  5.299622  1.0  \n",
       "4  4.401668  5.614796  6.298538  6.293809  5.578622  6.118113  7.776001  0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cd94e-5734-4ad0-84a4-26261dcc3970",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d1bb13f3-63e8-4849-aaca-82a08a8ce06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:150], df.iloc[:,-1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e4fab0-e311-4eac-9256-d03181c3dd14",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "db93291b-647d-4998-b7fe-2b702d8e743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter = plt.scatter(X_train.iloc[:,6], X_train.iloc[:,7], c=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c8cb0-be5d-46d3-bdd1-b589aea83e3f",
   "metadata": {},
   "source": [
    "# XG-BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b556a05d-cddb-48dc-9228-890e7857dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\aceme\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\aceme\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\aceme\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "# First, put this prompt: \"conda install -c conda-forge py-xgboost\" in anaconda to download xgboost package\n",
    "# install xgboost in jupyter\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8486047d-e245-44b0-b266-223cf1d04aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1\n",
      " 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1]\n",
      "Accuracy: 0.7916666666666665\n"
     ]
    }
   ],
   "source": [
    "# import the classifier from the xgboost package\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# read data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# create model instance\n",
    "# n_estimators: number of trees(estimators) the model uses --> the more used, the more accurate the model is\n",
    "# max_depth: maximum depth of tree --> higher number makes model more complex, but too high can cause overfitting\n",
    "# learning_rate: quantifies each tree's contribution to total prediction --> lower number takes longer, but can lead to better generalization\n",
    "# objective: binary:logistic outputs probabilities. if classification is wanted, use binary:hinge\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic', enable_categorical=True)\n",
    "\n",
    "# fit model with the training data\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for the test dataset\n",
    "preds = bst.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(preds)\n",
    "\n",
    "# print model F1-Score\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd9727-fa96-4eed-84fd-ab332fee941d",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9815a9c1-2ef9-468e-a32b-15eee40f443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "# kernel: options for kernel include linear, poly, rbf, sigmoid\n",
    "    # linear: use this when data can be split by a linear function\n",
    "    # poly (polynomial): use this when data can be split by a polynomial function\n",
    "    # rbf (radial basis function): use this when there are clusters of one class inside another\n",
    "    # sigmoid: use this when the split between classes is curved and irregular\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(y_pred)\n",
    "\n",
    "# print model F1-Score\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbb0a4-af3e-4f69-84aa-258df7d433b1",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "43a30467-013d-4449-beeb-9d53774928c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#import knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#create a knn classifier\n",
    "#n_neighbors: predicting the label of the data point by looking at the 3 closest data points and getting them to \"vote\"\n",
    "#algorithm: we may need to look at this if it misbehaves\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#train the model using the training sets\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "#predict the response for the test dataset\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "#print predictions\n",
    "print(y_pred)\n",
    "\n",
    "# print model F1-Score\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a38be0-c339-4bc9-ba85-450adfd743f3",
   "metadata": {},
   "source": [
    "# FIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c0eb0c28-3b5a-4cea-a2b9-eb11d65d1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc = 0.01, classifier = 'DecisionTree', bias = [], control = None, n_jobs = None, random_state = None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73db710-5f77-4fd5-bd77-da872810c6cb",
   "metadata": {},
   "source": [
    "# F1-SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4e350123-8349-4ab6-bed8-6743cbd19a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 1.0\n",
      "[103, 14, 137, 30, 5, 121, 66, 94, 100, 95, 130, 60, 104, 59, 149, 48, 40, 6, 32, 123, 127, 20, 134, 39, 111, 24, 110, 58, 2, 78, 70, 43, 13, 113, 122, 131, 61, 25, 0, 47, 135, 145, 140, 21, 143, 8, 125, 1, 65, 34, 101, 108, 132, 64, 3, 102, 91, 118, 42, 49, 38, 138, 46, 18, 83, 44, 128, 57, 112, 15, 53, 87, 33, 22, 55, 115, 23, 89, 76, 26, 74, 129, 90, 68, 31, 107, 133, 75, 17, 146, 16, 141, 19, 105, 37, 109, 54, 126, 124, 71, 36, 35, 139, 7, 12, 72, 69, 52, 82, 27, 29, 77, 106, 79, 114, 88, 98, 62, 119, 144, 99, 73, 97, 28, 51, 11, 86, 142, 93, 45, 120, 10, 96, 41, 147, 63, 9, 148, 56, 84, 81, 85, 136, 117, 67, 4, 50, 80, 116, 92]\n"
     ]
    }
   ],
   "source": [
    "# Assuming FeatureClassifier is correctly implemented for DecisionTreeClassifier\n",
    "clf1 = FeatureClassifier(0, classifier='DecisionTree', control=3, random_state = 42)\n",
    "\n",
    "# Fit model with the training data\n",
    "clf1.fit(np.array(X_train), np.array(y_train).astype(int))\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred = clf1.predict(np.array(X_test))\n",
    "\n",
    "# Calculate and print F1 score\n",
    "f1 = metrics.f1_score(np.array(y_test).astype(int), y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Print other relevant outputs for debugging\n",
    "print(clf1.indexLs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
