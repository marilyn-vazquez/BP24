{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da77f20e-a3f5-48da-8aec-4960d9f07f79",
   "metadata": {},
   "source": [
    "# HAT\n",
    "- Histogram Augmentation Technique (HAT) is used widely to augment and classify any tabular data\n",
    "- HAT is designed such that the generated data retains the distribution of the original tabular data histogram\n",
    "- HAT analyses the data distribution of a particular feature and based on the feature type (i.e. continuous or discrete) it generates new samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a737b0-03df-46c9-84fa-51d0da483b24",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd4bc04-cb71-4cce-8d99-e5c6e58713ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.DataFrame.iteritems = pd.DataFrame.items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d89b50-13e2-4a37-b0b5-cd58dec13f7e",
   "metadata": {},
   "source": [
    "# Load dataset: STACKED DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c855b190-2706-44ca-831f-c015ec85ab40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data1 = pd.read_csv(\"C:/Users/kateh/OneDrive/Documents/GitHub/BP24/Ellee/Data/Stacked/stacked_orig.csv\", header=None)\n",
    "\n",
    "# # categorical columns have index: 16, 17, 18, 19, 20, 21, 22, 23, 24 (including label column)\n",
    "# for column in data1.columns[-9:]:\n",
    "#     data1[column] = data1[column].astype('category')\n",
    "\n",
    "# # Verify the changes\n",
    "# print(data1.dtypes)\n",
    "\n",
    "# X_train = data1.iloc[:168,:-1]\n",
    "# X_test = data1.iloc[168:,:-1]\n",
    "# y_train = data1.iloc[:168,-1]\n",
    "# y_test = data1.iloc[168:,-1]\n",
    "\n",
    "# # Combining X_train and y_train into one DataFrame\n",
    "# train_combined = pd.concat([X_train, y_train], axis=1)\n",
    "# train_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d57945-0285-4717-8ebe-07c7cd4c4c30",
   "metadata": {},
   "source": [
    "# Load dataset: GAUSSIAN DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16970978-f3ca-41db-a0f6-fa0a9d06b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      float64\n",
      "1      float64\n",
      "2     category\n",
      "3     category\n",
      "4      float64\n",
      "5      float64\n",
      "6      float64\n",
      "7     category\n",
      "8      float64\n",
      "9     category\n",
      "10     float64\n",
      "11     float64\n",
      "12    category\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.596936</td>\n",
       "      <td>6.392943</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.178398</td>\n",
       "      <td>5.707033</td>\n",
       "      <td>6.606476</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.137377</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.139811</td>\n",
       "      <td>5.230782</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.429079</td>\n",
       "      <td>5.295145</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.989084</td>\n",
       "      <td>3.945631</td>\n",
       "      <td>4.585737</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.623490</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.208136</td>\n",
       "      <td>2.886573</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.702416</td>\n",
       "      <td>6.172278</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.611566</td>\n",
       "      <td>6.860789</td>\n",
       "      <td>7.077732</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.919119</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.684395</td>\n",
       "      <td>5.871246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.307809</td>\n",
       "      <td>4.170768</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.405416</td>\n",
       "      <td>4.066206</td>\n",
       "      <td>5.680602</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.241232</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.411881</td>\n",
       "      <td>4.452292</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.064397</td>\n",
       "      <td>5.360269</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.605607</td>\n",
       "      <td>6.865364</td>\n",
       "      <td>5.551478</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.185243</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.178490</td>\n",
       "      <td>5.338828</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>7.185176</td>\n",
       "      <td>5.350908</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.091944</td>\n",
       "      <td>5.542469</td>\n",
       "      <td>5.583059</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.709175</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.219380</td>\n",
       "      <td>6.737135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4.583288</td>\n",
       "      <td>4.238561</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.294444</td>\n",
       "      <td>6.264513</td>\n",
       "      <td>4.746501</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.870950</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.924425</td>\n",
       "      <td>5.579261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6.517825</td>\n",
       "      <td>7.875915</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.428946</td>\n",
       "      <td>5.361262</td>\n",
       "      <td>7.666402</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.657551</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.981350</td>\n",
       "      <td>7.490593</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.361044</td>\n",
       "      <td>3.280050</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.316527</td>\n",
       "      <td>5.822541</td>\n",
       "      <td>5.671623</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.640614</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.547070</td>\n",
       "      <td>3.780136</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>7.296375</td>\n",
       "      <td>6.467932</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.665432</td>\n",
       "      <td>6.517958</td>\n",
       "      <td>5.656407</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.528151</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.735295</td>\n",
       "      <td>6.170193</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1    2    3         4         5         6    7   \\\n",
       "0    5.596936  6.392943  7.0  6.0  6.178398  5.707033  6.606476  5.0   \n",
       "1    5.429079  5.295145  6.0  6.0  4.989084  3.945631  4.585737  5.0   \n",
       "2    5.702416  6.172278  5.0  6.0  6.611566  6.860789  7.077732  7.0   \n",
       "3    4.307809  4.170768  3.0  6.0  4.405416  4.066206  5.680602  6.0   \n",
       "4    5.064397  5.360269  7.0  6.0  7.605607  6.865364  5.551478  7.0   \n",
       "..        ...       ...  ...  ...       ...       ...       ...  ...   \n",
       "115  7.185176  5.350908  6.0  6.0  5.091944  5.542469  5.583059  7.0   \n",
       "116  4.583288  4.238561  7.0  6.0  6.294444  6.264513  4.746501  7.0   \n",
       "117  6.517825  7.875915  6.0  6.0  6.428946  5.361262  7.666402  7.0   \n",
       "118  7.361044  3.280050  6.0  6.0  5.316527  5.822541  5.671623  7.0   \n",
       "119  7.296375  6.467932  5.0  6.0  5.665432  6.517958  5.656407  7.0   \n",
       "\n",
       "           8    9         10        11   12  \n",
       "0    7.137377  6.0  6.139811  5.230782  0.0  \n",
       "1    8.623490  6.0  5.208136  2.886573  0.0  \n",
       "2    6.919119  5.0  4.684395  5.871246  0.0  \n",
       "3    5.241232  4.0  4.411881  4.452292  1.0  \n",
       "4    6.185243  7.0  6.178490  5.338828  0.0  \n",
       "..        ...  ...       ...       ...  ...  \n",
       "115  7.709175  5.0  6.219380  6.737135  0.0  \n",
       "116  5.870950  7.0  5.924425  5.579261  0.0  \n",
       "117  5.657551  5.0  4.981350  7.490593  0.0  \n",
       "118  6.640614  5.0  3.547070  3.780136  0.0  \n",
       "119  4.528151  7.0  4.735295  6.170193  0.0  \n",
       "\n",
       "[120 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"C:/Users/kateh/OneDrive/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)\n",
    "\n",
    "# categorical columns have index: 2, 3, 7, 9\n",
    "\n",
    "# List of column indices that should be converted to categorical\n",
    "categorical_columns = [2, 3, 7, 9, 12]\n",
    "\n",
    "for i in categorical_columns:\n",
    "    data1.iloc[:, i] = data1.iloc[:, i].astype('category') # Convert to categorical type\n",
    "\n",
    "# Display the data types of the columns to verify the changes\n",
    "print(data1.dtypes)\n",
    "\n",
    "X_train = data1.iloc[:120,:-1]\n",
    "X_test = data1.iloc[120:,:-1]\n",
    "y_train = data1.iloc[:120,-1]\n",
    "y_test = data1.iloc[120:,-1]\n",
    "\n",
    "# Combining X_train and y_train into one DataFrame\n",
    "train_combined = pd.concat([X_train, y_train], axis=1)\n",
    "train_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276698d-7740-4366-a511-385114f8561c",
   "metadata": {},
   "source": [
    "# Load dataset: UNIFORM DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95e31d7f-cbe5-4138-8807-fb057e028dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = pd.read_csv(\"C:/Users/kateh/OneDrive/Documents/GitHub/BP24/Ellee/Data/Uniform/uniform_orig.csv\", header=None)\n",
    "\n",
    "# # List of column indices that should be converted to categorical\n",
    "# categorical_columns = [2, 7, 10, 15, 24]\n",
    "\n",
    "# for i in categorical_columns:\n",
    "#     data1.iloc[:, i] = data1.iloc[:, i].astype('category') # Convert to categorical type\n",
    "\n",
    "# # Display the data types of the columns to verify the changes\n",
    "# print(data1.dtypes)\n",
    "\n",
    "# X_train = data1.iloc[:240,:-1]\n",
    "# X_test = data1.iloc[240:,:-1]\n",
    "# y_train = data1.iloc[:240,-1]\n",
    "# y_test = data1.iloc[240:,-1]\n",
    "\n",
    "# # Combining X_train and y_train into one DataFrame\n",
    "# train_combined = pd.concat([X_train, y_train], axis=1)\n",
    "# train_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d254a0b4-3f95-4116-ad30-b9fce5455cfa",
   "metadata": {},
   "source": [
    "# HAT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "250e6e5f-494b-4a96-9910-98a9c27829f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define histogram function\n",
    "#data: This is the original dataset that you want to use for generating new data\n",
    "#no_new_data: This parameter indicates how much new data you want to generate\n",
    "#data_feat: This parameter specifies the type of data feature. It can be either 'c' for continuous data or 'd' for discrete data.\n",
    "#preserve: This parameter determines whether to preserve the original dataset or not while generating new data. If set to True, the original dataset will be included in the generated data; otherwise, it won't be included.\n",
    "def histogram_sampler(data, no_new_data, data_feat, preserve):\n",
    "\n",
    "    if (data_feat == 'c'):\n",
    "        start_time = time.time()\n",
    "        print(\"Existing data:\", len(data))\n",
    "        print(\"New data to be produced:\", no_new_data)\n",
    "\n",
    "#Function parameters\n",
    "#X_new = New data for each iteration\n",
    "#len_X_new = length of the newly generated data\n",
    "#iter_count = number of iterations\n",
    "#data_gen = Augmented data (original data + newly generated data)\n",
    "        \n",
    "        X_new = []\n",
    "        len_X_new = len(X_new)\n",
    "        iter_count = 0\n",
    "        data_gen = data\n",
    "\n",
    "\n",
    "         # Histogram calculation and sampling logic goes here...\n",
    "        # Adjust the condition for the while loop\n",
    "        while (len_X_new < 0.7 * no_new_data):\n",
    "            iter_count += 1\n",
    "            print(\"Number of iterations ---> niter_count=\", iter_count)\n",
    "\n",
    "            \n",
    "#Histogram: Generating the histogram , choosing the mid-value of the bins, and normalizing frequency\n",
    "#fd- Freedman–Diaconis rule is employed to choose the bin size, as it depends on the spread of the data, without any presumption\n",
    "            if (iter_count == 1):\n",
    "                Y,X_interval=np.histogram(data_gen,bins='doane')\n",
    "                n_bins = len(Y)\n",
    "            else:\n",
    "                Y,X_interval=np.histogram(data_gen,bins=n_bins)\n",
    "\n",
    "            \n",
    "            X = ((X_interval[0:-1] + X_interval[1:])/2) \n",
    "            Y = Y/max(Y)\n",
    "\n",
    "            bin_val = list(np.round(X,8))\n",
    "            weight = list(Y)\n",
    "            hist = dict(zip(bin_val,weight))\n",
    "\n",
    "            for xi in bin_val[0:-1]:\n",
    "\n",
    "#Values: choosing the values for undergoing validity check\n",
    "\n",
    "                bin_width = ((max(bin_val) - min(bin_val)) / int(len(bin_val)-1))\n",
    "                xm = xi + (bin_width/2)\n",
    "                x1 = xi\n",
    "                y1 = hist[xi]\n",
    "\n",
    "                res = None\n",
    "                temp = iter(hist)\n",
    "                for key in temp:\n",
    "                    if(key == xi):\n",
    "                        res = next(temp,None)\n",
    "\n",
    "                y2 = hist[res]\n",
    "                ym = ((y1+y2)/2)\n",
    "#Validity check: checking if the specified value can be considered\n",
    "#if(no_new_data <= len(data)):\n",
    "#ym = ym*(np.random.rand()<=ym)\n",
    "#y1 = y1*(np.random.rand()<=y1)\n",
    "    \n",
    "                #else:\n",
    "                ym = ym*(abs(np.random.normal(0,0.5))<=ym)\n",
    "                y1 = y1*(abs(np.random.normal(0,0.5))<=y1)\n",
    "\n",
    "#Appending: appending the valid values\n",
    "                \n",
    "\n",
    "                if (ym!=0):\n",
    "                    X_new.append(np.round(xm,8))\n",
    "                    #X_new.append(np.round(xm+0.1*xm,8))\n",
    "                    #X_new.append(np.round(xm-0.1*xm,8))\n",
    "                if (y1!=0):\n",
    "                    X_new.append(np.round(x1,8))\n",
    "                    #X_new.append(np.round(x1+0.1*xm,8))\n",
    "                    #X_new.append(np.round(x1-0.1*xm,8))\n",
    "#Stopping: bins * 2, length check\n",
    "\n",
    "            data_gen = data_gen + X_new\n",
    "            n_bins = n_bins*2     \n",
    "            len_X_new+= len(X_new)\n",
    "            print(len_X_new)\n",
    "            X_new = []\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "        print(len(data_gen)-len(data),no_new_data)\n",
    "\n",
    "        if(len(data_gen)-len(data) >= no_new_data):\n",
    "            data_gen = data_gen[:len(data)] + list(np.random.choice(data_gen[len(data):], no_new_data, replace = False))\n",
    "            print('\\nNew data generated:', len(data_gen[len(data):]), '\\nNew data:', len(data_gen), '\\n')\n",
    "            #sns.distplot(data_gen)\n",
    "            if(preserve == False):\n",
    "                data_gen = data_gen[len(data):]\n",
    "            return data_gen\n",
    "\n",
    "        else:\n",
    "            print('to discrete...', no_new_data - (len(data_gen)-len(data)))\n",
    "            samples = histogram_sampler(data_gen, no_new_data - (len(data_gen)-len(data)), 'd', preserve = True)\n",
    "            if(preserve == False):\n",
    "                samples = samples[len(data):]\n",
    "            return samples\n",
    "            \n",
    "    elif(data_feat == 'd'):\n",
    "        X_new=[]\n",
    "        data_gen=[]\n",
    "        disc_data= list(set(data))\n",
    "\n",
    "        for i in disc_data: \n",
    "            x=data.count(i)\n",
    "            X_new.append(round(x*(no_new_data) / len(data)))\n",
    "        #print(x_new,sum(x_new))\n",
    "\n",
    "        for j in range(0,len(X_new)):\n",
    "            for i in range(X_new[j]):\n",
    "                data_gen.append(disc_data[j])\n",
    "\n",
    "        if(len(data_gen)==0):\n",
    "            data_gen = data + data_gen\n",
    "\n",
    "        print(no_new_data, sum(X_new))            \n",
    "        if(no_new_data > sum(X_new)):\n",
    "            data_gen = data + data_gen\n",
    "            data_gen = list(data_gen + list(np.random.choice(data_gen,int(no_new_data-sum(X_new)),replace = False)))    \n",
    "\n",
    "        data_gen = list(np.random.choice(data_gen,int(no_new_data),replace = False))   \n",
    "        \n",
    "        if(preserve == True):\n",
    "            data_gen = data + data_gen\n",
    "    \n",
    "        #sns.distplot(data_gen)     \n",
    "        print('\\nNew data generated:', len(data_gen[len(data):]), '\\nNew data:', len(data_gen), '\\n') \n",
    "        return data_gen\n",
    "        \n",
    "    else:\n",
    "        print('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2700468-ca31-4fff-8539-d6139ba6e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_class : This parameter represents the DataFrame containing the data.\n",
    "#diff :This parameter specifies the difference or ratio between the number of samples in the smallest and largest classes after splitting\n",
    "#label_name: It's the column in your DataFrame that you want to use for splitting the data.\n",
    "#cd: It can take values 'c' for continuous classes or 'd' for discrete classes.\n",
    "#label_column: It helps the function identify which column contains the labels or classes.\n",
    "#preserve: If set to `True`, the original dataset will be included in the split data; otherwise, it won't be included.\n",
    "def label_split(df_class, diff, label_name , cd, label_column, preserve):\n",
    "    cdi = 0\n",
    "    columns_data ={}\n",
    "    \n",
    "    df_ = pd.DataFrame(columns=[])\n",
    "    del df_class[label_column]\n",
    "    \n",
    "    for (columnName, columnData) in df_class.iteritems(): \n",
    "        print(columnName)\n",
    "        feat_type = cd[cdi]\n",
    "        df_[columnName] = histogram_sampler(list(columnData.values), diff, feat_type, preserve)\n",
    "        cdi+=1\n",
    "    \n",
    "    df_[label_column] = label_name\n",
    "    print(df_)\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a38fa058-c7a2-4c45-9a9f-51ef5676efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance(data, label_column, cd, augment = False, preserve = True):\n",
    "    split_list=[]\n",
    "    #label_column = 'species'\n",
    "    for label, df_label in data.groupby(label_column):\n",
    "        split_list.append(df_label)\n",
    "\n",
    "    maxLength = max(len(x) for x in split_list)\n",
    "\n",
    "    if(augment == False):\n",
    "        augmented_list=[]\n",
    "        for i in range(0,len(split_list)):\n",
    "\n",
    "            label_name = list(set(split_list[i][label_column]))[0]\n",
    "            diff = maxLength - len(split_list[i])\n",
    "            augmented_list.append(label_split(split_list[i], diff, label_name, cd, label_column, preserve))\n",
    "        finaldf = pd.DataFrame(columns=[])\n",
    "\n",
    "    elif(type(augment) == dict):\n",
    "        augmented_list=[]\n",
    "        for i in range(0,len(split_list)):\n",
    "\n",
    "            label_name = list(set(split_list[i][label_column]))[0]\n",
    "            diff = augment[label_name]\n",
    "            augmented_list.append(label_split(split_list[i], diff, label_name, cd, label_column, preserve))\n",
    "        finaldf = pd.DataFrame(columns=[])\n",
    "\n",
    "    elif(type(augment) == int):\n",
    "\n",
    "        label_count = dict(Counter(list(df[label_column])))\n",
    "        count_key = list(label_count.keys())\n",
    "        count_val = list(label_count.values())\n",
    "\n",
    "        for i in range(0,len(count_val)):\n",
    "            count_val[i] = round(count_val[i] * augment  /sum(list(label_count.values())))\n",
    "\n",
    "\n",
    "        while(sum(count_val) != augment):\n",
    "            if(sum(count_val) > augment):\n",
    "                rand_indx = int(np.random.rand() * len(count_val))\n",
    "                if(count_val[rand_indx] > 0):\n",
    "                    count_val[rand_indx]-= 1\n",
    "\n",
    "            else:\n",
    "                rand_indx = int(np.random.rand() * len(count_val))\n",
    "                count_val[rand_indx]+= 1\n",
    "\n",
    "        new_count = dict(zip(count_key, count_val))\n",
    "\n",
    "        augmented_list=[]\n",
    "        for i in range(0,len(split_list)):\n",
    "\n",
    "            label_name = list(set(split_list[i][label_column]))[0]\n",
    "            diff = new_count[label_name]\n",
    "            augmented_list.append(label_split(split_list[i], diff, label_name, cd, label_column, preserve))\n",
    "        finaldf = pd.DataFrame(columns=[])\n",
    "\n",
    "\n",
    "        #finaldf = class_balance(data, label_column, cd, augment = new_count, preserve = preserve)\n",
    "\n",
    "\n",
    "    for i in range(0,len(split_list)):\n",
    "        finaldf = pd.concat([finaldf,augmented_list[i]],axis=0)\n",
    "\n",
    "    return finaldf\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01651932-1b29-4f4e-82b4-f28c6e506afb",
   "metadata": {},
   "source": [
    "# This is where you begin coding!\n",
    "- Below: Only change --> for i in range(0, 24):\n",
    "- 24 is the number of columns in your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83d942-b529-46ea-81a0-a9e4bb490b09",
   "metadata": {},
   "source": [
    "# Run HAT Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27561d2e-4779-4e0d-8e58-e0f6bdf06d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of new rows to augment:  224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "1\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "2\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "3\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "4\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "5\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "6\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "7\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "8\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "9\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "10\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "11\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "          0         1    2    3         4         5         6    7         8   \\\n",
      "0   5.596936  6.392943  7.0  6.0  6.178398  5.707033  6.606476  5.0  7.137377   \n",
      "1   5.429079  5.295145  6.0  6.0  4.989084  3.945631  4.585737  5.0  8.623490   \n",
      "2   5.702416  6.172278  5.0  6.0  6.611566  6.860789  7.077732  7.0  6.919119   \n",
      "3   5.064397  5.360269  7.0  6.0  7.605607  6.865364  5.551478  7.0  6.185243   \n",
      "4   6.406391  4.913910  6.0  5.0  5.079177  5.817027  4.284056  5.0  5.643546   \n",
      "5   5.534314  5.334691  8.0  6.0  6.577870  3.300916  4.949460  5.0  6.447243   \n",
      "6   6.155975  5.934637  5.0  6.0  5.852345  5.460428  5.851116  6.0  5.853993   \n",
      "7   7.202329  6.716851  5.0  6.0  6.894092  4.651015  7.352533  4.0  7.341246   \n",
      "8   3.469324  5.251129  5.0  6.0  3.988510  7.116241  6.473887  6.0  4.923208   \n",
      "9   7.392368  3.268832  6.0  7.0  5.927271  6.084748  7.031500  6.0  6.639702   \n",
      "10  5.075552  6.784911  5.0  8.0  3.963238  6.310043  7.330238  4.0  5.342560   \n",
      "11  6.120154  5.920678  6.0  8.0  4.566924  5.981041  5.000989  5.0  6.608870   \n",
      "12  5.703799  4.734323  6.0  7.0  6.752765  6.749684  6.129597  6.0  6.179002   \n",
      "13  5.546099  6.499395  5.0  6.0  5.759195  6.017199  7.250997  6.0  4.039187   \n",
      "14  7.189996  6.650038  5.0  7.0  4.571479  6.490176  5.726844  7.0  6.210600   \n",
      "15  7.279756  5.964317  6.0  6.0  6.924658  5.525987  5.083510  7.0  5.797930   \n",
      "16  5.648482  6.318851  4.0  6.0  7.088950  5.952151  6.119839  7.0  5.918971   \n",
      "17  4.997042  6.176937  6.0  6.0  7.079871  5.128712  6.721169  8.0  5.146526   \n",
      "18  5.327867  7.016696  4.0  6.0  5.782515  6.945124  7.646152  5.0  6.970193   \n",
      "19  4.376049  5.904600  6.0  7.0  6.611220  5.328020  4.890202  6.0  4.726318   \n",
      "20  4.097110  5.047997  6.0  6.0  7.323042  5.674522  7.632020  6.0  6.547131   \n",
      "21  5.890270  5.472093  6.0  8.0  5.599756  4.896488  4.748897  7.0  6.678419   \n",
      "22  5.235589  5.584953  6.0  8.0  5.499387  4.409664  7.032000  6.0  5.853709   \n",
      "23  5.918259  5.953738  8.0  6.0  5.044223  5.633227  6.770537  8.0  3.491844   \n",
      "24  4.262623  5.480626  5.0  7.0  6.261249  6.821118  5.630560  8.0  6.290397   \n",
      "25  7.054544  5.494744  5.0  5.0  7.071451  6.640085  6.443935  6.0  4.818190   \n",
      "26  7.235282  7.452864  6.0  4.0  5.525715  5.532571  7.098568  7.0  3.919655   \n",
      "27  3.967052  4.493467  4.0  4.0  7.207132  6.075919  6.310255  5.0  7.503672   \n",
      "28  7.545973  5.865520  7.0  6.0  7.498391  7.291545  6.249108  6.0  6.330015   \n",
      "29  5.741801  4.966243  7.0  7.0  5.610832  5.548583  5.653978  8.0  5.883020   \n",
      "30  8.172242  6.489071  6.0  7.0  8.097148  3.948839  5.185635  6.0  5.035992   \n",
      "31  6.936980  4.918960  7.0  6.0  7.681805  5.320171  6.295589  6.0  6.451573   \n",
      "32  7.854545  7.335607  6.0  6.0  5.783150  7.056815  6.344510  7.0  7.576761   \n",
      "33  7.064665  5.916796  7.0  5.0  6.598436  5.196120  5.768735  6.0  7.058539   \n",
      "34  6.191965  6.940963  6.0  7.0  7.423924  6.372825  5.306592  6.0  4.985339   \n",
      "35  5.690247  6.320501  5.0  7.0  6.236097  7.192003  6.910317  7.0  5.915115   \n",
      "36  5.695169  5.508804  6.0  6.0  5.699533  8.098494  6.048501  6.0  5.083973   \n",
      "37  6.853917  6.566257  8.0  6.0  6.245326  7.300118  5.410839  6.0  5.559799   \n",
      "38  6.651613  5.346124  6.0  5.0  5.820924  6.700055  6.295609  5.0  4.957995   \n",
      "39  6.833478  7.206347  5.0  6.0  7.247600  5.493135  6.730706  6.0  5.960963   \n",
      "40  5.247244  6.474493  7.0  7.0  6.137197  7.296586  6.545846  5.0  6.301731   \n",
      "41  7.642943  5.017763  6.0  5.0  6.044939  5.162401  6.617786  5.0  6.084685   \n",
      "42  6.732514  2.930512  6.0  7.0  6.020405  8.480886  6.107248  8.0  6.387610   \n",
      "43  5.559514  4.211026  6.0  4.0  6.110332  4.284004  7.341168  5.0  5.718139   \n",
      "44  6.703687  6.064183  7.0  8.0  6.839436  5.352511  4.513334  6.0  7.185157   \n",
      "45  6.734113  6.965092  4.0  7.0  5.799682  6.294790  6.430711  6.0  7.043556   \n",
      "46  4.840868  5.990105  5.0  7.0  4.631789  4.934136  4.894502  6.0  5.170363   \n",
      "47  6.490237  5.424558  6.0  5.0  5.035360  5.175661  6.636937  8.0  5.719585   \n",
      "48  6.615135  6.805724  7.0  7.0  6.104782  6.612247  4.948019  3.0  6.271684   \n",
      "49  5.247976  4.660838  7.0  7.0  5.992130  8.344864  7.377327  5.0  5.008763   \n",
      "50  7.679128  7.305886  6.0  6.0  5.907767  5.610342  6.594279  7.0  5.881908   \n",
      "51  4.819875  6.369985  7.0  5.0  6.306791  6.433096  5.898040  7.0  5.554247   \n",
      "52  5.772960  4.802364  6.0  7.0  5.464124  6.384017  6.643206  4.0  4.261729   \n",
      "53  6.409693  5.897709  6.0  6.0  3.820651  5.627815  7.283256  7.0  5.776454   \n",
      "54  5.985452  5.765988  6.0  6.0  6.146165  5.919119  6.256313  5.0  5.232174   \n",
      "55  7.185176  5.350908  6.0  6.0  5.091944  5.542469  5.583059  7.0  7.709175   \n",
      "56  4.583288  4.238561  7.0  6.0  6.294444  6.264513  4.746501  7.0  5.870950   \n",
      "57  6.517825  7.875915  6.0  6.0  6.428946  5.361262  7.666402  7.0  5.657551   \n",
      "58  7.361044  3.280050  6.0  6.0  5.316527  5.822541  5.671623  7.0  6.640614   \n",
      "59  7.296375  6.467932  5.0  6.0  5.665432  6.517958  5.656407  7.0  4.528151   \n",
      "\n",
      "     9         10        11   12  \n",
      "0   6.0  6.139811  5.230782  0.0  \n",
      "1   6.0  5.208136  2.886573  0.0  \n",
      "2   5.0  4.684395  5.871246  0.0  \n",
      "3   7.0  6.178490  5.338828  0.0  \n",
      "4   7.0  6.285720  5.980711  0.0  \n",
      "5   5.0  5.726026  7.893199  0.0  \n",
      "6   4.0  5.875307  4.547044  0.0  \n",
      "7   7.0  4.798448  5.052880  0.0  \n",
      "8   8.0  4.912982  5.441708  0.0  \n",
      "9   6.0  6.698943  6.822522  0.0  \n",
      "10  7.0  5.596924  5.130746  0.0  \n",
      "11  5.0  7.705304  7.023467  0.0  \n",
      "12  5.0  7.943248  5.685950  0.0  \n",
      "13  4.0  5.850030  7.691195  0.0  \n",
      "14  5.0  5.052577  6.803661  0.0  \n",
      "15  5.0  4.976161  4.802076  0.0  \n",
      "16  6.0  5.875458  7.109955  0.0  \n",
      "17  5.0  8.416379  6.329816  0.0  \n",
      "18  7.0  6.526033  5.469854  0.0  \n",
      "19  8.0  7.176382  6.170728  0.0  \n",
      "20  7.0  6.686121  5.503551  0.0  \n",
      "21  6.0  5.908670  4.598366  0.0  \n",
      "22  7.0  6.432159  7.387166  0.0  \n",
      "23  8.0  6.223256  5.497726  0.0  \n",
      "24  6.0  5.862922  3.814903  0.0  \n",
      "25  7.0  5.946600  6.119099  0.0  \n",
      "26  6.0  3.638856  5.455708  0.0  \n",
      "27  6.0  5.785152  4.576634  0.0  \n",
      "28  5.0  4.723811  6.308293  0.0  \n",
      "29  5.0  5.493522  7.529879  0.0  \n",
      "30  7.0  5.208320  5.864852  0.0  \n",
      "31  6.0  6.619325  6.450188  0.0  \n",
      "32  7.0  6.541647  6.581995  0.0  \n",
      "33  5.0  6.753587  5.591417  0.0  \n",
      "34  6.0  6.276327  6.091520  0.0  \n",
      "35  6.0  3.746639  7.372480  0.0  \n",
      "36  5.0  4.634151  5.992043  0.0  \n",
      "37  7.0  4.998713  5.654898  0.0  \n",
      "38  7.0  5.372854  5.430401  0.0  \n",
      "39  7.0  6.806141  6.063315  0.0  \n",
      "40  6.0  5.916654  6.091445  0.0  \n",
      "41  6.0  6.582561  7.011973  0.0  \n",
      "42  7.0  5.392913  7.309143  0.0  \n",
      "43  5.0  6.807557  5.252765  0.0  \n",
      "44  7.0  5.713794  6.413684  0.0  \n",
      "45  4.0  7.526526  6.555926  0.0  \n",
      "46  5.0  6.003962  5.415578  0.0  \n",
      "47  7.0  6.028461  4.080268  0.0  \n",
      "48  6.0  6.127717  6.842150  0.0  \n",
      "49  7.0  5.003687  7.705885  0.0  \n",
      "50  6.0  5.844162  5.678147  0.0  \n",
      "51  6.0  6.450920  5.318377  0.0  \n",
      "52  7.0  4.734138  5.010591  0.0  \n",
      "53  7.0  5.046904  6.622804  0.0  \n",
      "54  6.0  5.535746  5.929357  0.0  \n",
      "55  5.0  6.219380  6.737135  0.0  \n",
      "56  7.0  5.924425  5.579261  0.0  \n",
      "57  5.0  4.981350  7.490593  0.0  \n",
      "58  5.0  3.547070  3.780136  0.0  \n",
      "59  7.0  4.735295  6.170193  0.0  \n",
      "0\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "1\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "2\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "3\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "4\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "5\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "6\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "7\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "8\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "9\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "10\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "11\n",
      "Existing data: 60\n",
      "New data to be produced: 0\n",
      "0 0\n",
      "\n",
      "New data generated: 0 \n",
      "New data: 60 \n",
      "\n",
      "          0         1    2    3         4         5         6    7         8   \\\n",
      "0   4.307809  4.170768  3.0  6.0  4.405416  4.066206  5.680602  6.0  5.241232   \n",
      "1   5.834275  3.564325  6.0  5.0  3.256779  6.439137  4.063638  5.0  5.111320   \n",
      "2   4.806419  3.568842  4.0  4.0  6.253253  2.372733  6.010642  6.0  5.762946   \n",
      "3   5.248060  6.832011  5.0  5.0  5.363832  4.710552  3.841818  5.0  5.252324   \n",
      "4   4.586697  4.472360  5.0  6.0  6.077552  4.704025  5.087675  5.0  4.024883   \n",
      "5   5.720899  4.721652  4.0  6.0  4.798888  4.881947  4.242297  5.0  4.080720   \n",
      "6   6.062941  4.574905  3.0  7.0  4.693401  4.655206  8.468994  5.0  3.567088   \n",
      "7   5.441972  6.094952  5.0  3.0  5.184801  5.724830  5.867825  6.0  4.636006   \n",
      "8   6.448161  5.414750  7.0  4.0  5.405746  3.860178  3.096018  5.0  6.037853   \n",
      "9   4.863069  4.764314  5.0  7.0  4.034312  4.596740  5.386089  5.0  3.422336   \n",
      "10  6.213947  3.574367  4.0  3.0  6.094333  3.757848  5.728376  6.0  5.850987   \n",
      "11  6.280245  4.621907  6.0  6.0  3.781611  3.579684  6.138232  7.0  6.483437   \n",
      "12  5.358708  4.247611  5.0  7.0  5.191702  6.509778  5.492053  5.0  3.963464   \n",
      "13  5.154673  4.194011  5.0  4.0  5.698725  4.710927  5.715743  3.0  5.014955   \n",
      "14  4.396374  5.276412  6.0  4.0  5.392863  6.370201  6.118735  6.0  4.165101   \n",
      "15  4.657120  6.060578  5.0  4.0  3.497998  6.278251  4.282530  4.0  5.389905   \n",
      "16  5.834853  5.511092  5.0  5.0  4.341084  5.844254  6.178046  5.0  6.048947   \n",
      "17  5.763806  3.890314  5.0  4.0  5.748177  5.357902  5.331221  5.0  4.928570   \n",
      "18  5.569309  5.288979  5.0  6.0  4.904803  4.985036  3.564036  4.0  4.968485   \n",
      "19  5.041630  6.789978  3.0  5.0  3.169978  6.144192  4.802284  5.0  6.233268   \n",
      "20  4.320709  5.751255  5.0  4.0  5.205238  4.343904  3.264623  6.0  5.079717   \n",
      "21  5.516420  5.304405  6.0  5.0  4.798958  6.101050  5.133835  4.0  4.952671   \n",
      "22  4.907803  3.838096  5.0  4.0  6.510610  4.482599  5.603096  6.0  4.689769   \n",
      "23  5.624358  3.800501  4.0  3.0  6.550786  4.427655  6.851221  5.0  3.169221   \n",
      "24  4.543959  4.493017  5.0  5.0  6.421123  5.745005  5.463397  5.0  3.963437   \n",
      "25  5.031364  5.788476  6.0  5.0  4.604526  6.977798  5.083489  5.0  5.655565   \n",
      "26  4.883766  6.897795  4.0  3.0  4.403898  6.959174  4.504770  5.0  5.589177   \n",
      "27  3.185652  6.414735  3.0  5.0  6.291207  4.193860  4.928998  5.0  4.044998   \n",
      "28  5.405791  6.209979  6.0  6.0  6.169297  3.818559  5.977498  5.0  6.941689   \n",
      "29  6.119918  5.550057  6.0  5.0  4.822103  4.797021  4.332131  6.0  7.091414   \n",
      "30  3.421119  4.845384  6.0  5.0  5.315548  6.558774  4.902730  4.0  6.314292   \n",
      "31  6.218831  4.806983  5.0  7.0  6.298617  6.338709  2.154242  6.0  6.392343   \n",
      "32  3.222013  5.091805  8.0  6.0  5.806583  5.080549  4.859727  7.0  5.878705   \n",
      "33  7.578369  7.957837  5.0  5.0  6.128759  2.942566  5.205635  6.0  6.166409   \n",
      "34  4.184546  4.496213  6.0  6.0  6.195283  6.498104  4.175435  5.0  5.474373   \n",
      "35  5.278447  3.710497  6.0  5.0  4.541166  5.662146  5.321727  5.0  3.618699   \n",
      "36  3.875903  4.590655  6.0  5.0  4.553236  6.039136  3.448229  5.0  3.871026   \n",
      "37  4.424441  6.224404  6.0  5.0  4.245709  4.995726  5.079357  4.0  5.287330   \n",
      "38  4.119734  5.033207  5.0  4.0  5.684794  4.722916  5.691090  5.0  5.411949   \n",
      "39  4.857692  2.825783  5.0  4.0  5.563327  3.486845  3.416033  5.0  4.856532   \n",
      "40  4.590654  5.313255  5.0  7.0  4.265963  3.820101  6.143161  5.0  6.197323   \n",
      "41  5.963958  4.559898  5.0  5.0  4.947286  6.215504  5.209971  4.0  5.310882   \n",
      "42  5.568782  4.147172  4.0  3.0  5.723142  4.203514  6.385224  6.0  6.729732   \n",
      "43  5.832287  5.326892  7.0  3.0  3.832529  3.990603  5.455258  4.0  4.209129   \n",
      "44  3.101329  6.060481  4.0  5.0  3.082612  4.323419  5.009184  6.0  5.082309   \n",
      "45  5.858998  6.449868  7.0  6.0  3.656296  6.587154  5.169888  5.0  5.187603   \n",
      "46  5.224901  5.256594  5.0  7.0  6.133215  3.354693  6.325946  6.0  3.751437   \n",
      "47  5.165254  5.367693  6.0  6.0  4.138404  6.244508  3.984666  5.0  4.332924   \n",
      "48  3.349792  5.355100  5.0  5.0  5.853717  6.057899  5.315871  6.0  3.726121   \n",
      "49  4.663174  4.460726  4.0  5.0  4.698980  6.361014  5.353959  5.0  4.802938   \n",
      "50  5.418419  6.376306  4.0  4.0  5.364608  2.988939  3.871334  4.0  5.219146   \n",
      "51  3.298482  4.594695  5.0  6.0  6.370103  4.793106  3.424677  4.0  6.156863   \n",
      "52  2.504144  3.726769  5.0  6.0  5.036388  4.864908  6.196544  7.0  5.839259   \n",
      "53  3.844886  5.455383  5.0  6.0  4.904164  5.303066  5.604008  5.0  4.009697   \n",
      "54  5.489250  4.462861  7.0  4.0  5.332029  6.900825  5.097011  6.0  4.095508   \n",
      "55  5.227411  3.804893  6.0  4.0  3.057756  3.113451  3.853110  4.0  5.205356   \n",
      "56  6.302922  4.456670  6.0  5.0  3.334844  7.809058  6.921192  7.0  5.849808   \n",
      "57  4.977861  5.893179  4.0  4.0  4.774601  4.768621  4.909540  4.0  4.569643   \n",
      "58  5.609518  5.871075  6.0  4.0  4.371781  6.305805  5.185200  5.0  5.830094   \n",
      "59  6.307108  5.151312  4.0  4.0  6.880439  5.646834  6.120093  3.0  4.083375   \n",
      "\n",
      "     9         10        11   12  \n",
      "0   4.0  4.411881  4.452292  1.0  \n",
      "1   5.0  7.740854  6.109896  1.0  \n",
      "2   5.0  3.862951  5.585868  1.0  \n",
      "3   4.0  5.120997  2.759233  1.0  \n",
      "4   4.0  5.530339  4.173597  1.0  \n",
      "5   5.0  7.261585  3.401322  1.0  \n",
      "6   4.0  4.704239  5.324074  1.0  \n",
      "7   4.0  3.642273  4.426116  1.0  \n",
      "8   4.0  4.833751  4.855566  1.0  \n",
      "9   6.0  3.578349  5.622139  1.0  \n",
      "10  6.0  3.304138  4.831300  1.0  \n",
      "11  6.0  5.290666  3.514022  1.0  \n",
      "12  4.0  3.278992  4.332985  1.0  \n",
      "13  5.0  4.582410  5.030178  1.0  \n",
      "14  5.0  6.979142  6.181664  1.0  \n",
      "15  7.0  4.792199  5.557160  1.0  \n",
      "16  5.0  5.172958  6.250668  1.0  \n",
      "17  5.0  5.155288  5.660728  1.0  \n",
      "18  6.0  5.122017  5.264355  1.0  \n",
      "19  5.0  4.592609  6.791037  1.0  \n",
      "20  5.0  4.498765  6.214677  1.0  \n",
      "21  4.0  3.277935  5.457799  1.0  \n",
      "22  6.0  4.558421  3.780620  1.0  \n",
      "23  2.0  4.171247  4.298877  1.0  \n",
      "24  5.0  4.365637  6.734942  1.0  \n",
      "25  4.0  4.369911  4.420431  1.0  \n",
      "26  5.0  3.432734  5.949542  1.0  \n",
      "27  5.0  4.619635  3.316309  1.0  \n",
      "28  4.0  4.474739  5.323207  1.0  \n",
      "29  5.0  3.734230  6.666464  1.0  \n",
      "30  3.0  6.544394  4.489705  1.0  \n",
      "31  4.0  5.480754  5.661581  1.0  \n",
      "32  6.0  4.256513  5.728990  1.0  \n",
      "33  4.0  4.292667  6.182997  1.0  \n",
      "34  6.0  5.251179  3.567092  1.0  \n",
      "35  6.0  5.245126  6.578541  1.0  \n",
      "36  5.0  4.306767  4.740394  1.0  \n",
      "37  6.0  4.801798  3.047174  1.0  \n",
      "38  5.0  4.987837  4.723848  1.0  \n",
      "39  4.0  5.514898  5.081731  1.0  \n",
      "40  4.0  3.811208  5.271769  1.0  \n",
      "41  5.0  3.917681  4.343341  1.0  \n",
      "42  5.0  3.968638  5.756199  1.0  \n",
      "43  4.0  5.634480  3.791024  1.0  \n",
      "44  5.0  6.038710  4.373417  1.0  \n",
      "45  5.0  3.999804  3.893594  1.0  \n",
      "46  4.0  5.748998  5.332956  1.0  \n",
      "47  4.0  4.573738  5.940707  1.0  \n",
      "48  4.0  6.356141  5.815176  1.0  \n",
      "49  4.0  5.218309  5.733402  1.0  \n",
      "50  5.0  6.340863  4.013494  1.0  \n",
      "51  6.0  5.241339  4.043854  1.0  \n",
      "52  4.0  4.877632  4.771906  1.0  \n",
      "53  7.0  5.747202  5.454627  1.0  \n",
      "54  4.0  6.168634  3.363170  1.0  \n",
      "55  4.0  5.515495  5.342144  1.0  \n",
      "56  5.0  3.679289  5.124251  1.0  \n",
      "57  4.0  5.011479  4.329630  1.0  \n",
      "58  5.0  5.647032  5.714574  1.0  \n",
      "59  4.0  6.028662  4.050116  1.0  \n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>> 4.792637348175049 seconds \n",
      "----------------------------- Augmented DataFrame -------------------------\n",
      "\n",
      "           0         1    2    3         4         5         6    7   \\\n",
      "0    5.596936  6.392943  7.0  6.0  6.178398  5.707033  6.606476  5.0   \n",
      "1    5.429079  5.295145  6.0  6.0  4.989084  3.945631  4.585737  5.0   \n",
      "2    5.702416  6.172278  5.0  6.0  6.611566  6.860789  7.077732  7.0   \n",
      "3    4.307809  4.170768  3.0  6.0  4.405416  4.066206  5.680602  6.0   \n",
      "4    5.064397  5.360269  7.0  6.0  7.605607  6.865364  5.551478  7.0   \n",
      "..        ...       ...  ...  ...       ...       ...       ...  ...   \n",
      "339  6.615135  6.805724  7.0  7.0  6.104782  6.612247  4.948019  3.0   \n",
      "340  4.590654  5.313255  5.0  7.0  4.265963  3.820101  6.143161  5.0   \n",
      "341  6.936980  4.918960  7.0  6.0  7.681805  5.320171  6.295589  6.0   \n",
      "342  6.732514  2.930512  6.0  7.0  6.020405  8.480886  6.107248  8.0   \n",
      "343  5.248060  6.832011  5.0  5.0  5.363832  4.710552  3.841818  5.0   \n",
      "\n",
      "           8    9         10        11   12  \n",
      "0    7.137377  6.0  6.139811  5.230782  0.0  \n",
      "1    8.623490  6.0  5.208136  2.886573  0.0  \n",
      "2    6.919119  5.0  4.684395  5.871246  0.0  \n",
      "3    5.241232  4.0  4.411881  4.452292  1.0  \n",
      "4    6.185243  7.0  6.178490  5.338828  0.0  \n",
      "..        ...  ...       ...       ...  ...  \n",
      "339  6.271684  6.0  6.127717  6.842150  0.0  \n",
      "340  6.197323  4.0  3.811208  5.271769  1.0  \n",
      "341  6.451573  6.0  6.619325  6.450188  0.0  \n",
      "342  6.387610  7.0  5.392913  7.309143  0.0  \n",
      "343  5.252324  4.0  5.120997  2.759233  1.0  \n",
      "\n",
      "[344 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kateh\\AppData\\Local\\Temp\\ipykernel_42624\\4247497729.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for label, df_label in data.groupby(label_column):\n"
     ]
    }
   ],
   "source": [
    "# Start Timing the Execution: (do not change this)\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a List cd with Specific Values and prints it\n",
    "cd = []\n",
    "for i in range(0, 12):  # you need to input your number of columns\n",
    "    cd.append('c')\n",
    "print(cd)\n",
    "\n",
    "# Assuming train_combined is your dataframe\n",
    "label_column_index = 12  # Index of the label column\n",
    "label_column_name = train_combined.columns[label_column_index]\n",
    "\n",
    "# Function to augment the data\n",
    "def augment_data(a_df, label_column, cd, num_new_rows):\n",
    "    # Assuming class_balance is your augmentation method\n",
    "    augmented_data = class_balance(a_df, label_column=label_column, cd=cd, augment=False, preserve=True)\n",
    "    additional_rows = augmented_data.sample(n=num_new_rows, replace=True)\n",
    "    augmented_data = pd.concat([a_df, additional_rows], ignore_index=True)\n",
    "    return augmented_data\n",
    "\n",
    "# Get user input for the number of new rows to augment\n",
    "num_new_rows = int(input(\"Enter the number of new rows to augment: \"))\n",
    "\n",
    "# Augment the dataframe with the specified number of new rows\n",
    "a_df = augment_data(train_combined, label_column=label_column_name, cd=cd, num_new_rows=num_new_rows)\n",
    "\n",
    "# Print the Time Taken for Execution\n",
    "print(\"\\n\\n\\n>>>>>>>>> %s seconds \" % (time.time() - start_time))\n",
    "\n",
    "# Print new augmented dataframe\n",
    "print(\"----------------------------- Augmented DataFrame -------------------------\\n\")\n",
    "print(a_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b7bcd9e-5923-4da8-85e6-ad592d260452",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('gaussian_HAT.csv', a_df, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
