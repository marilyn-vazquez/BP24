{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68aabc6-0f04-4d84-88a6-78c41c87bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433f8e46-2392-4582-86d7-53152a3ffabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def betterApplyAugmentationMethods(X_train, method, nrows, nvalues=None, unit=None, noise=None):\n",
    "    # If nvalues not specified, entire column is selected\n",
    "    if nvalues is None:\n",
    "        nvalues = X_train.shape[1] - 1\n",
    "\n",
    "    if str(method).lower() == 'pmone':\n",
    "        # Creates empty dataframe to store augmented data\n",
    "        augmentedDf = pd.DataFrame()\n",
    "\n",
    "        # Randomly selects rows from data and appends to augmentedDf\n",
    "        for i in range(nrows):\n",
    "            augmentedDf = pd.concat([augmentedDf, X_train.iloc[[random.randint(0, X_train.shape[0] - 1)]]],\n",
    "                                    ignore_index=True)\n",
    "\n",
    "        # Selects nvalues amount of unique column indexes\n",
    "        randCols = random.sample(range(0, X_train.shape[1] - 1), nvalues)\n",
    "\n",
    "        # Iterates through augmentedData and applies plus or minus to randCols indexes\n",
    "        for i in range(augmentedDf.shape[0]):\n",
    "            for col in randCols:\n",
    "                if (random.randint(0, 1) == 0):\n",
    "                    augmentedDf.iloc[i, col] += unit\n",
    "                else:\n",
    "                    augmentedDf.iloc[i, col] -= unit\n",
    "\n",
    "        return augmentedDf\n",
    "\n",
    "    elif str(method).lower() == 'modpmone':\n",
    "        # Creates empty dataframe to store augmented data\n",
    "        augmentedDf = pd.DataFrame()\n",
    "\n",
    "        # Randomly selects rows from data and appends to augmentedDf\n",
    "        for i in range(nrows):\n",
    "            augmentedDf = pd.concat([augmentedDf, X_train.iloc[[random.randint(0, X_train.shape[0] - 1)]]],\n",
    "                                    ignore_index=True)\n",
    "\n",
    "        # Selects nvalues amount of unique column indexes\n",
    "        randCols = random.sample(range(0, X_train.shape[1] - 1), nvalues)\n",
    "\n",
    "        # Iterates through augmentedData and applies plus or minus to randCols indexes\n",
    "        for i in range(augmentedDf.shape[0]):\n",
    "            for col in randCols:\n",
    "                colMax = X_train.iloc[:, col].max()\n",
    "                colMin = X_train.iloc[:, col].min()\n",
    "\n",
    "                if (augmentedDf.iloc[i, col] + unit < colMax and augmentedDf.iloc[i, col] - unit > colMin):\n",
    "                    if (random.randint(0, 1) == 0):\n",
    "                        if (augmentedDf.iloc[i, col] + unit <= colMax):\n",
    "                            augmentedDf.iloc[i, col] += unit\n",
    "                        else:\n",
    "                            augmentedDf.iloc[i, col] -= unit\n",
    "                    else:\n",
    "                        if (augmentedDf.iloc[i, col] - unit >= colMin):\n",
    "                            augmentedDf.iloc[i, col] -= unit\n",
    "                        else:\n",
    "                            augmentedDf.iloc[i, col] += unit\n",
    "\n",
    "        return augmentedDf\n",
    "\n",
    "    elif str(method).lower() == 'gausnoise':\n",
    "        # Creates empty dataframe to hold augmented rows\n",
    "        augmentedDf = pd.DataFrame()\n",
    "\n",
    "        # Selects random rows from data and appends to augmentedDf\n",
    "        for i in range(nrows):\n",
    "            augmentedDf = pd.concat([augmentedDf, X_train.iloc[[random.randint(0, X_train.shape[0] - 1)]]],\n",
    "                                    ignore_index=True)\n",
    "\n",
    "        # Selects random unique column index\n",
    "        randCols = random.sample(range(0, X_train.shape[1] - 1), nvalues)\n",
    "\n",
    "        # Applies Gaussian noise to randCols values stored in array\n",
    "        for i in range(augmentedDf.shape[0]):\n",
    "            for cols in randCols:\n",
    "                augmentedDf.iloc[i, cols] += np.random.normal(0, noise)\n",
    "\n",
    "        return augmentedDf\n",
    "\n",
    "    elif str(method).lower() == 'modgausnoise':\n",
    "        # Creates an empty dataframe to hold augmented observations\n",
    "        augmentedDf = pd.DataFrame()\n",
    "\n",
    "        # Randomly selects unique column indexs from data\n",
    "        randCols = random.sample(range(0, X_train.shape[1] - 1), nvalues)\n",
    "\n",
    "        # Appends randomly selected rows from data to augmentedDf\n",
    "        for i in range(nrows):\n",
    "            augmentedDf = pd.concat([augmentedDf, X_train.iloc[[random.randint(0, X_train.shape[0] - 1)]]],\n",
    "                                    ignore_index=True)\n",
    "\n",
    "        # Generates Gaussian distribution based on columns summary statistics\n",
    "        # Swaps value with random value in generated Gaussian distribution\n",
    "        for col in randCols:\n",
    "            for i in range(augmentedDf.shape[0]):\n",
    "                mean = augmentedDf[col].mean()\n",
    "                stDev = augmentedDf[col].std()\n",
    "\n",
    "                augmentedDf.iloc[i, col] = np.random.normal(mean, stDev)\n",
    "\n",
    "        return augmentedDf\n",
    "\n",
    "    elif str(method).lower() == 'randswap':\n",
    "        # Creates empty dataframe to store augmented rows\n",
    "        augmentedDf = pd.DataFrame()\n",
    "\n",
    "        # Copies nrows from original data and appends to augmentedDf\n",
    "        for i in range(nrows):\n",
    "            augmentedDf = pd.concat([augmentedDf, X_train.iloc[[random.randint(0, X_train.shape[0] - 1)]]],\n",
    "                                    ignore_index=True)\n",
    "\n",
    "        # Picks UNIQUE column indexes to swap\n",
    "        columnIndexSwaps = random.sample(range(0, X_train.shape[1] - 1), nvalues)\n",
    "\n",
    "        # Swaps augmentedDf column value from same column in data\n",
    "        for i in range(augmentedDf.shape[0]):\n",
    "            for col in columnIndexSwaps:\n",
    "                randValue = X_train.iloc[random.randint(0, X_train.shape[0] - 1), col]\n",
    "\n",
    "                augmentedDf.iloc[i, col] = randValue\n",
    "\n",
    "        return augmentedDf\n",
    "\n",
    "    else:\n",
    "        print(\"Method not found\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generateLabels(X_train, Y_train, augmented):\n",
    "    # import the class\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    # instantiate the model (using the default parameters)\n",
    "    # random.seed(1)\n",
    "    logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "    # fit the model with data\n",
    "\n",
    "    # print(y_train)\n",
    "    logreg.fit(X_train, Y_train)\n",
    "\n",
    "    # create the prediction\n",
    "    augmented_labels = pd.DataFrame(logreg.predict(augmented))\n",
    "\n",
    "    Y_train = pd.concat([Y_train, augmented_labels], axis=0, ignore_index=True)\n",
    "\n",
    "    X_train = pd.concat([X_train, augmented], axis=0, ignore_index=True)\n",
    "\n",
    "    return X_train, Y_train\n",
    "\n",
    "\n",
    "def runClassifier(X_train, Y_train, X_test, Y_test, classifier):\n",
    "    # Creates accuracy table dataframe\n",
    "    results_df = pd.DataFrame(columns=[\"Accuracy\", \"Mean Absolute Error\", \"Rooted Mean Square Error\", \"F1 Score\"])\n",
    "\n",
    "    if classifier == \"kNN\":\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "\n",
    "        knn.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "        # Predict on dataset which model has not seen before\n",
    "        predicted_values = knn.predict(X_test)\n",
    "\n",
    "    elif classifier == \"D_tree\":\n",
    "        clf_gini = DecisionTreeClassifier(criterion=\"gini\",\n",
    "                                          random_state=100, max_depth=3, min_samples_leaf=5)\n",
    "\n",
    "        clf_gini.fit(X_train, Y_train)\n",
    "\n",
    "        predicted_values = clf_gini.predict(X_test)\n",
    "\n",
    "\n",
    "    elif classifier == \"Naive_bayes\":\n",
    "\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "\n",
    "        predicted_values = classifier.predict(X_test)\n",
    "\n",
    "    elif classifier == \"ANN\":\n",
    "        # Performing Feature Scaling\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        # Initializing Artificial Neural Network\n",
    "        ann = tf.keras.models.Sequential()\n",
    "\n",
    "        # Adding Hidden Layers\n",
    "        ann.add(tf.keras.layers.Dense(units=6, activation=\"relu\"))\n",
    "        ann.add(tf.keras.layers.Dense(units=6, activation=\"relu\"))\n",
    "\n",
    "        # Adding output layers\n",
    "        ann.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "        # compiling the Artificial Neural Network\n",
    "        ann.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "        # Fitting the Artificial Neural Network\n",
    "        ann.fit(X_train, Y_train, batch_size=32, epochs=100)\n",
    "\n",
    "        # Generate the predicted labels\n",
    "        first_predicted_values = ann.predict(X_test)\n",
    "        second_predicted_labels = first_predicted_values > .5\n",
    "        final_predicted_labels = second_predicted_labels * 1\n",
    "        predicted_values = final_predicted_labels\n",
    "\n",
    "    # SVM\n",
    "    elif classifier == \"SVM\":\n",
    "        # random.seed(1)\n",
    "        svm = SVC(gamma=2, C=1, kernel='linear', max_iter=1000000, random_state=0)\n",
    "\n",
    "        # fit the model with data\n",
    "        # svm.fit(X_train,y_train)\n",
    "        svm.fit(X_train, Y_train)\n",
    "        predicted_values = svm.predict(X_test)\n",
    "\n",
    "    # XGBoost\n",
    "    elif classifier == \"xgboost\":\n",
    "        # Create model instance\n",
    "        bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic', enable_categorical=True)\n",
    "        \n",
    "        # fit model with the training data\n",
    "        bst.fit(X_train, Y_train)\n",
    "        \n",
    "        # make predictions for the test dataset\n",
    "        predicted_values = bst.predict(X_test)\n",
    "\n",
    "    else:\n",
    "        print(\"Unknown classifier\")\n",
    "        return None\n",
    "\n",
    "    # Accuracy\n",
    "    acc = skm.accuracy_score(Y_test, predicted_values)\n",
    "    mae_accuracy = skm.mean_absolute_error(Y_test, predicted_values)\n",
    "    rmse_accuracy = skm.root_mean_squared_error(Y_test, predicted_values)\n",
    "    f1_accuracy = skm.f1_score(Y_test, predicted_values)\n",
    "\n",
    "    # Appends accuracies to accuracy table\n",
    "    results_df.loc[1, 'Accuracy'] = acc\n",
    "    results_df.loc[1, 'Mean Absolute Error'] = mae_accuracy\n",
    "    results_df.loc[1, 'Rooted Mean Square Error'] = rmse_accuracy\n",
    "    results_df.loc[1, 'F1 Score'] = f1_accuracy\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "generatedGaussianDistrubutions Inputs\n",
    "\n",
    "nrows: Number of rows\n",
    "ncolumns: Number of columns\n",
    "median1: First Gaussian distribution median (center)\n",
    "median2: Second Gaussian distribution median (center)\n",
    "spread1: First Gaussian distrbiution spread\n",
    "spread2: Second Gaussian distribution spread\n",
    "\n",
    "Note:\n",
    "if label == 0, first Gaussian distribution\n",
    "if label == 1, second Gaussian distribution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generateGaussianDistributions(nrows, ncolumns, median1, median2, spread1, spread2):\n",
    "    # Creates first Gaussian distribution\n",
    "    label1 = pd.DataFrame(np.random.normal(median1, spread1, size=(int(nrows / 2), ncolumns)))\n",
    "    # Adds new column for label\n",
    "    label1['label'] = 0\n",
    "\n",
    "    # Creates second Gaussian distribution\n",
    "    label2 = pd.DataFrame(np.random.normal(median2, spread2, size=(int(nrows / 2), ncolumns)))\n",
    "    # Adds new column for label\n",
    "    label2['label'] = 1\n",
    "\n",
    "    # Combines both Gaussian distributions\n",
    "    df = pd.concat([label1, label2])\n",
    "\n",
    "    # Shuffles Gaussian distributions\n",
    "    shuffled_df = pd.DataFrame(np.random.permutation(df))\n",
    "\n",
    "    return shuffled_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "superFunction applies all methods from the flowchart: augmentation, \n",
    "interpretable/uninterpretable classifiers, and accuracy, taking all inputs from\n",
    "these functions and outputs the accuracy of the augmented data.\n",
    "\n",
    "Inputs:\n",
    "    data: A dataframe where the labels are the LAST column\n",
    "    method: The augmentation method the user wants to use for the data\n",
    "    nrows: How many output augmentation rows are wanted\n",
    "    nvalues: The number of values in each row that need to be augmented\n",
    "    classifier: The classifier the user wants to use\n",
    "    unit(optional): Only for the pmOne augmentation method and is the unit the \n",
    "    augmented data will differ from original data by\n",
    "    noise(optional): Only for the gausNoise augmentation method and denotes the\n",
    "    percent by which the augmented data varies from original data\n",
    "\n",
    "\n",
    "Outputs:\n",
    "    Returns two dataframes of original and augmented data accuracy measures\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def superFunction(data, method, nrows, nvalues, classifier, unit=None, noise=None):\n",
    "    X = data.drop(data.shape[1] - 1, axis=1)\n",
    "    Y = data[data.shape[1] - 1]\n",
    "\n",
    "    # Split into training and test set\n",
    "    # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=52)\n",
    "\n",
    "    # Gaussian synth.\n",
    "    X_train = df.iloc[:120,:-1]\n",
    "    X_test = df.iloc[120:,:-1]\n",
    "    Y_train = df.iloc[:120,-1]\n",
    "    Y_test = df.iloc[240:,-1]\n",
    "\n",
    "    original_accuracies = runClassifier(X_train, Y_train, X_test, Y_test, classifier)\n",
    "\n",
    "    # Applies augmentation method to X_train\n",
    "    augmented = betterApplyAugmentationMethods(X_train, method, nrows, nvalues, unit=unit, noise=noise)\n",
    "\n",
    "    # Generates labels and concat to X_train and Y_train\n",
    "    X_train_augmented, Y_train_augmented = generateLabels(X_train, Y_train, augmented)\n",
    "\n",
    "    augmented_accuracies = runClassifier(X_train_augmented, Y_train_augmented, X_test, Y_test, classifier)\n",
    "\n",
    "    return original_accuracies, augmented_accuracies\n",
    "\n",
    "\n",
    "# df = generateGaussianDistributions(500, 150, 0, 0.25, 1, 1)\n",
    "\n",
    "# Prints the F1 Score of the augmented data for each augmentation method\n",
    "# print('pmOne:', superFunction(df, \"pmOne\", 200, 15, \"kNN\", unit=0.1)[1]['F1 Score'][1])\n",
    "# print('randSwap:', superFunction(df, \"randSwap\", 200, 15, \"kNN\")[1]['F1 Score'][1])\n",
    "# print('gausNoise:', superFunction(df, \"gausNoise\", 200, 15, \"kNN\", noise=0.1)[1]['F1 Score'][1])\n",
    "# print('modPmOne:', superFunction(df, \"modpmone\", 200, 15, \"kNN\", unit=0.1)[1]['F1 Score'][1])\n",
    "# print('modGausNoise:', superFunction(df, \"modgausnoise\", 200, 15, \"kNN\")[1]['F1 Score'][1])\n",
    "\n",
    "\n",
    "# orig, new = superFunction(df, \"pmOne\", 200, 15, \"kNN\", unit=0.1)\n",
    "# print('No Augmentation:', orig['F1 Score'][1])\n",
    "# print('w/ Augmentation:', new['F1 Score'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71828927-309a-4dd9-9068-c8f83579f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.loadtxt(\"C:/Users/kateh/OneDrive/Documents/GitHub/BP24/Kate/Testing/uniform_small_d_1.tex\")\n",
    "# array = np.array(data)\n",
    "# df = pd.DataFrame(array)\n",
    "\n",
    "# for i in range(25):\n",
    "#     df.iloc[:,i] = df.iloc[:,i].round() # Rounding\n",
    "#     df.iloc[:,i] = df.iloc[:,i].astype(int) # Integer\n",
    "#     df.iloc[:,i] = df.iloc[:,i].astype('category') # Categories\n",
    "   \n",
    "# df.iloc[:,150] = df.iloc[:,150].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12cbb81-7582-449e-a6f8-3ebb628baf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig, new = superFunction(df, method=\"modpmone\", nrows=200, nvalues=15, classifier=\"xgboost\", unit=0.1)\n",
    "# print(\"Augmentation method modpmone with xgboost classifier:\")\n",
    "# print('Before augmentation:', orig['Accuracy'][1])\n",
    "# print('After augmentation:', new['Accuracy'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456a40f0-7613-461f-b33a-e6a5f9459789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Original\n",
    "df1 = pd.read_csv(\"C:/Users/kateh/OneDrive/Documents/GitHub/BP24/Ellee/Data/Gaussian/gaussian_orig.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "041f8556-9d29-45a6-a6b5-124f6ce7938d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.596936</td>\n",
       "      <td>6.392943</td>\n",
       "      <td>6.178398</td>\n",
       "      <td>5.707033</td>\n",
       "      <td>6.606476</td>\n",
       "      <td>7.137377</td>\n",
       "      <td>6.139811</td>\n",
       "      <td>5.230782</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.429079</td>\n",
       "      <td>5.295145</td>\n",
       "      <td>4.989084</td>\n",
       "      <td>3.945631</td>\n",
       "      <td>4.585737</td>\n",
       "      <td>8.623490</td>\n",
       "      <td>5.208136</td>\n",
       "      <td>2.886573</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.702416</td>\n",
       "      <td>6.172278</td>\n",
       "      <td>6.611566</td>\n",
       "      <td>6.860789</td>\n",
       "      <td>7.077732</td>\n",
       "      <td>6.919119</td>\n",
       "      <td>4.684395</td>\n",
       "      <td>5.871246</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.307809</td>\n",
       "      <td>4.170768</td>\n",
       "      <td>4.405416</td>\n",
       "      <td>4.066206</td>\n",
       "      <td>5.680602</td>\n",
       "      <td>5.241232</td>\n",
       "      <td>4.411881</td>\n",
       "      <td>4.452292</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.064397</td>\n",
       "      <td>5.360269</td>\n",
       "      <td>7.605607</td>\n",
       "      <td>6.865364</td>\n",
       "      <td>5.551478</td>\n",
       "      <td>6.185243</td>\n",
       "      <td>6.178490</td>\n",
       "      <td>5.338828</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>5.468118</td>\n",
       "      <td>6.375846</td>\n",
       "      <td>5.822394</td>\n",
       "      <td>7.188126</td>\n",
       "      <td>7.849766</td>\n",
       "      <td>5.773961</td>\n",
       "      <td>6.569665</td>\n",
       "      <td>7.129214</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>3.758244</td>\n",
       "      <td>4.868939</td>\n",
       "      <td>5.930121</td>\n",
       "      <td>5.815141</td>\n",
       "      <td>6.506723</td>\n",
       "      <td>5.659340</td>\n",
       "      <td>6.105059</td>\n",
       "      <td>5.289611</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3.980267</td>\n",
       "      <td>5.410853</td>\n",
       "      <td>5.625917</td>\n",
       "      <td>3.394410</td>\n",
       "      <td>5.426688</td>\n",
       "      <td>4.446746</td>\n",
       "      <td>6.164200</td>\n",
       "      <td>3.479337</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>6.462183</td>\n",
       "      <td>5.618096</td>\n",
       "      <td>3.953341</td>\n",
       "      <td>7.150823</td>\n",
       "      <td>6.436998</td>\n",
       "      <td>5.679984</td>\n",
       "      <td>7.325375</td>\n",
       "      <td>5.531821</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>4.767006</td>\n",
       "      <td>5.303694</td>\n",
       "      <td>3.940922</td>\n",
       "      <td>4.372523</td>\n",
       "      <td>4.560846</td>\n",
       "      <td>5.400655</td>\n",
       "      <td>5.659464</td>\n",
       "      <td>5.498783</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    5.596936  6.392943  6.178398  5.707033  6.606476  7.137377  6.139811   \n",
       "1    5.429079  5.295145  4.989084  3.945631  4.585737  8.623490  5.208136   \n",
       "2    5.702416  6.172278  6.611566  6.860789  7.077732  6.919119  4.684395   \n",
       "3    4.307809  4.170768  4.405416  4.066206  5.680602  5.241232  4.411881   \n",
       "4    5.064397  5.360269  7.605607  6.865364  5.551478  6.185243  6.178490   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "167  5.468118  6.375846  5.822394  7.188126  7.849766  5.773961  6.569665   \n",
       "168  3.758244  4.868939  5.930121  5.815141  6.506723  5.659340  6.105059   \n",
       "169  3.980267  5.410853  5.625917  3.394410  5.426688  4.446746  6.164200   \n",
       "170  6.462183  5.618096  3.953341  7.150823  6.436998  5.679984  7.325375   \n",
       "171  4.767006  5.303694  3.940922  4.372523  4.560846  5.400655  5.659464   \n",
       "\n",
       "           7    8    9    10   11   12  \n",
       "0    5.230782  7.0  6.0  5.0  6.0  0.0  \n",
       "1    2.886573  6.0  6.0  5.0  6.0  0.0  \n",
       "2    5.871246  5.0  6.0  7.0  5.0  0.0  \n",
       "3    4.452292  3.0  6.0  6.0  4.0  1.0  \n",
       "4    5.338828  7.0  6.0  7.0  7.0  0.0  \n",
       "..        ...  ...  ...  ...  ...  ...  \n",
       "167  7.129214  6.0  7.0  7.0  6.0  0.0  \n",
       "168  5.289611  6.0  7.0  6.0  7.0  0.0  \n",
       "169  3.479337  5.0  3.0  3.0  5.0  1.0  \n",
       "170  5.531821  6.0  5.0  7.0  4.0  0.0  \n",
       "171  5.498783  5.0  7.0  4.0  6.0  1.0  \n",
       "\n",
       "[172 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_convert = [2, 3, 7, 9, 12]\n",
    "columns_to_move = [2, 3, 7, 9]\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    df1.iloc[:, col] = df1.iloc[:, col].astype('category')\n",
    "\n",
    "columns_to_move1 = [df1.columns[i] for i in columns_to_move]\n",
    "\n",
    "# List of columns excluding the ones to be moved and the last column\n",
    "remaining_columns1 = [col for col in df1.columns if col not in columns_to_move1 and col != df1.columns[-1]]\n",
    "\n",
    "# Append the columns to be moved just before the last column\n",
    "new_column_order1 = remaining_columns1 + columns_to_move1 + [df1.columns[-1]]\n",
    "\n",
    "df1 = df1[new_column_order1]\n",
    "\n",
    "df1.columns = range(df1.shape[1])\n",
    "\n",
    "df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
