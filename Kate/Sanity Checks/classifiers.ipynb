{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975e2c1f-5e05-4835-801d-4263aae6f310",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "39179e0a-ebed-4582-907a-5fe57bff1559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.645936</td>\n",
       "      <td>4.444420</td>\n",
       "      <td>5.882756</td>\n",
       "      <td>6.699313</td>\n",
       "      <td>3.362616</td>\n",
       "      <td>5.624176</td>\n",
       "      <td>4.552078</td>\n",
       "      <td>2.622931</td>\n",
       "      <td>6.745673</td>\n",
       "      <td>5.324437</td>\n",
       "      <td>...</td>\n",
       "      <td>5.005013</td>\n",
       "      <td>5.525472</td>\n",
       "      <td>5.835458</td>\n",
       "      <td>4.334682</td>\n",
       "      <td>5.882338</td>\n",
       "      <td>4.320398</td>\n",
       "      <td>7.020972</td>\n",
       "      <td>4.373049</td>\n",
       "      <td>6.877316</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.685283</td>\n",
       "      <td>6.174860</td>\n",
       "      <td>5.757977</td>\n",
       "      <td>6.520946</td>\n",
       "      <td>5.247406</td>\n",
       "      <td>7.182799</td>\n",
       "      <td>7.582562</td>\n",
       "      <td>5.345074</td>\n",
       "      <td>6.239722</td>\n",
       "      <td>5.959306</td>\n",
       "      <td>...</td>\n",
       "      <td>5.936925</td>\n",
       "      <td>7.035587</td>\n",
       "      <td>5.807185</td>\n",
       "      <td>6.260498</td>\n",
       "      <td>5.713241</td>\n",
       "      <td>4.741151</td>\n",
       "      <td>8.523618</td>\n",
       "      <td>7.544684</td>\n",
       "      <td>6.321774</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.833938</td>\n",
       "      <td>5.480186</td>\n",
       "      <td>4.660813</td>\n",
       "      <td>2.640568</td>\n",
       "      <td>4.991246</td>\n",
       "      <td>5.329018</td>\n",
       "      <td>4.527029</td>\n",
       "      <td>4.486931</td>\n",
       "      <td>5.577468</td>\n",
       "      <td>4.682285</td>\n",
       "      <td>...</td>\n",
       "      <td>3.801542</td>\n",
       "      <td>3.500481</td>\n",
       "      <td>5.433775</td>\n",
       "      <td>4.678873</td>\n",
       "      <td>5.093956</td>\n",
       "      <td>4.844797</td>\n",
       "      <td>5.067531</td>\n",
       "      <td>5.539606</td>\n",
       "      <td>4.852789</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.840690</td>\n",
       "      <td>3.332420</td>\n",
       "      <td>4.881624</td>\n",
       "      <td>4.554784</td>\n",
       "      <td>4.809637</td>\n",
       "      <td>2.666808</td>\n",
       "      <td>5.156898</td>\n",
       "      <td>4.464810</td>\n",
       "      <td>5.552007</td>\n",
       "      <td>4.911071</td>\n",
       "      <td>...</td>\n",
       "      <td>5.185953</td>\n",
       "      <td>5.964207</td>\n",
       "      <td>5.399361</td>\n",
       "      <td>3.848238</td>\n",
       "      <td>5.883973</td>\n",
       "      <td>5.656945</td>\n",
       "      <td>4.562846</td>\n",
       "      <td>4.012647</td>\n",
       "      <td>6.632066</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.443890</td>\n",
       "      <td>5.533707</td>\n",
       "      <td>5.561488</td>\n",
       "      <td>4.913582</td>\n",
       "      <td>5.843202</td>\n",
       "      <td>5.324853</td>\n",
       "      <td>5.749330</td>\n",
       "      <td>5.860838</td>\n",
       "      <td>5.765502</td>\n",
       "      <td>5.117370</td>\n",
       "      <td>...</td>\n",
       "      <td>3.163400</td>\n",
       "      <td>5.900974</td>\n",
       "      <td>4.625896</td>\n",
       "      <td>5.144522</td>\n",
       "      <td>4.693454</td>\n",
       "      <td>6.534560</td>\n",
       "      <td>4.659843</td>\n",
       "      <td>4.017394</td>\n",
       "      <td>6.300626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  4.645936  4.444420  5.882756  6.699313  3.362616  5.624176  4.552078   \n",
       "1  6.685283  6.174860  5.757977  6.520946  5.247406  7.182799  7.582562   \n",
       "2  5.833938  5.480186  4.660813  2.640568  4.991246  5.329018  4.527029   \n",
       "3  3.840690  3.332420  4.881624  4.554784  4.809637  2.666808  5.156898   \n",
       "4  5.443890  5.533707  5.561488  4.913582  5.843202  5.324853  5.749330   \n",
       "\n",
       "        7         8         9    ...       141       142       143       144  \\\n",
       "0  2.622931  6.745673  5.324437  ...  5.005013  5.525472  5.835458  4.334682   \n",
       "1  5.345074  6.239722  5.959306  ...  5.936925  7.035587  5.807185  6.260498   \n",
       "2  4.486931  5.577468  4.682285  ...  3.801542  3.500481  5.433775  4.678873   \n",
       "3  4.464810  5.552007  4.911071  ...  5.185953  5.964207  5.399361  3.848238   \n",
       "4  5.860838  5.765502  5.117370  ...  3.163400  5.900974  4.625896  5.144522   \n",
       "\n",
       "        145       146       147       148       149  150  \n",
       "0  5.882338  4.320398  7.020972  4.373049  6.877316  1.0  \n",
       "1  5.713241  4.741151  8.523618  7.544684  6.321774  0.0  \n",
       "2  5.093956  4.844797  5.067531  5.539606  4.852789  1.0  \n",
       "3  5.883973  5.656945  4.562846  4.012647  6.632066  1.0  \n",
       "4  4.693454  6.534560  4.659843  4.017394  6.300626  1.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/AceMejiaSanchez/Data/gaussian_small_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Kate/Data/uniform_small_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Fabiana/Data/uniform_large_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/gaussian_large_d_1.tex\")\n",
    "\n",
    "# Creating NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df = pd.DataFrame(array)\n",
    "\n",
    "# Look at data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47374f2a-42f2-4690-9035-3d6086010171",
   "metadata": {},
   "source": [
    "# Convert 25/150 Columns into NON-CONSECUTIVE Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "42db5971-5001-4ee9-8742-201d0d6b700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 25 columns from numerical floats -> categorical integers\n",
    "for i in range(25):\n",
    "    \n",
    "    df.iloc[:,i] = df.iloc[:,i].round() # Rounding\n",
    "    df.iloc[:,i] = df.iloc[:,i].astype(int) # Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ee4c61bf-8320-4d97-badf-75d933daa5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.400718</td>\n",
       "      <td>9.613205</td>\n",
       "      <td>7.522342</td>\n",
       "      <td>8.623440</td>\n",
       "      <td>8.639828</td>\n",
       "      <td>8.749055</td>\n",
       "      <td>9.208908</td>\n",
       "      <td>9.060524</td>\n",
       "      <td>8.933239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.874917</td>\n",
       "      <td>4.508863</td>\n",
       "      <td>5.760392</td>\n",
       "      <td>5.427105</td>\n",
       "      <td>5.100361</td>\n",
       "      <td>6.743385</td>\n",
       "      <td>4.463974</td>\n",
       "      <td>5.194206</td>\n",
       "      <td>3.705310</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.719226</td>\n",
       "      <td>8.556954</td>\n",
       "      <td>7.247095</td>\n",
       "      <td>8.142212</td>\n",
       "      <td>8.558377</td>\n",
       "      <td>8.417857</td>\n",
       "      <td>8.760038</td>\n",
       "      <td>8.464984</td>\n",
       "      <td>9.188946</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.039694</td>\n",
       "      <td>4.193900</td>\n",
       "      <td>6.023520</td>\n",
       "      <td>6.168796</td>\n",
       "      <td>4.758035</td>\n",
       "      <td>5.899085</td>\n",
       "      <td>5.069440</td>\n",
       "      <td>6.234275</td>\n",
       "      <td>3.800722</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.617910</td>\n",
       "      <td>7.790990</td>\n",
       "      <td>10.612359</td>\n",
       "      <td>9.874875</td>\n",
       "      <td>8.924992</td>\n",
       "      <td>9.743395</td>\n",
       "      <td>8.162828</td>\n",
       "      <td>8.706789</td>\n",
       "      <td>9.728883</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2    3     4     5     6    7     8     9    ...       141  \\\n",
       "0   9.0  10.0  10.0  8.0   9.0   9.0   9.0  9.0   9.0   8.0  ...  7.400718   \n",
       "1   4.0   6.0   4.0  7.0   5.0   5.0   7.0  5.0   5.0   5.0  ...  4.874917   \n",
       "2  10.0   9.0   9.0  9.0  10.0  12.0  10.0  9.0  10.0  10.0  ...  7.719226   \n",
       "3   5.0   6.0   6.0  5.0   5.0   6.0   6.0  7.0   4.0   5.0  ...  5.039694   \n",
       "4   8.0  10.0   8.0  9.0   9.0  11.0   9.0  9.0   8.0   9.0  ...  6.617910   \n",
       "\n",
       "        142        143       144       145       146       147       148  \\\n",
       "0  9.613205   7.522342  8.623440  8.639828  8.749055  9.208908  9.060524   \n",
       "1  4.508863   5.760392  5.427105  5.100361  6.743385  4.463974  5.194206   \n",
       "2  8.556954   7.247095  8.142212  8.558377  8.417857  8.760038  8.464984   \n",
       "3  4.193900   6.023520  6.168796  4.758035  5.899085  5.069440  6.234275   \n",
       "4  7.790990  10.612359  9.874875  8.924992  9.743395  8.162828  8.706789   \n",
       "\n",
       "        149  150  \n",
       "0  8.933239  0.0  \n",
       "1  3.705310  1.0  \n",
       "2  9.188946  0.0  \n",
       "3  3.800722  1.0  \n",
       "4  9.728883  0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cd94e-5734-4ad0-84a4-26261dcc3970",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d1bb13f3-63e8-4849-aaca-82a08a8ce06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:150], df.iloc[:,-1], test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "983d27b7-a27a-45a2-b7da-812d4645eb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159    1.0\n",
       "198    0.0\n",
       "259    1.0\n",
       "301    1.0\n",
       "220    1.0\n",
       "      ... \n",
       "86     0.0\n",
       "151    0.0\n",
       "13     0.0\n",
       "267    0.0\n",
       "156    1.0\n",
       "Name: 150, Length: 400, dtype: category\n",
       "Categories (2, float64): [0.0, 1.0]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e4fab0-e311-4eac-9256-d03181c3dd14",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "db93291b-647d-4998-b7fe-2b702d8e743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9t0lEQVR4nO3deXwU9f3H8ffMbrIkIVlIEEIEFCuKCiqKrQdVqIVaFa+KIh541KuoqNUiKoKtEjmkKngUtWhF1FpREUsVEeHn0Yoi3opUKihG7t2EhBw78/sjgsYku7OS/c5meT0fj63NzAf27brJvHeuWK7rugIAADDE9jsAAADYuVA+AACAUZQPAABgFOUDAAAYRfkAAABGUT4AAIBRlA8AAGAU5QMAABgV9DvADzmOozVr1ig/P1+WZfkdBwAAeOC6rsrLy1VSUiLbjr9vI+3Kx5o1a9S1a1e/YwAAgB9h9erV6tKlS9yZtCsf+fn5kurDFxQU+JwGAAB4EY1G1bVr1+3b8XjSrnxsO9RSUFBA+QAAoJXxcsoEJ5wCAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjEq7m4wByEx1tXV6Z8H72vRNRB12LdQBA/ZTIBDwOxYAHyS952Px4sUaPHiwSkpKZFmWnnnmme3ramtrNWrUKPXu3Vt5eXkqKSnROeecozVr1rRkZgCtzEszF+uMrpfo+mPHa9J5d2vUoD/pzN0u1f/N/o/f0QD4IOnysWXLFh1wwAGaNm1ao3WVlZVaunSpxowZo6VLl2r27Nlavny5TjjhhBYJC6D1eWnmYk04Z6o2r400WL7h603645DJeu2ZN31KBsAvluu67o/+w5alp59+WieddFKzM0uWLNFPf/pTffHFF+rWrVvCvzMajSocDisSifC7XYBWrq62TkO7XKzIumjTA5ZUvHtHPfzZ1IS/ghtAektm+53y7/ZIJCLLstSuXbsm11dXVysajTZ4AMgM7yx4v/niIUmuVLZyrT7+92fmQgHwXUrLx9atW3Xddddp2LBhzbag0tJShcPh7Y+uXbumMhIAgzaWbW7ROQCZIWXlo7a2VkOHDpXjOLrnnnuanRs9erQikcj2x+rVq1MVCYBhRSWFnuY67OptDkBmSMmltrW1tTrttNO0cuVKvfzyy3GP/YRCIYVCoVTEAOCzPr/opfbF7bSpmT0blmWpZM9i9fzpnmaDAfBVi+/52FY8PvvsM7300ksqKipq6acA0EoEggFddtf5kqX6x/dYliVZ0og7z6v//wB2GkmXj4qKCi1btkzLli2TJK1cuVLLli3TqlWrVFdXp1NPPVVvvfWWHn30UcViMZWVlamsrEw1NTUtnR1AK3DkqYdp7D+uUcduuzRY3vknnXTr3NE65Jg+PiUD4JekL7V95ZVXNGDAgEbLhw8frnHjxql79+5N/rmFCxeqf//+Cf9+LrUFMpPjOProjeXaVLZZRbsWap+f9WCPB5BBktl+J33OR//+/RWvr+zAbUMAZDDbttXriJ5+xwCQBrirDwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIwK+h0AANJRTU2N7rzkfr3yxOuqra5VIBjQwYP213WPXK624bZ+x2tSVVWVzur2O0U3VGxfZgUs3favG3TQ0Qf4mCy+ET8dpeVvfb7962BWQGNnX6NDj+vrY6r4vvhotebeN1+fvvVfZbfJ0mGD+2rQuf2V3z493xuS9PXn32juX+brg1c/ViAYUN9fHahfX/ALte/UzngWy3Vd1/izxhGNRhUOhxWJRFRQUOB3HAA7ocjGcp2x60Wqra5rtM6yLU1fNlm79+rmQ7Lmbdy4Uad3uLjZ9cdddLSuvO8Sg4kSq66u1vE5ZzW7/sghh2rME783mMib2Xc+r3uvfkh2wJZT50iSLMtS2/Z5mjj/Ju3Zp7vPCRt7aeZiTTrvbkmSE/s2s20plJOtW54brQP677fDz5HM9pvyAQA/cFrJhdpUtrnZ9dltsvR85SxzgTwYaA9JODPfedJAEu+Ob3umqitr4s489s0D6rBL2FCixN568V2NPuaWJtfZAVv5hW31yOd3KyevjeFkzVvxzkr97pBRcp3Gm/ttBeRvK6bt8B6QZLbfnPMBAN+z5r9fxy0eklSztVaLnnzdTCAPvlrxlae5Ybunz56P6urqhMVDki7e7yoDabx7cvKzsgNNbzqdmKPIuqgWPvaa4VTxPXXHXNm21eQ613FVXVWjfz6wwGgmygcAfM8TE5/1NPf0Xf9McRLvxp4y2dPculUbUpzEu+fuedHTXHR9eYqTeOc4jpa9/MH2wxZNsW1L7yx4z2CqxJbMe0exuuYzu46rt19812AiygcANFBXG/M0F/M4Z0I6ZfGqqmKr3xF+lERnKriuFKtLr/8eTizx2RVe3/cthfIBAN/z6wuO9jR31OmHpziJdxffPtzTXE5+ToqTeHfiyF95mgvlZqc4iXe2bWvPg/aQ1cwhDEmSJe1z6N7mQnmw3xF7yw42v7m3A7Z69+tpMBHlAwAa6HVET7VpG/9kQcu2dOpVgw0lSuzQYw/2NPfQyjtSGyQJBQUFzZ478X2TF45LfZgk/ObK45s8cVOSLEvKCmXpV+f2NxsqgZNHHrf9qpzmHHfxQENp6lE+AOAH7nztT1KcD7c3PZl+l3/+ae51cdd337+bCgsLDaXxZubKaXHXd+25q3oe0sNQGm9+Mayfjr+kfkP9/fIUCNoKBAO66e9Xq6Ao3694TTro6N46Z+xpktRgD0ggaMuyLF3z19+p5CfFRjNxqS0ANOGbVet004kT9fl7/5O+/SnZeY9OuuGJK7X3wXv6mq05n7z1ma449IZGn8yPOW+Afv/g73xKFd/6dRGdu8cIVW+pbrB84DlH6g8PXe5Tqvhc19Ubc97S01P/qc+Wfq6s7CwdcdJPdfLIY7XbPl38jtespQve19N3Pa8PXv1EgYCtvsccqFNGHqe9Dv5Ji/z93OcDAAAYxX0+AABA2qJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwCM2bQ2opUfrFJkfdTvKJ5NumCahnT+rW46+Ta/o3h20ykT9Os2Q3Xm7pf4HcWz5x94Uef2vFx/GDhOlZWVfsfxJLqxXG88t0TvvvKhHMfxO06rYrmu6/od4vui0ajC4bAikYgKCgr8jgOgBSx/+7+accNjemv+u5IrWZalnx1/kM6/dZi69+rmd7wmDet+qdZ9sb7R8lBuSHMrZvqQKLEhxRdo89qmi91850nDaby589LpmvuX+Y2W20FbL9Q84UOixNav2agxg2/TindWbl8WyApo0Dn9dfX9rafwtbRktt9J7/lYvHixBg8erJKSElmWpWeeeabBetd1NW7cOJWUlCgnJ0f9+/fXhx9+mOzTAMgQH7z2ia7sd6OWLnhf+vajjuu6evOf7+jyQ69v8AM8XZy+62+bLB6SVF1ZrWNCQw0nSixe8ZCkgfYQg2m8ue+ah5osHpLk1DlpmXnT2s06t8fljd63sdqY5j24QNcMGOdPsFYm6fKxZcsWHXDAAZo2bVqT6ydOnKgpU6Zo2rRpWrJkiYqLizVw4ECVl5fvcFgArYvrurr9gnsUq43JiTXcLe3EHNVW1+qOS6b7lK55G7+OxF0fq42prKzMUBpv4hWPbR4a95iBJN49NeX5hDPTrnjQQBLvJg6fpuqqmmbXv7vow/o9fIgr6fLx61//WrfccotOOeWURutc19Udd9yhG264Qaeccop69eqlhx9+WJWVlZo1a1aLBAbQenz4+qf6cvnXcpymj+46MUefLlmhlR+sMpyseef2vMLb3G5XpjZIEq7qP8bT3KN/nJ3iJN598MbHnuaenfavFCdJztKX3k8489CYxw0kad1a9ITTlStXqqysTIMGDdq+LBQK6aijjtLrr7/e5J+prq5WNBpt8ACQGb767OsWnTNhzQpvezRitbEUJ/Huo9c+9TtC0mb/OfFej3RTU1PbaA9eU9at3mAgTevWouVj227ITp06NVjeqVOnZndRlpaWKhwOb3907dq1JSMB8FFeONfTXG6BtzkTsttk+R0haW3ahvyOkLTeR+3nd4SkBYMBT3Oh3OwUJ2n9UnKprWVZDb52XbfRsm1Gjx6tSCSy/bF69epURALgg4MHHaA2efE3jOEO+er9856GEiV2z7LJnuZOG3ViipN4N+O/d3qaa9cxfa4gPHnErz3NFZW0T3ES72zbVsmexQnnBp7TP/VhWrkWLR/FxfX/UX64l2Pt2rWN9oZsEwqFVFBQ0OABIDPk5LXRsOt/E3fm7LGnKSs7ffY2dNuzs6e5C0vPSnES7woLCz3NPVmWXidv5hfmJZx5/Mv0OiH5kinnxl3fJi+kM0afZCRLa9ai5aN79+4qLi7W/PnfXTpVU1OjRYsW6fDDD2/JpwLQSgy97iSdecNvFAjasmxLwazA9n9eMH6YTvjdr/yO2Eiie2I8smaqoSTeJcr8+xmXGkri3ez1DymY3fyhjGvSMPNhxx+sy6ddIMtuvDe/bbs83bd0koLBoA/JWpekbzJWUVGhFStWSJL69OmjKVOmaMCAASosLFS3bt00YcIElZaWasaMGerRo4fGjx+vV155RZ9++qny8/MT/v3cZAzITJu+2ayFj7+mTWWb1aFLkQYMPUIFRYl/Jvhp6hUPaM60F7Z/feDRvTRp/lgfEyU25eJ7NO/+hdu/bts+T09veMi/QB78Z97bGnP8BG3bHHXbt0QPfuDtUJJftlZu1d/G/l0fvvGpsrKz9OvfHq2jh/3c71i+Smb7nXT5eOWVVzRgwIBGy4cPH66HHnpIruvq5ptv1l/+8hdt2rRJP/vZz3T33XerV69eLR4eAACkh5SWj1SjfAAA0Pqk9PbqAAAAO4LyAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADAq6HcAADuHe6+aoWfv/pdiMUeBYEDDrj9Z54w93e9YcZ2yy7kq37Bl+9fB7IDmbX3cx0SJnbbrb7Xp60iDZfOdJ31K4830UY/oyUlztn8dysvW3PJHfUyU2LqvNqj0zLu06qPVCmQFdOSph+mSKcMVCAT8jtas2ppavf7MEn30xnLZAVsHDdxfBw/cX7Ztfj+E5bqua/xZ44hGowqHw4pEIiooKPA7DoAdVFFRoZPD50lN/KSxbEtzK2cqOzvbfLA4vvnmG53V+bJm15e+cKP6DjzAYCJvBtpDml33qwuO1DX3X24wjTfxMp905bEaMeU8g2m8uf2Ce/SvGQsbLbdsS5MWjNUBR+3nQ6r4PnnzM409aaI2lm1WICsguVKsLqauPXfVrc+PVufunXb4OZLZflM+AKTUoOBpcp3mf8wEs4Oat/Uxg4kSi7dB3Cbd9ia0xszHZA9VrC4Wd2Z25K/Kz883lCixJ2+fo+nXPtL8gCXNqZipnJyQuVAJrF21Tr/tfbWqK2vkxJwG6wJBWx12LdL9H0xRTl6bHXqeZLbfnPMBIGXemPt23OIhSXU1dfrio1WGEiU2Z/o8T3Pn7TsyxUm8++qrrzzNDQwmLigmJSoeknR68cUGknj38Li/xx9wpUnDp5kJ49EzU+c1WTwkKVbn6Jsv1mnhrFeNZqJ8AEiZKb+9x9PcTSdPSnES76Ze8ldPc19+sibFSbw7t+uV3gYbb3t8c/fVMzzN1VbVpjiJd7FYTNVbqhPOLfnXstSHScLCx19rsnhsY1mWFj35usFElA8AKVSztc7TXFX51hQnQbr5/J2VfkdIWk2Nt/dzrDbxHh2TqrbE//5yXVdbolWG0tSjfABImd17dfU0t/9R+6Q4iXfB7NZ3EeCue+34yYKmnX3zaX5HSJrX8zjCHdLnHBVJ6tazi2zbanZ9IGire69uBhNRPgCk0KSXb/I0d+NjV6c4iXdeT36d+XX6HNd/6BNvWU68YlCKk3h34JG9PM0d89tfpDhJcrrt0yXhzEWTzzaQxLsTRxwjJ865V7E6R8dd9EuDiSgfAFIoOztbBw6If9nhkaf+zFAa76xA858St+nUKb32NoTyEl+ufNkdFxpI4t1JVx6bcOb30y81kMS7SQtuirsXoVvPXTXg9H4GEyXWf+jhOvzEQ2RZDXNv+3LI7wer5097GM1E+QCQUpMWjFO/U5ouGIPO768xf7/GcKLEXqz9e9zDL+l2yaokzS1/VG3ymz8skI6ZR0w5T4MvHdjkOsu20jJzYXF7zfziXu3SpajBcsuSfnb8QXrwozv8CRZHIBDQTU/+XuePH6bCzu23L991rxL9/oFLdeFE83tquM8HAGPemPu2li14T4cOPlh9frG/33E8ufn0SfrPnKX6yUG7a+prpX7H8eRPZ0zWq0+9qY7dOuiRFd6uOPLb4tmv65GxT6pLz1019sn0K6RNqYhUaNnLHyq/sG1a3lisKbFYTBvWbFIgGFBhcbtGe0N2BDcZAwAARnGTMQAAkLYoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMCooN8BAD+5df+Tu+Uhaetcya2SArvLyhsm5QyRZWX7HS9jLHj0/zT5gntUV1O3fVl2myzd+OTVOuy4vj4ma970UY/oyUlzGi0/8Oj9NGn+OPOBPLjvDw/rqclzGy3PyQ9pTmSmD4kS+98nq3Vx72vkxJwGy3sfta+mLLzZp1TxVVRU6OzdLlPFpi0Nlvc5urcmzr/Jp1StS4vv+airq9ONN96o7t27KycnR3vssYf++Mc/ynGcxH8YMMiteUvu+hOlqickNyqpVoqtkBv9o9yNF8h1q/2OmBEevfUp3Xb2XQ2KhyTVbK3VTYMn6J8PzPcpWfNuOmlCk8VDkpYt+FBn7fE7w4kSG3/2n5ssHpJUVV6tgYEhhhMltuLdlbpw36sbFQ9Jen/RRzq1+AIfUsVXUVGhkwvOa1Q8JOmdBe9rSBpmTkctXj4mTJig++67T9OmTdPHH3+siRMnatKkSZo6dWpLPxXwo7lujdzNl0mqlhT7/pr6R+0SuRV/8SdchnlozONx1//5oumGknj3xpy34q7/5n/rDCXxbuGjr8cfcKVPPvnETBiPLj3oD3HXR9ZG9Z95Sw2l8WbYrpfGXb95bVSzpz5vKE3r1eLl44033tCJJ56o4447TrvvvrtOPfVUDRo0SG+9Ff+bGTBq64uSs1FSc3vkHKlyply31mSqjHPHxfd5mnvstqdTnMS7aweO8zR3QsHZqQ2ShLsuv9/T3OX7jklxEu82b95c3/UTGHvihJRnSUZV+daEM9OvecRAktatxctHv379tGDBAi1fvlyS9O677+rVV1/Vscce2+R8dXW1otFogweQam7t+0p4ypO7WYqVmYiTsd547m1Pcy/MWJjiJN69u/AjT3NVFYk3QqY8d++LfkdI2uN/esbTXKwufQ7Zb9xY7mkuVhtLPLSTa/ETTkeNGqVIJKKePXsqEAgoFovp1ltv1RlnnNHkfGlpqW6+OT1PKkIGs7Jadg5NCmQFPM1lhdLn3HfLsuR6+UieRgIBW7FWdl5dYef2fkdIWtu2Ib8jZIwW3/PxxBNPaObMmZo1a5aWLl2qhx9+WJMnT9bDDz/c5Pzo0aMViUS2P1avXt3SkYBGrNCRkuriTUiBn0h2J1ORMtI5407zNPe7O89PcRLvLvnzcE9ze/XtnuIk3k1cMM7bYBrdXOG0a070NNe2MC/FSbzLzvZ2BVxeODfFSVq/Fn8rXnvttbruuus0dOhQ9e7dW2effbauuuoqlZaWNjkfCoVUUFDQ4AGkXNYhUnA/Sc19Mndltb1YlmWZTJVxjjnvF1KClzAQtNVnQC8zgTw4+bKmDxH/0N1vTkxxEu/277ePp7n5dU+mOElysnMSb8xnrLgj9UGSsFuvrglnJsxPn3Nr0lWLl4/KykrZdsO/NhAIcKkt0oplWbLa3ycFdvt2ybb37LdlJG+ErJyTfEiWeaa/Oznu+plf3G0oiXfT3rwl7vpzb/G2R8ekx9beG3f97h42mqY9v+XRuOX0F2f2U7t27Yzl8eKB96aoTV7zh1+OPPVn2rvvngYTtU6W67otenDz3HPP1UsvvaS//OUv2m+//fTOO+/ooosu0vnnn68JExKftRyNRhUOhxWJRNgLgpRz3Rpp63y5W/8lueVScE9ZOafLyurhd7SMUltbqyuPGKPlb/9XcuvLX6+f99SE+WOUlZWe59WUl5fr9I4Xqbb6u8Nzlm3poVV3qKSkxMdk8Q0MDGl0FcnYOdeo3/E/8yeQB1cPGKv3F313om8wO6gpi2/WPj/dy8dU8d171Qw9PXWeXKf+xW6TF9Ktz4/W/kfu53My/ySz/W7x8lFeXq4xY8bo6aef1tq1a1VSUqIzzjhDN910k6fjZZQPAABaH1/Lx46ifAAA0Poks/1Oo3OfAQDAzoDyAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADAq6HcAZBan5iOp4g7JrZRCR8lue6HfkRJyar+QyidIblTKOljKu0J2IOB3rLicui+lzddK7kYp0EMquEN2ML2/nV23Vqp5Q3LWS3YnKftQWVZ6v86RyBbd+Otb9c3KdQrvkq8/zR2t4m67+B0rrlgspvtHzdTytz5Xuw75uvTO87TLrkV+x4qrtrZWt5z+Z33y788Uys3WVfdfqj4DevkdK6GVH6zSindWKjuUpT5H91ZBUb7fkVoNy3Vd1+8Q3xeNRhUOhxWJRFRQUOB3HHjkxCLS+l/VbwwbsKT8cbLzzvAlVzxOrEba+Csp9lXjlXkjZOePNB8qAaeuTtrYX3LWNl6Z1V920XTjmbxwq56VW36b5Gz4bqHdUVbBGFltfuVfsDgu6HWVVn30ZaPl7ToW6MmyB31IlNjdI/+qZ6bOa7S8W89dNf392xVIw1J967A79MrjrzVaHswO6vFvHlA4nOdDqvjW/LdME4dP04evf7p9WTAroOMuHqiLJ5+jrOwsH9P5J5ntN4dd0DLWHdlE8ZAkVyofK6fqX8YjJbShf9PFQ5K23C2n4iGTabzZ8POmi4ck1b4iZ+MVZvN44FY9KzdybcPiIUnOOrmbr5C7db4/weK4uM81TRYPSdq8Nqrf7HK+4USJ/fXGx5osHpK06pOvdN5e6Vemp135YJPFQ5Lqauo0pOg8w4kSW79mo0YecaM+/s9nDZbX1cY0554XVHrmnUqzz/RpifKBHeZU3CepKv5QdIyRLF45VQvqd//HUzHZTBiPnOr3JHdD/KGa9Cp5rlsrt7y0ubX1/1teKtd1zIVKoLa2Vp+/+0XcmeiGcq36tJni6pMnJj4Td/3XK7/Rp2+uMBPGo2fviv9+dR1XD45+1FAab/5x+3OKbiiXE2v8nnUdV//31H8aFRM0RvnAjtvyUOIZN1J/mCNdVEzwMFQjp2Z5yqN4Fr3W05hTkUaHBGrekJym9oht40qxL6XaZaYSJTTh7Kme5sYMvi3FSbx7859vy6lLXODuuux+A2m8+WzZSk9z//jz3BQnSc4LMxY2WTy2CQRtzX/4FXOBWinKB3acm2CvxzbO16nNkQwn6m2u7uPU5kiGs9nbXM0HKY2RlFiCvUvbOOtSmyMJqz5Z42kuuqE8xUm8++yd/3ma27zW4/vegA9e+8TTXKwuluIk3sViMVVs3hJ/ps7Rpm82mwnUilE+sOOsXG9zdufU5kiG3c7bXDCNzri323ubyz44tTmSEejobc4uTm2OJHTv1c3TXPtO4RQn8a7nT/f0NFfU2eN7yIADj9rX01xWdvpcxRUIBJRf2Db+TNBWUUmhoUStF+UDOy7v4sQzVnvZgezUZ/Eq/wYPQyHZ2T9JeRTPwnd4GrPbnpXaHMnIPlSyO8QZsKTAblLW/sYiJXLNjEs9zY3/140pTuLdwQMPUCCY+EqWK6dfZCCNN9177SZZieeG3fCb1IdJwq8vOFp2oPlNZ6zO0aBzBxhM1DpRPrDD7LbnSkpwfXs4vU7etNv8PPGemPz02bhIkp3dM3Hm0ClmwnhkWUFZBTepfivzwy1N/TKrYIwsy8NWyJCsrCztc9hecWcKO7dPu/t9DL/5tLjru+3TRXv03t1MGI+GXR///RrICujMNCsfp/5+sAqL28kONrH5tKSjz/y59u6bRh9a0hTlAy1jl1eb2TAGpIIp9Rv7dFP0shRoane1LbUdLTvvdOORErE7LpLsZg4LhI6X3T59ToLcxmpzjKx2Uxu/PwJdZbWfLit0pD/B4rjrtVu1dzOHMnbpWqQnvkq/+6mcMfoUnTXmN2qqx+3Vdw89+OGfzYdK4Lw/naETRhzT5LpQbraeq3jEcKLE2ncM687Xb9VBv+jdYHkoN6ShfzhJ184Y4VOy1oWbjKFFOXVf1t/h1KmU2gyUnXuy35EScmIbpfLJkrNJyj5Mdttz/I6UkFO3WYpcJ7lr6w9Z5N3YCu5w6ki173x3h9OsA9Jqj0dTamtrdfMpk7Xq4y/VoUuRxj47Ki1vevVDf5/0rD547RMVdm6n3952ptqG45+nkA6mXv6glvzrHeWFczX60ZHqtveufkdK6OvPv9F/3/2fskJZ6v3zfZSbn+N3JF8ls/2mfAAAgB3GHU4BAEDaonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAo4J+B0DTnK0Lpch1krvp2yVtpLwRsvMv9jVXPE75w9KWWxsutPeU3fGf/gTywFl/s1T3aKPldvFyH9J445S/IG25/AdLA1Lem7Lz833JlIgTq6h/P9e8IqlWUrbUZpCUXyo7kO1zuszhuq4+ePUT/fOBl7T60zUqKGyrAUP76ajTDlN2G15npA/LdV23pf/Sr776SqNGjdK8efNUVVWlvfbaSw8++KAOPvjghH82Go0qHA4rEomooKCgpaO1Cs6mq6XquU2vtLvJ7viS2UAeOGsHS86nza5Px425U3awpPLmB4Kvy+7QwVgeL5wNl0m1LzY/kPec7Py9zQXywKn9QtrwK0lOE2uD0i6LZAd2MR0r4ziOozsuma55DyxQIGgrVufIti05jquuPXfV5JfHqrC4vd8xkcGS2X63+GGXTZs26YgjjlBWVpbmzZunjz76SLfffrvatWvX0k+VkZytrzdfPCTJWSVn0zXmAnngVL0dt3hIklPWy1Aab5z16xW3eEhS3eFGsiQlXvGQpC2DzeRIxoYT1HTxkKQ6ad2xJtNkrKf+/LzmPbBAkhSrq3+9Haf+s+WaFV/r5t9M9i0b8EMtfthlwoQJ6tq1q2bMmLF92e67797ST5O5Ir9PPFM9V1Ia/SCJnOVhqCblMZLisVg469enzd4Pp6yvt7nyRbLzj0pxGm+crf8nqSrBVEROzUeys/c1ESkjxepievL2OXHWO/rojeX6dMkK7X3IngaTAU1r8T0fc+bMUd++fTVkyBB17NhRffr00f3339/sfHV1taLRaIPHTs3d4GGouU+Rfol5mnKq3ktxjhSoO87vBN/j8Xuj0fkgPtryoMe5B1KbI8Ot+uQrbSrbHHfGDtha+tL7ZgIBCbR4+fj888917733qkePHnrhhRd0ySWX6IorrtDf/va3JudLS0sVDoe3P7p27drSkZA2Nvod4EdIsz02nrT4aVw7wFsxrT8JFT+WE0v8gcSy6veQAOmgxcuH4zg66KCDNH78ePXp00cXX3yxLrzwQt17771Nzo8ePVqRSGT7Y/Xq1S0dqZVp63eAH8HyNGXn9E9tjFQIptHhLa9HSXMuTW2MZOSc4HHuN6nNkeG67NVZuQU5cWdidY72PWwvQ4mA+Fq8fHTu3Fn77tvw2O0+++yjVatWNTkfCoVUUFDQ4LFTK7gx8UzQ27F/Y9qO9TDkraAYE5zkaczucHSKgyQh7z+exuzw71IcxDs7d4ikQIKpkOw2/Q2kyVyhnJCOv3iQbLvp7zM7YGvXHp114C/S68Rv7LxavHwcccQR+vTThlc+LF++XLvttltLP1VGsnNPkQL7xJnIkd1hlrE8XththynhHpvwG0ayeGV3ODHxkMeCYkr9PTw6xR/K/YORLElpNz3++sLG91lB8s4ZN0S9fl7/s8P6XgmxA7bywrkaN/ta2Tb3lUR6aPF34lVXXaV///vfGj9+vFasWKFZs2Zp+vTpGjFiREs/Vcayd3lWyhmuRp8Ysw6TXfyuL5kSsYuXSoEDm1iTJYXflZ1TaDpSQvX3HmlmT1vwXm8FxTC7+P+kYP+mV+ZNlV3wW6N5vLDb/FwqfE4K7N5wRaCHVDRfdvb+vuTKNKGckG574UZdNf0S7Xng7soL56pjtw4aOuok3f/+FO2+H+fTIX2k5CZjc+fO1ejRo/XZZ5+pe/fuuvrqq3XhhRd6+rPcZAwAgNYnme13SsrHjqB8AADQ+vh6h1MAAIB4KB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAo4J+B0DznNpKqWqa5FRIeb+VndXN70gJOdGoVHmSpHIp9xLZBRf4HckTp6y3pGpJP5Nd/IjfcTxxyn4qabOkA2QXP+lzGm+cqpekmqVS6Gey2xzldxwAPrFc13X9DvF90WhU4XBYkUhEBQUFfsfxhVNbK208THKjP1gTlIqekZ21ly+5EnHKmsmVfYbswpvNhvGo2cwKyy5eYjSLV81nzpZd/IHRLF45kZukqsd/sNSSci6QHf6DL5kAtKxktt8cdklHG/ZvonhIUp204Xg5tauMR0qk+Q2ipJrH5Gy6xVwYj+JmVkRO2aHGsngVP3ONnLL9jGXxytl4VRPFQ5JcqeoBOZE/Gs8EwF+UjzTjbLpCUiz+0MZTjGTxyik7JvFQ9d9SHyQJTtmJHqY2pjxHMpy1MzxM1aY8RzKcujqp5vn4Q1UzzYQBkDYoH+mm+sXEM03uFfHT556mnGg65f7Y05RTdlWKcyTBKfU2VnZYioMkIXqtpzEnMjHFQQCkE8pH2nH8DpA6bmv8hPuC3wF+hA1+B/hO3Yfe5mrfTG0OAGmF8gFzrDT6RO5ZB78D/AiW3wG+Y3s8adwqTG0OAGmF8pFurM4ehgIpj5Ecb28ju6BPinO0PLt4sd8RvqfI25j9f6mNkYywt0NFCt+a2hwA0grlI90UPpZ4JndE6nMkI9fLLvPclMdIhl283O8ISbOL3/A217FjipN4Z2f1kKx2CYaKZQd3MZIHQHqgfKQZO6tEyv9T8wPZv5RdcJm5QB7YBQVS1qlxJizZxctMxUnCb+KuTcuCYt8Zf3U6Zi56XVJe0+usdlLhyybTAEgDlI80ZOedLhV9KGX1l5QtKUuyfyIVLZFdeI/P6ZpmF43/dsP3g41M7r2yiz/1JVMidnHpt5l/eI7Ecem5EZdkd/z1t9l+uCfp0PTNHAzKLn5HCk+TrI6SciW7WGo3Q3anN2UHudEysLPhDqcAAGCHcYdTAACQtigfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwKig3wFMcN2YVL1Ibs1/JLmysg+RQgNkWTvFv74xTjQqVR4qqe67hbmjZBdc4FsmL5yyvX6wZF/Zxc/4EcUz55tBkvu/7xaETpbdfoJvebxw676Utj4n11kvy+4k5ZwgK1Dsd6y43NhaaescubGvZdmFUpvBsoLd/I4FtHqW67puKp+gtLRU119/vUaOHKk77rgj4Xw0GlU4HFYkElFBQcEOP79bt0Lupouk2Jf6rmvVSXZnWe3/Iiur5w4/ByRn/UVS3SvNrreLl5sL45FTdq6k15tdn5aZt/xHKj+72fXpmNl1Hbnlt0mVD0uyVL/D1alfmXeJrLYjZVmWjwkbc11X2nKf3Io7v12yLbMr5Zwhq2CMLCvgY0Ig/SSz/U7pYZclS5Zo+vTp2n///VP5NM1ync1yN54jxb7+dkmdtn8qd9bK3XiO3NgGX7JlEif6ZdziIUlOWS8zYZLSfPGQmtojkgbiFA8pPTO7FVOlyockuarfgNd9+09H2nKPVDnDz3hNq5olt+LP2p5ze2ZXqnpMbvlkX+MBrV3KykdFRYXOPPNM3X///Wrfvn2qnia+qqckZ4OkWBMrY5IblaqeMJ0q81Qe7WGoJuUxkpGOG+lEnPXDvc1t2ZLiJN65ToW05cH4MxX3ynXT5/3hurVyK6bFm5Aq/ybX2WwqEpBxUlY+RowYoeOOO06//OUv485VV1crGo02eLQUt+p51X/aao4jt2puiz3fzsvbkTsn+k6Kc7Q8p+xQvyN8p+4Nb3Plx6Q2RzJqXpO0Nf6MG5FqlhiJ40ntu99+aIk7JFUvMhIHyEQpKR+PP/64li5dqtLS0oSzpaWlCofD2x9du3ZtuSBuRcvMoGW4HjeeaSXid4AfIY3e067HvTBe50xwK1t2DkAjLV4+Vq9erZEjR2rmzJlq06ZNwvnRo0crEolsf6xevbrlwgT3khTvpLDAtzMwwjrL7wQ/wmC/A3yPx2/XbC+HwQwJ/MTbXHCP1OZIRqC7t7mgx383AI20ePl4++23tXbtWh188MEKBoMKBoNatGiR7rrrLgWDQcViDc+/CIVCKigoaPBoKVbuGWr6fI9tYrJyh7XY8+20rH08jdkt+N92x/X1NGUXT0xxjiTkP+NpzC5Mo5Mhs/aXgj3U/I+agJR1kKzgniZTxWUFu0rZh6v5Dy62FOgmZR1iMhaQUVq8fBx99NF6//33tWzZsu2Pvn376swzz9SyZcsUCBi8PC37cClnyLdfNHEpX5sTpNAAc3kylN3p2cRDuaNSHyQJdvEsD1OdU54jGXZeT0lZ8YcCPzWSxSvLsmSFJ0gKqfHGPCBZubLCt/iQLD6rYJxk5avJzMqSFZ6YdpcHA61Ji5eP/Px89erVq8EjLy9PRUVF6tXL7OWWlmXJKviTrIKxUmDX71bYJbLyb+AHSAuKe3+JnCvT8kZj8e+J0Vl2cfqdUGgXfyipmT1IwSNk7zLTaB4vrKxesor+IYV+qe9+5ASlNsfKKnoqrfZ6bGMFd5dV9JTU5nh9d38gq/7mhEV/l5V9kJ/xgFYv42/xaVm2lHumlHOG5KytX2h3rF+OFrVtY+6sO1eKlUm5Y2QXHOFvqAS2Zy47StJ6ScNlF//B10yJ2MVvSZKczVOkmjekvDNk553ic6r4rKwestpPrb/01tks2e1l2Xl+x4rLCnaV1W6SXOdmydko2WFZdr7fsYCMkPI7nCarpe9wCgAAUi9t7nAKAADwQ5QPAABgFOUDAAAYRfkAAABGUT4AAIBRlA8AAGAU5QMAABhF+QAAAEZRPgAAgFGUDwAAYBTlAwAAGEX5AAAARlE+AACAUZQPAABgFOUDAAAYRfkAAABGUT4AAIBRlA8AAGAU5QMAABhF+QAAAEZRPgAAgFGUDwAAYFTQ7wBomlvzjtwtf5VqFktuTMrqLStvuBT6lSzL8jtek5yqeVL5ZMlZ/e2SNlLOYCn/Ztl2er7VnPK/SFumSqr5bqHdWSr8h+zgLr7lisepeVeKjpPqPpLkSgpKoX5SQansQJG/4ZrhOhvlbvmbVPUPydko2bvIyj1Nyj1Llh32Ox4AwyzXdV2/Q3xfNBpVOBxWJBJRQUGB33F84VbOlhsdrfodU7Fvl9qSHCnnLFkFY9KugDjld0hb7ml6pV0sdXhJtp1tNFMizsaRUs285gc6vCw72MVcIA+cqhelyOWqLx0/FJI6vCA7WGI6Vlxu7Cu5G4ZKzjpJzvfW2FJgV1mFj8sKpGfRA+BdMttvDrukGbfuS7nR61W/cYl9b823P7SrZkrVL/qQrHlO3ermi4ckOWVSdJS5QB44dWXxi4ckrT/BTBiPHMeRIleq6eIhSdXSpgsMJvLG3fwHyVmvhsVD9V/H1siNjvEjFgAfUT7SjFv1RIIJu373dTopvy3xzNYXUp8jGZsu9DBUIaduQ8qjeFb5N0l18Wdi/60vVmnCrVsh1S5RwyL9fTGpeqHc2BqTsQD4jPKRbmrfVeNPiN/nSLXvm0rjTe1HHobq5DgbUx7Fs9gX3ua2zk1tjmTUvuZtrnpRanMkw9N71ZVqP0x5FADpg/KRdrIlJTifw0qzkzc95wmlNEZyPL717XQ678jjOTN2m9TGSEqWtzHL4xyAjED5SDNW6MgEEwEpNMBIFs+y+yeesQpk23kpj+JZ9hEe5wanNkcycoZ4GLKk0MCUR/Es+1BJgQRDbaSsvibSAEgTlI90k3OyZIXV/H8aV1beuQYDeZB/lRJuYPLONxLFs4I7E88E9pAdTJ+9THab/pJVGH8odKRsO9dIHi+sQIf693Sz72dLyh0my25rMhYAn1E+0oxl58sq/KtkFaj+8Mu2QzC2pICs8GRZWb39C9gE286V2j+gZt9OoWNkt/2d0UyJ2MGgVDA5zkRb2bv8y1gez4qelNRMuQj8RArfazSOF1bBTd/b0xRo+M/QIFn5v/cjFgAfcZ+PNOU6FdLWZ+VuXSypVso6QFbu6bICxX5Ha5bjbJaiE7494bFWCnaT2l4rO3So39Ga5dStq788Nfap6i9hDUk558oOp+8G0XFq6i9trnpacrdIdgep7UWyc07xO1qzXNeVal6XW/WM5KyVAp1l5fxGyuqbdvesAfDjJLP9pnwAAIAdxk3GAABA2qJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKOCfgdAZnGdiFTzuuRulYI9ZWXt43ekjOS61VL1a5K7WQp0lbL6yrIsv2MBgCctXj5KS0s1e/ZsffLJJ8rJydHhhx+uCRMmaO+9927pp0Iacd1aueWTpcpHJdV8tzy4v6x2E2QFf+JfuAziuq5U+Yjcijslt/y7FYGuUsGfZIUO9y8cAHjU4oddFi1apBEjRujf//635s+fr7q6Og0aNEhbtmxp6adCGnEj10uVD+n7xUOSVPeh3A1nyI195UeszFP5V7nltzQsHpIU+1Lupgvk1izxJxcAJMFyXddN5ROsW7dOHTt21KJFi3TkkUcmnI9GowqHw4pEIiooKEhlNLQQt/YjuRtOijMRkHJPl10wzlCizOQ6FXLXHiapupkJW8raX3bR303GAgBJyW2/U37CaSQSkSQVFhY2ub66ulrRaLTBA62LW/WMpECciZhU+bRc1zGUKENVv6jmi4ckOVLtMrl1q0wlAoAfJaXlw3VdXX311erXr5969erV5ExpaanC4fD2R9euXVMZCangrJeUaAdaleRWmUiTuWLrFb/kfctZl/IoALAjUlo+LrvsMr333nt67LHHmp0ZPXq0IpHI9sfq1atTGQmpYHeUlOBKCytXsnKMxMlYgY6SYonn7E4pjwIAOyJll9pefvnlmjNnjhYvXqwuXbo0OxcKhRQKhVIVAwZYOafIrfxrnImAlHOqLIvbyuyQ0EBJOZKa24NkS1kHyQo2//0GAOmgxbcGruvqsssu0+zZs/Xyyy+re/fuLf0USDNW1l5SzunNrA1IdntZeRcazZSJLDtPVsEfmllrSwrIyh9lMhIA/CgtXj5GjBihmTNnatasWcrPz1dZWZnKyspUVcXx/kxmFYyT8kbUH175vuxDZBU+ISvAoYCWYOWeKatgvGQXNVwR3FNW4SOysg/wJxgAJKHFL7Vt7i6LM2bM0Lnnnpvwz3OpbevmOpVS7RLJrZaCe8sK7uZ3pIzkunVSzVuSG5ECXaTgvtzhFICvktl+t/g5Hym+bQjSnGXnSqGj/I6R8SwrKIUO9TsGAPwonAEIAACMonwAAACjKB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjErZb7X9sbbdITUajfqcBAAAeLVtu+3lTudpVz7Ky8slSV27dvU5CQAASFZ5ebnC4XDcmRb/xXI7ynEcrVmzRvn5+S3+i7Ki0ai6du2q1atX80vrUojX2QxeZ3N4rc3gdTYjVa+z67oqLy9XSUmJbDv+WR1pt+fDtm116dIlpc9RUFDAG9sAXmczeJ3N4bU2g9fZjFS8zon2eGzDCacAAMAoygcAADBqpyofoVBIY8eOVSgU8jtKRuN1NoPX2RxeazN4nc1Ih9c57U44BQAAmW2n2vMBAAD8R/kAAABGUT4AAIBRlA8AAGDUTlE+SktLdcghhyg/P18dO3bUSSedpE8//dTvWBmttLRUlmXpyiuv9DtKRvrqq6901llnqaioSLm5uTrwwAP19ttv+x0ro9TV1enGG29U9+7dlZOToz322EN//OMf5TiO39FatcWLF2vw4MEqKSmRZVl65plnGqx3XVfjxo1TSUmJcnJy1L9/f3344Yf+hG3l4r3WtbW1GjVqlHr37q28vDyVlJTonHPO0Zo1a4xk2ynKx6JFizRixAj9+9//1vz581VXV6dBgwZpy5YtfkfLSEuWLNH06dO1//77+x0lI23atElHHHGEsrKyNG/ePH300Ue6/fbb1a5dO7+jZZQJEybovvvu07Rp0/Txxx9r4sSJmjRpkqZOnep3tFZty5YtOuCAAzRt2rQm10+cOFFTpkzRtGnTtGTJEhUXF2vgwIHbf+8XvIv3WldWVmrp0qUaM2aMli5dqtmzZ2v58uU64YQTzIRzd0Jr1651JbmLFi3yO0rGKS8vd3v06OHOnz/fPeqoo9yRI0f6HSnjjBo1yu3Xr5/fMTLecccd555//vkNlp1yyinuWWed5VOizCPJffrpp7d/7TiOW1xc7N52223bl23dutUNh8Pufffd50PCzPHD17opb775pivJ/eKLL1KeZ6fY8/FDkUhEklRYWOhzkswzYsQIHXfccfrlL3/pd5SMNWfOHPXt21dDhgxRx44d1adPH91///1+x8o4/fr104IFC7R8+XJJ0rvvvqtXX31Vxx57rM/JMtfKlStVVlamQYMGbV8WCoV01FFH6fXXX/cx2c4hEonIsiwje1HT7hfLpZrrurr66qvVr18/9erVy+84GeXxxx/X0qVLtWTJEr+jZLTPP/9c9957r66++mpdf/31evPNN3XFFVcoFArpnHPO8Ttexhg1apQikYh69uypQCCgWCymW2+9VWeccYbf0TJWWVmZJKlTp04Nlnfq1ElffPGFH5F2Glu3btV1112nYcOGGfmlfjtd+bjsssv03nvv6dVXX/U7SkZZvXq1Ro4cqRdffFFt2rTxO05GcxxHffv21fjx4yVJffr00Ycffqh7772X8tGCnnjiCc2cOVOzZs3Sfvvtp2XLlunKK69USUmJhg8f7ne8jGZZVoOvXddttAwtp7a2VkOHDpXjOLrnnnuMPOdOVT4uv/xyzZkzR4sXL1aXLl38jpNR3n77ba1du1YHH3zw9mWxWEyLFy/WtGnTVF1drUAg4GPCzNG5c2ftu+++DZbts88+euqpp3xKlJmuvfZaXXfddRo6dKgkqXfv3vriiy9UWlpK+UiR4uJiSfV7QDp37rx9+dq1axvtDUHLqK2t1WmnnaaVK1fq5ZdfNrLXQ9pJrnZxXVeXXXaZZs+erZdfflndu3f3O1LGOfroo/X+++9r2bJl2x99+/bVmWeeqWXLllE8WtARRxzR6FLx5cuXa7fddvMpUWaqrKyUbTf8ERkIBLjUNoW6d++u4uJizZ8/f/uympoaLVq0SIcffriPyTLTtuLx2Wef6aWXXlJRUZGx594p9nyMGDFCs2bN0rPPPqv8/PztxxXD4bBycnJ8TpcZ8vPzG51Dk5eXp6KiIs6taWFXXXWVDj/8cI0fP16nnXaa3nzzTU2fPl3Tp0/3O1pGGTx4sG699VZ169ZN++23n9555x1NmTJF559/vt/RWrWKigqtWLFi+9crV67UsmXLVFhYqG7duunKK6/U+PHj1aNHD/Xo0UPjx49Xbm6uhg0b5mPq1inea11SUqJTTz1VS5cu1dy5cxWLxbZvGwsLC5WdnZ3acCm/niYNSGryMWPGDL+jZTQutU2d5557zu3Vq5cbCoXcnj17utOnT/c7UsaJRqPuyJEj3W7durlt2rRx99hjD/eGG25wq6ur/Y7Wqi1cuLDJn8fDhw93Xbf+ctuxY8e6xcXFbigUco888kj3/fff9zd0KxXvtV65cmWz28aFCxemPJvluq6b2noDAADwnZ3inA8AAJA+KB8AAMAoygcAADCK8gEAAIyifAAAAKMoHwAAwCjKBwAAMIryAQAAjKJ8AAAAoygfAADAKMoHAAAwivIBAACM+n87yFfIvzUY6AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter = plt.scatter(X_train.iloc[:,6], X_train.iloc[:,7], c=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c8cb0-be5d-46d3-bdd1-b589aea83e3f",
   "metadata": {},
   "source": [
    "# XG-BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b556a05d-cddb-48dc-9228-890e7857dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\aceme\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\aceme\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\aceme\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "# First, put this prompt: \"conda install -c conda-forge py-xgboost\" in anaconda to download xgboost package\n",
    "# install xgboost in jupyter\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8486047d-e245-44b0-b266-223cf1d04aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0\n",
      " 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1]\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# import the classifier from the xgboost package\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# read data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# create model instance\n",
    "# n_estimators: number of trees(estimators) the model uses --> the more used, the more accurate the model is\n",
    "# max_depth: maximum depth of tree --> higher number makes model more complex, but too high can cause overfitting\n",
    "# learning_rate: quantifies each tree's contribution to total prediction --> lower number takes longer, but can lead to better generalization\n",
    "# objective: binary:logistic outputs probabilities. if classification is wanted, use binary:hinge\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic', enable_categorical=True)\n",
    "\n",
    "# fit model with the training data\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for the test dataset\n",
    "preds = bst.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(preds)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd9727-fa96-4eed-84fd-ab332fee941d",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9815a9c1-2ef9-468e-a32b-15eee40f443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "# kernel: options for kernel include linear, poly, rbf, sigmoid\n",
    "    # linear: use this when data can be split by a linear function\n",
    "    # poly (polynomial): use this when data can be split by a polynomial function\n",
    "    # rbf (radial basis function): use this when there are clusters of one class inside another\n",
    "    # sigmoid: use this when the split between classes is curved and irregular\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(y_pred)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbb0a4-af3e-4f69-84aa-258df7d433b1",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "43a30467-013d-4449-beeb-9d53774928c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#import knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#create a knn classifier\n",
    "#n_neighbors: predicting the label of the data point by looking at the 3 closest data points and getting them to \"vote\"\n",
    "#algorithm: we may need to look at this if it misbehaves\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#train the model using the training sets\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "#predict the response for the test dataset\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "#print predictions\n",
    "print(y_pred)\n",
    "\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a38be0-c339-4bc9-ba85-450adfd743f3",
   "metadata": {},
   "source": [
    "# FIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0eb0c28-3b5a-4cea-a2b9-eb11d65d1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Authors: Balachander S, Prahalad Srinivas C G, Yogesh Chandra Singh Samant, B Varshin Hariharan\n",
    "'''\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#import scikit learn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc=0.01,classifier='DesicionTree',bias=[],control=None,n_jobs=None,random_state=None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e1f81e26-2ab8-432b-8a76-bb023a2c9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "[136, 102, 12, 13, 99, 109, 139, 103, 129, 112, 4, 14, 58, 94, 93, 137, 47, 134, 59, 120, 0, 42, 122, 65, 121, 124, 127, 131, 64, 67, 123, 148, 130, 145, 29, 119, 111, 143, 57, 54, 144, 1, 133, 52, 126, 43, 104, 20, 38, 24, 117, 48, 25, 7, 128, 45, 113, 75, 106, 110, 60, 90, 35, 114, 31, 77, 62, 83, 5, 39, 66, 142, 107, 44, 21, 56, 19, 41, 73, 88, 76, 138, 69, 86, 89, 37, 96, 23, 2, 6, 51, 28, 108, 80, 22, 33, 100, 18, 30, 97, 71, 34, 68, 50, 61, 118, 141, 36, 63, 16, 84, 98, 105, 79, 27, 11, 26, 92, 125, 115, 53, 10, 85, 78, 32, 17, 8, 81, 82, 140, 74, 46, 40, 95, 101, 132, 70, 9, 135, 3, 147, 15, 91, 116, 87, 49, 55, 146, 72]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(DecisionTreeClassifier(max_depth=3), 30.902744020452335, 136),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.08277754996489, 102),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.69072362930995, 12),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.369190478602555, 13),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.802436359002744, 99),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.180272523937617, 109),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.036212102731373, 139),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.923520090798014, 103),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.79824628055546, 129),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.348075129239582, 112),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.32918219362252, 4),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.872093942354187, 14),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.548718797867465, 58),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.380360405545794, 94),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.317780150976382, 93),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.949231292052993, 137),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.475290943738138, 47),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.391768207267024, 134),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.265470124573987, 59),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.020287576600566, 120),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.0048495065447, 0),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.983302222489442, 42),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.834364151568888, 122),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.715898636253627, 65),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.464862635824357, 121),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.28174573878738, 124),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.268301528244237, 127),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.146352884137755, 131),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.086118238680292, 64),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.006679853451615, 67),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.996849025284128, 123),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.972792213145496, 148),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.946014053339898, 130),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.861580488825904, 145),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.687577255744184, 29),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.64441940447636, 119),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.635416126024996, 111),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.62599774823464, 143),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.38376400081298, 57),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.349578357291016, 54),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.313078827562798, 144),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.246967667007723, 1),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.23581323698732, 133),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.231585771033043, 52),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.16338491979842, 126),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.110139268588902, 43),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.07709233392022, 104),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.943851820141802, 20),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.837083505158237, 38),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.683169397912668, 24),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.658872499134837, 117),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.58348783481863, 48),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.573824762641625, 25),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.570186723888522, 7),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.51449468572604, 128),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.49580782490643, 45),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.43853687854285, 113),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.375501703880612, 75),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.369740777054098, 106),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.319384720499606, 110),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.28111714851201, 60),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.253146489372064, 90),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.017092671722516, 35),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.994875204197555, 114),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.961509617181974, 31),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.959256472302407, 77),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.95266701785482, 62),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.84017112091187, 83),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.801427286132053, 5),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.78728445907675, 39),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.762841858473237, 66),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.72441707294182, 142),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.70587115413956, 107),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.703922695211293, 44),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.63016797268198, 21),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.549904768573334, 56),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.51190489835802, 19),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.4341246970321, 41),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.401066608100944, 73),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.318311874186687, 88),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.281018008020098, 76),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.234058108628545, 138),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.20947340766984, 69),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.097713813980565, 86),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.07531179162667, 89),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.066571257056253, 37),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.976966717574754, 96),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.953559732536085, 23),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.92925982607988, 2),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.784873095625077, 6),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.774451736702275, 51),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.75192203269132, 28),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.375854979024915, 108),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.33081257001851, 80),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.311870777297806, 22),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.20677214997444, 33),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.17754512252224, 100),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.941952227729956, 18),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.90848174913595, 30),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.868714628316184, 97),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.76743625960408, 71),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.729055970030366, 34),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.66272822003579, 68),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.584179256120038, 50),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.54481243620757, 61),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.54106823555948, 118),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.516516830198093, 141),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.49954351835426, 36),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.42978780047711, 63),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.318483852323173, 16),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.25367373610333, 84),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.23937149522451, 98),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.21957886787402, 105),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.128508127470855, 79),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.12529804540063, 27),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.12457826697525, 11),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.053281953488174, 26),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.032158181141927, 92),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.916569091559882, 125),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.909679361154613, 115),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.83476903382806, 53),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.805230880946628, 10),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.668640782899558, 85),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.633486014147328, 78),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.532770264366095, 32),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.499861126434762, 17),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.492805089249632, 8),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.348720777775553, 81),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.241205702395163, 82),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.233267924878636, 140),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.108074331118207, 74),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.07111401069584, 46),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.04371805320498, 40),\n",
       " (DecisionTreeClassifier(max_depth=3), 14.908854273711917, 95),\n",
       " (DecisionTreeClassifier(max_depth=3), 14.60395338153706, 101),\n",
       " (DecisionTreeClassifier(max_depth=3), 14.388700006821772, 132),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.849498021394727, 70),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.768187375897819, 9),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.754893938149005, 135),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.594730184724654, 3),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.30059281995129, 147),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.070148856005156, 15),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.041717009279953, 91),\n",
       " (DecisionTreeClassifier(max_depth=3), 12.877902913398467, 116),\n",
       " (DecisionTreeClassifier(max_depth=3), 12.813202843290096, 87),\n",
       " (DecisionTreeClassifier(max_depth=3), 12.229988131657542, 49),\n",
       " (DecisionTreeClassifier(max_depth=3), 12.053947352575118, 55),\n",
       " (DecisionTreeClassifier(max_depth=3), 11.433743815959318, 146),\n",
       " (DecisionTreeClassifier(max_depth=3), 11.31795324415877, 72)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model using the training sets\n",
    "clf1=FeatureClassifier(0,classifier='DecisionTree',control=3)\n",
    "clf1.fit(np.array(X_train), np.array(y_train)[:,np.newaxis].astype(int))\n",
    "\n",
    "#predict the response for the test dataset\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(np.array(y_test).astype(int),clf1.predict(np.array(X_test))))\n",
    "\n",
    "print(clf1.indexLs)\n",
    "clf1.featureClassifiers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
