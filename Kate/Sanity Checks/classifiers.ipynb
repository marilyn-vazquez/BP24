{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975e2c1f-5e05-4835-801d-4263aae6f310",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39179e0a-ebed-4582-907a-5fe57bff1559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Smoking_History</th>\n",
       "      <th>Tumor_Size_mm</th>\n",
       "      <th>Tumor_Location</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Survival_Months</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>Alanine_Aminotransferase_Level</th>\n",
       "      <th>Aspartate_Aminotransferase_Level</th>\n",
       "      <th>Creatinine_Level</th>\n",
       "      <th>LDH_Level</th>\n",
       "      <th>Calcium_Level</th>\n",
       "      <th>Phosphorus_Level</th>\n",
       "      <th>Glucose_Level</th>\n",
       "      <th>Potassium_Level</th>\n",
       "      <th>Sodium_Level</th>\n",
       "      <th>Smoking_Pack_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient0000</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Current Smoker</td>\n",
       "      <td>81.678677</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>44</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>27.985571</td>\n",
       "      <td>46.801214</td>\n",
       "      <td>1.245849</td>\n",
       "      <td>239.240255</td>\n",
       "      <td>10.366307</td>\n",
       "      <td>3.547734</td>\n",
       "      <td>113.919243</td>\n",
       "      <td>4.968163</td>\n",
       "      <td>139.822861</td>\n",
       "      <td>17.006956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient0001</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never Smoked</td>\n",
       "      <td>78.448272</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Radiation Therapy</td>\n",
       "      <td>101</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>30.120956</td>\n",
       "      <td>39.711531</td>\n",
       "      <td>1.463231</td>\n",
       "      <td>233.515237</td>\n",
       "      <td>10.081731</td>\n",
       "      <td>2.945020</td>\n",
       "      <td>101.321578</td>\n",
       "      <td>3.896795</td>\n",
       "      <td>135.449361</td>\n",
       "      <td>93.270893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patient0002</td>\n",
       "      <td>44</td>\n",
       "      <td>Male</td>\n",
       "      <td>Former Smoker</td>\n",
       "      <td>67.714305</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Chemotherapy</td>\n",
       "      <td>69</td>\n",
       "      <td>African American</td>\n",
       "      <td>...</td>\n",
       "      <td>5.882418</td>\n",
       "      <td>32.640602</td>\n",
       "      <td>0.630109</td>\n",
       "      <td>169.037460</td>\n",
       "      <td>8.660892</td>\n",
       "      <td>4.637399</td>\n",
       "      <td>78.214177</td>\n",
       "      <td>4.369050</td>\n",
       "      <td>143.377155</td>\n",
       "      <td>70.348376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patient0003</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>Current Smoker</td>\n",
       "      <td>70.806008</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Chemotherapy</td>\n",
       "      <td>95</td>\n",
       "      <td>African American</td>\n",
       "      <td>...</td>\n",
       "      <td>38.908154</td>\n",
       "      <td>44.319393</td>\n",
       "      <td>0.594342</td>\n",
       "      <td>213.967590</td>\n",
       "      <td>8.832669</td>\n",
       "      <td>3.617098</td>\n",
       "      <td>127.895361</td>\n",
       "      <td>4.348474</td>\n",
       "      <td>138.586005</td>\n",
       "      <td>19.828128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patient0004</td>\n",
       "      <td>37</td>\n",
       "      <td>Female</td>\n",
       "      <td>Never Smoked</td>\n",
       "      <td>87.272433</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>Radiation Therapy</td>\n",
       "      <td>105</td>\n",
       "      <td>Asian</td>\n",
       "      <td>...</td>\n",
       "      <td>26.344877</td>\n",
       "      <td>15.746906</td>\n",
       "      <td>1.478239</td>\n",
       "      <td>118.187543</td>\n",
       "      <td>9.247609</td>\n",
       "      <td>4.773255</td>\n",
       "      <td>148.801185</td>\n",
       "      <td>3.671976</td>\n",
       "      <td>141.230724</td>\n",
       "      <td>81.047456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient_ID  Age  Gender Smoking_History  Tumor_Size_mm Tumor_Location  \\\n",
       "0  Patient0000   68    Male  Current Smoker      81.678677     Lower Lobe   \n",
       "1  Patient0001   58    Male    Never Smoked      78.448272     Lower Lobe   \n",
       "2  Patient0002   44    Male   Former Smoker      67.714305     Lower Lobe   \n",
       "3  Patient0003   72    Male  Current Smoker      70.806008     Lower Lobe   \n",
       "4  Patient0004   37  Female    Never Smoked      87.272433     Lower Lobe   \n",
       "\n",
       "       Stage          Treatment  Survival_Months         Ethnicity  ...  \\\n",
       "0  Stage III            Surgery               44          Hispanic  ...   \n",
       "1    Stage I  Radiation Therapy              101         Caucasian  ...   \n",
       "2    Stage I       Chemotherapy               69  African American  ...   \n",
       "3  Stage III       Chemotherapy               95  African American  ...   \n",
       "4   Stage IV  Radiation Therapy              105             Asian  ...   \n",
       "\n",
       "  Alanine_Aminotransferase_Level Aspartate_Aminotransferase_Level  \\\n",
       "0                      27.985571                        46.801214   \n",
       "1                      30.120956                        39.711531   \n",
       "2                       5.882418                        32.640602   \n",
       "3                      38.908154                        44.319393   \n",
       "4                      26.344877                        15.746906   \n",
       "\n",
       "  Creatinine_Level   LDH_Level Calcium_Level Phosphorus_Level Glucose_Level  \\\n",
       "0         1.245849  239.240255     10.366307         3.547734    113.919243   \n",
       "1         1.463231  233.515237     10.081731         2.945020    101.321578   \n",
       "2         0.630109  169.037460      8.660892         4.637399     78.214177   \n",
       "3         0.594342  213.967590      8.832669         3.617098    127.895361   \n",
       "4         1.478239  118.187543      9.247609         4.773255    148.801185   \n",
       "\n",
       "  Potassium_Level Sodium_Level  Smoking_Pack_Years  \n",
       "0        4.968163   139.822861           17.006956  \n",
       "1        3.896795   135.449361           93.270893  \n",
       "2        4.369050   143.377155           70.348376  \n",
       "3        4.348474   138.586005           19.828128  \n",
       "4        3.671976   141.230724           81.047456  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/AceMejiaSanchez/Data/gaussian_small_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Kate/Data/uniform_small_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Fabiana/Data/uniform_large_d_1.tex\")\n",
    "# data = np.loadtxt(\"C:/Users/aceme/OneDrive/Documents/GitHub/BP24/Ellee/Data/gaussian_large_d_1.tex\")\n",
    "df = pd.read_csv(\"C:/Users/kateh/OneDrive/Documents/GitHub/BP24/Kate/Data/lung_cancer_data.csv\")\n",
    "\n",
    "# # Creating NumPy array\n",
    "# array = np.array(data)\n",
    "\n",
    "# # Converting to Pandas DataFrame\n",
    "# df = pd.DataFrame(array)\n",
    "\n",
    "# Look at data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47374f2a-42f2-4690-9035-3d6086010171",
   "metadata": {},
   "source": [
    "# Convert 25/150 Columns into NON-CONSECUTIVE Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42db5971-5001-4ee9-8742-201d0d6b700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Converting 25 columns from numerical floats -> categorical integers\n",
    "# for i in range(25):\n",
    "    \n",
    "#     df.iloc[:,i] = df.iloc[:,i].round() # Rounding\n",
    "#     df.iloc[:,i] = df.iloc[:,i].astype(int) # Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4c61bf-8320-4d97-badf-75d933daa5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Smoking_History</th>\n",
       "      <th>Tumor_Size_mm</th>\n",
       "      <th>Tumor_Location</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Survival_Months</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>Alanine_Aminotransferase_Level</th>\n",
       "      <th>Aspartate_Aminotransferase_Level</th>\n",
       "      <th>Creatinine_Level</th>\n",
       "      <th>LDH_Level</th>\n",
       "      <th>Calcium_Level</th>\n",
       "      <th>Phosphorus_Level</th>\n",
       "      <th>Glucose_Level</th>\n",
       "      <th>Potassium_Level</th>\n",
       "      <th>Sodium_Level</th>\n",
       "      <th>Smoking_Pack_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient0000</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Current Smoker</td>\n",
       "      <td>81.678677</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>44</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>27.985571</td>\n",
       "      <td>46.801214</td>\n",
       "      <td>1.245849</td>\n",
       "      <td>239.240255</td>\n",
       "      <td>10.366307</td>\n",
       "      <td>3.547734</td>\n",
       "      <td>113.919243</td>\n",
       "      <td>4.968163</td>\n",
       "      <td>139.822861</td>\n",
       "      <td>17.006956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient0001</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never Smoked</td>\n",
       "      <td>78.448272</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Radiation Therapy</td>\n",
       "      <td>101</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>30.120956</td>\n",
       "      <td>39.711531</td>\n",
       "      <td>1.463231</td>\n",
       "      <td>233.515237</td>\n",
       "      <td>10.081731</td>\n",
       "      <td>2.945020</td>\n",
       "      <td>101.321578</td>\n",
       "      <td>3.896795</td>\n",
       "      <td>135.449361</td>\n",
       "      <td>93.270893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patient0002</td>\n",
       "      <td>44</td>\n",
       "      <td>Male</td>\n",
       "      <td>Former Smoker</td>\n",
       "      <td>67.714305</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Chemotherapy</td>\n",
       "      <td>69</td>\n",
       "      <td>African American</td>\n",
       "      <td>...</td>\n",
       "      <td>5.882418</td>\n",
       "      <td>32.640602</td>\n",
       "      <td>0.630109</td>\n",
       "      <td>169.037460</td>\n",
       "      <td>8.660892</td>\n",
       "      <td>4.637399</td>\n",
       "      <td>78.214177</td>\n",
       "      <td>4.369050</td>\n",
       "      <td>143.377155</td>\n",
       "      <td>70.348376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patient0003</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>Current Smoker</td>\n",
       "      <td>70.806008</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Chemotherapy</td>\n",
       "      <td>95</td>\n",
       "      <td>African American</td>\n",
       "      <td>...</td>\n",
       "      <td>38.908154</td>\n",
       "      <td>44.319393</td>\n",
       "      <td>0.594342</td>\n",
       "      <td>213.967590</td>\n",
       "      <td>8.832669</td>\n",
       "      <td>3.617098</td>\n",
       "      <td>127.895361</td>\n",
       "      <td>4.348474</td>\n",
       "      <td>138.586005</td>\n",
       "      <td>19.828128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patient0004</td>\n",
       "      <td>37</td>\n",
       "      <td>Female</td>\n",
       "      <td>Never Smoked</td>\n",
       "      <td>87.272433</td>\n",
       "      <td>Lower Lobe</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>Radiation Therapy</td>\n",
       "      <td>105</td>\n",
       "      <td>Asian</td>\n",
       "      <td>...</td>\n",
       "      <td>26.344877</td>\n",
       "      <td>15.746906</td>\n",
       "      <td>1.478239</td>\n",
       "      <td>118.187543</td>\n",
       "      <td>9.247609</td>\n",
       "      <td>4.773255</td>\n",
       "      <td>148.801185</td>\n",
       "      <td>3.671976</td>\n",
       "      <td>141.230724</td>\n",
       "      <td>81.047456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient_ID  Age  Gender Smoking_History  Tumor_Size_mm Tumor_Location  \\\n",
       "0  Patient0000   68    Male  Current Smoker      81.678677     Lower Lobe   \n",
       "1  Patient0001   58    Male    Never Smoked      78.448272     Lower Lobe   \n",
       "2  Patient0002   44    Male   Former Smoker      67.714305     Lower Lobe   \n",
       "3  Patient0003   72    Male  Current Smoker      70.806008     Lower Lobe   \n",
       "4  Patient0004   37  Female    Never Smoked      87.272433     Lower Lobe   \n",
       "\n",
       "       Stage          Treatment  Survival_Months         Ethnicity  ...  \\\n",
       "0  Stage III            Surgery               44          Hispanic  ...   \n",
       "1    Stage I  Radiation Therapy              101         Caucasian  ...   \n",
       "2    Stage I       Chemotherapy               69  African American  ...   \n",
       "3  Stage III       Chemotherapy               95  African American  ...   \n",
       "4   Stage IV  Radiation Therapy              105             Asian  ...   \n",
       "\n",
       "  Alanine_Aminotransferase_Level Aspartate_Aminotransferase_Level  \\\n",
       "0                      27.985571                        46.801214   \n",
       "1                      30.120956                        39.711531   \n",
       "2                       5.882418                        32.640602   \n",
       "3                      38.908154                        44.319393   \n",
       "4                      26.344877                        15.746906   \n",
       "\n",
       "  Creatinine_Level   LDH_Level Calcium_Level Phosphorus_Level Glucose_Level  \\\n",
       "0         1.245849  239.240255     10.366307         3.547734    113.919243   \n",
       "1         1.463231  233.515237     10.081731         2.945020    101.321578   \n",
       "2         0.630109  169.037460      8.660892         4.637399     78.214177   \n",
       "3         0.594342  213.967590      8.832669         3.617098    127.895361   \n",
       "4         1.478239  118.187543      9.247609         4.773255    148.801185   \n",
       "\n",
       "  Potassium_Level Sodium_Level  Smoking_Pack_Years  \n",
       "0        4.968163   139.822861           17.006956  \n",
       "1        3.896795   135.449361           93.270893  \n",
       "2        4.369050   143.377155           70.348376  \n",
       "3        4.348474   138.586005           19.828128  \n",
       "4        3.671976   141.230724           81.047456  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cd94e-5734-4ad0-84a4-26261dcc3970",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1bb13f3-63e8-4849-aaca-82a08a8ce06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:150], df.iloc[:,-1], test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "983d27b7-a27a-45a2-b7da-812d4645eb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15575    19.085740\n",
       "14020    81.926227\n",
       "8060     58.430898\n",
       "8332     85.756587\n",
       "3540     66.795841\n",
       "           ...    \n",
       "8695      3.024433\n",
       "4247     95.589070\n",
       "11019    20.973682\n",
       "9884      7.648412\n",
       "23541    17.983402\n",
       "Name: Smoking_Pack_Years, Length: 18926, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e4fab0-e311-4eac-9256-d03181c3dd14",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db93291b-647d-4998-b7fe-2b702d8e743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter = plt.scatter(X_train.iloc[:,6], X_train.iloc[:,7], c=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c8cb0-be5d-46d3-bdd1-b589aea83e3f",
   "metadata": {},
   "source": [
    "# XG-BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b556a05d-cddb-48dc-9228-890e7857dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\kateh\\anaconda\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kateh\\anaconda\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\kateh\\anaconda\\lib\\site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "# First, put this prompt: \"conda install -c conda-forge py-xgboost\" in anaconda to download xgboost package\n",
    "# install xgboost in jupyter\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8486047d-e245-44b0-b266-223cf1d04aa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [    0     1     2 ... 18923 18924 18925], got [1.67997413e-02 5.08951576e-02 5.39166492e-02 ... 9.99901324e+01\n 9.99981828e+01 9.99994930e+01]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m bst \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m'\u001b[39m, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# fit model with the training data\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m bst\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# make predictions for the test dataset\u001b[39;00m\n\u001b[0;32m     24\u001b[0m preds \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\xgboost\\sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1468\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1470\u001b[0m ):\n\u001b[1;32m-> 1471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1472\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1474\u001b[0m     )\n\u001b[0;32m   1476\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [    0     1     2 ... 18923 18924 18925], got [1.67997413e-02 5.08951576e-02 5.39166492e-02 ... 9.99901324e+01\n 9.99981828e+01 9.99994930e+01]"
     ]
    }
   ],
   "source": [
    "# import the classifier from the xgboost package\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# read data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# create model instance\n",
    "# n_estimators: number of trees(estimators) the model uses --> the more used, the more accurate the model is\n",
    "# max_depth: maximum depth of tree --> higher number makes model more complex, but too high can cause overfitting\n",
    "# learning_rate: quantifies each tree's contribution to total prediction --> lower number takes longer, but can lead to better generalization\n",
    "# objective: binary:logistic outputs probabilities. if classification is wanted, use binary:hinge\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic', enable_categorical=True)\n",
    "\n",
    "# fit model with the training data\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for the test dataset\n",
    "preds = bst.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(preds)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd9727-fa96-4eed-84fd-ab332fee941d",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9815a9c1-2ef9-468e-a32b-15eee40f443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "# kernel: options for kernel include linear, poly, rbf, sigmoid\n",
    "    # linear: use this when data can be split by a linear function\n",
    "    # poly (polynomial): use this when data can be split by a polynomial function\n",
    "    # rbf (radial basis function): use this when there are clusters of one class inside another\n",
    "    # sigmoid: use this when the split between classes is curved and irregular\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print predictions\n",
    "print(y_pred)\n",
    "\n",
    "# print model Accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbb0a4-af3e-4f69-84aa-258df7d433b1",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "43a30467-013d-4449-beeb-9d53774928c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#import knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#create a knn classifier\n",
    "#n_neighbors: predicting the label of the data point by looking at the 3 closest data points and getting them to \"vote\"\n",
    "#algorithm: we may need to look at this if it misbehaves\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#train the model using the training sets\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "#predict the response for the test dataset\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "#print predictions\n",
    "print(y_pred)\n",
    "\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a38be0-c339-4bc9-ba85-450adfd743f3",
   "metadata": {},
   "source": [
    "# FIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0eb0c28-3b5a-4cea-a2b9-eb11d65d1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Authors: Balachander S, Prahalad Srinivas C G, Yogesh Chandra Singh Samant, B Varshin Hariharan\n",
    "'''\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#import scikit learn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "class FeatureClassifier:\n",
    "  def __init__(self,reqAcc=0.01,classifier='DesicionTree',bias=[],control=None,n_jobs=None,random_state=None):\n",
    "    self.featureClassifiers=[] #list of all the classifiers of all the selected features\n",
    "    self.reqAcc=reqAcc #user specified cutoff value\n",
    "    self.indexLs=[] # list of mapped index values to featureClassifiers\n",
    "    self.flag=0\n",
    "    self.bias=bias # list of biases for each and every label\n",
    "    self.control=control #overfitting control for decision trees\n",
    "    self.classifier=classifier #the classifier which is preferred by the user\n",
    "    self.dic={'DecisionTree':0,'LinearRegression':1,'SVM':2,'LogisticRegression':3} #a dictionary which maps the classifier to its index\n",
    "    self.n_jobs=n_jobs\n",
    "    self.random_state=random_state\n",
    "    self.num_lables = None\n",
    "\n",
    "  def finIndex(self):\n",
    "    #finds the index where the reqAcc condition fails and also created the indexLs[] for mapping\n",
    "    for i in range(len(self.featureClassifiers)):\n",
    "      if self.featureClassifiers[i][1] < self.reqAcc:\n",
    "        return i\n",
    "      self.indexLs.append(self.featureClassifiers[i][2])\n",
    "    self.flag=1\n",
    "    return i\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    #applied the model to the dataset. The model is trained and saved for further prediction\n",
    "    self.num_lables=len(set(y.flatten()))\n",
    "    bestfeatures = SelectKBest(score_func=chi2,k=1)\n",
    "    fit = bestfeatures.fit(x,y)\n",
    "\n",
    "    for i in range(len(x[0])):\n",
    "      clf=[DecisionTreeClassifier(max_depth=self.control,random_state=self.random_state),LinearRegression(n_jobs=self.n_jobs),SVC(gamma=self.control,random_state=self.random_state), LogisticRegression(penalty=self.control,random_state=self.random_state)][self.dic[self.classifier]]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=self.random_state)\n",
    "      clf.fit(X_train[:,i:i+1],y_train)\n",
    "      self.featureClassifiers.append((clf,fit.scores_[i],i))\n",
    "    self.featureClassifiers.sort(key=lambda x:x[1],reverse=True)\n",
    "    index=self.finIndex()\n",
    "    if self.flag==0:\n",
    "      self.featureClassifiers=self.featureClassifiers[:index]\n",
    "    return\n",
    "\n",
    "  def predict(self,x):\n",
    "    #given a list of inputs, predicts the possible outputs\n",
    "    if not self.bias:\n",
    "      self.bias=np.zeros(self.num_lables)\n",
    "    if len(self.bias)<self.num_lables:\n",
    "      raise AttributeError('Please check the lenth of bias list')\n",
    "    yPred=[]\n",
    "    for i in range(len(x)):\n",
    "      pred_arr=np.zeros(self.num_lables)\n",
    "      for j in range(len(self.indexLs)):\n",
    "        pred=np.round(self.featureClassifiers[j][0].predict([[x[i][self.indexLs[j]]]]))\n",
    "        pred_arr[pred]+=self.featureClassifiers[j][1]+self.bias[pred[0]]\n",
    "      yPred.append(np.argmax(pred_arr))\n",
    "    return yPred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e1f81e26-2ab8-432b-8a76-bb023a2c9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "[136, 102, 12, 13, 99, 109, 139, 103, 129, 112, 4, 14, 58, 94, 93, 137, 47, 134, 59, 120, 0, 42, 122, 65, 121, 124, 127, 131, 64, 67, 123, 148, 130, 145, 29, 119, 111, 143, 57, 54, 144, 1, 133, 52, 126, 43, 104, 20, 38, 24, 117, 48, 25, 7, 128, 45, 113, 75, 106, 110, 60, 90, 35, 114, 31, 77, 62, 83, 5, 39, 66, 142, 107, 44, 21, 56, 19, 41, 73, 88, 76, 138, 69, 86, 89, 37, 96, 23, 2, 6, 51, 28, 108, 80, 22, 33, 100, 18, 30, 97, 71, 34, 68, 50, 61, 118, 141, 36, 63, 16, 84, 98, 105, 79, 27, 11, 26, 92, 125, 115, 53, 10, 85, 78, 32, 17, 8, 81, 82, 140, 74, 46, 40, 95, 101, 132, 70, 9, 135, 3, 147, 15, 91, 116, 87, 49, 55, 146, 72]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(DecisionTreeClassifier(max_depth=3), 30.902744020452335, 136),\n",
       " (DecisionTreeClassifier(max_depth=3), 29.08277754996489, 102),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.69072362930995, 12),\n",
       " (DecisionTreeClassifier(max_depth=3), 26.369190478602555, 13),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.802436359002744, 99),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.180272523937617, 109),\n",
       " (DecisionTreeClassifier(max_depth=3), 25.036212102731373, 139),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.923520090798014, 103),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.79824628055546, 129),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.348075129239582, 112),\n",
       " (DecisionTreeClassifier(max_depth=3), 24.32918219362252, 4),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.872093942354187, 14),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.548718797867465, 58),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.380360405545794, 94),\n",
       " (DecisionTreeClassifier(max_depth=3), 23.317780150976382, 93),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.949231292052993, 137),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.475290943738138, 47),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.391768207267024, 134),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.265470124573987, 59),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.020287576600566, 120),\n",
       " (DecisionTreeClassifier(max_depth=3), 22.0048495065447, 0),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.983302222489442, 42),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.834364151568888, 122),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.715898636253627, 65),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.464862635824357, 121),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.28174573878738, 124),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.268301528244237, 127),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.146352884137755, 131),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.086118238680292, 64),\n",
       " (DecisionTreeClassifier(max_depth=3), 21.006679853451615, 67),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.996849025284128, 123),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.972792213145496, 148),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.946014053339898, 130),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.861580488825904, 145),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.687577255744184, 29),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.64441940447636, 119),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.635416126024996, 111),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.62599774823464, 143),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.38376400081298, 57),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.349578357291016, 54),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.313078827562798, 144),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.246967667007723, 1),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.23581323698732, 133),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.231585771033043, 52),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.16338491979842, 126),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.110139268588902, 43),\n",
       " (DecisionTreeClassifier(max_depth=3), 20.07709233392022, 104),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.943851820141802, 20),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.837083505158237, 38),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.683169397912668, 24),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.658872499134837, 117),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.58348783481863, 48),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.573824762641625, 25),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.570186723888522, 7),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.51449468572604, 128),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.49580782490643, 45),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.43853687854285, 113),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.375501703880612, 75),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.369740777054098, 106),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.319384720499606, 110),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.28111714851201, 60),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.253146489372064, 90),\n",
       " (DecisionTreeClassifier(max_depth=3), 19.017092671722516, 35),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.994875204197555, 114),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.961509617181974, 31),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.959256472302407, 77),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.95266701785482, 62),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.84017112091187, 83),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.801427286132053, 5),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.78728445907675, 39),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.762841858473237, 66),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.72441707294182, 142),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.70587115413956, 107),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.703922695211293, 44),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.63016797268198, 21),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.549904768573334, 56),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.51190489835802, 19),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.4341246970321, 41),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.401066608100944, 73),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.318311874186687, 88),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.281018008020098, 76),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.234058108628545, 138),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.20947340766984, 69),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.097713813980565, 86),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.07531179162667, 89),\n",
       " (DecisionTreeClassifier(max_depth=3), 18.066571257056253, 37),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.976966717574754, 96),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.953559732536085, 23),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.92925982607988, 2),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.784873095625077, 6),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.774451736702275, 51),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.75192203269132, 28),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.375854979024915, 108),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.33081257001851, 80),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.311870777297806, 22),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.20677214997444, 33),\n",
       " (DecisionTreeClassifier(max_depth=3), 17.17754512252224, 100),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.941952227729956, 18),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.90848174913595, 30),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.868714628316184, 97),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.76743625960408, 71),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.729055970030366, 34),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.66272822003579, 68),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.584179256120038, 50),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.54481243620757, 61),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.54106823555948, 118),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.516516830198093, 141),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.49954351835426, 36),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.42978780047711, 63),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.318483852323173, 16),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.25367373610333, 84),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.23937149522451, 98),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.21957886787402, 105),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.128508127470855, 79),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.12529804540063, 27),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.12457826697525, 11),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.053281953488174, 26),\n",
       " (DecisionTreeClassifier(max_depth=3), 16.032158181141927, 92),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.916569091559882, 125),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.909679361154613, 115),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.83476903382806, 53),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.805230880946628, 10),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.668640782899558, 85),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.633486014147328, 78),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.532770264366095, 32),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.499861126434762, 17),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.492805089249632, 8),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.348720777775553, 81),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.241205702395163, 82),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.233267924878636, 140),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.108074331118207, 74),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.07111401069584, 46),\n",
       " (DecisionTreeClassifier(max_depth=3), 15.04371805320498, 40),\n",
       " (DecisionTreeClassifier(max_depth=3), 14.908854273711917, 95),\n",
       " (DecisionTreeClassifier(max_depth=3), 14.60395338153706, 101),\n",
       " (DecisionTreeClassifier(max_depth=3), 14.388700006821772, 132),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.849498021394727, 70),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.768187375897819, 9),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.754893938149005, 135),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.594730184724654, 3),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.30059281995129, 147),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.070148856005156, 15),\n",
       " (DecisionTreeClassifier(max_depth=3), 13.041717009279953, 91),\n",
       " (DecisionTreeClassifier(max_depth=3), 12.877902913398467, 116),\n",
       " (DecisionTreeClassifier(max_depth=3), 12.813202843290096, 87),\n",
       " (DecisionTreeClassifier(max_depth=3), 12.229988131657542, 49),\n",
       " (DecisionTreeClassifier(max_depth=3), 12.053947352575118, 55),\n",
       " (DecisionTreeClassifier(max_depth=3), 11.433743815959318, 146),\n",
       " (DecisionTreeClassifier(max_depth=3), 11.31795324415877, 72)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model using the training sets\n",
    "clf1=FeatureClassifier(0,classifier='DecisionTree',control=3)\n",
    "clf1.fit(np.array(X_train), np.array(y_train)[:,np.newaxis].astype(int))\n",
    "\n",
    "#predict the response for the test dataset\n",
    "#model accuracy (how often the classifier is correct)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(np.array(y_test).astype(int),clf1.predict(np.array(X_test))))\n",
    "\n",
    "print(clf1.indexLs)\n",
    "clf1.featureClassifiers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
